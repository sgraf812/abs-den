@inproceedings{imprecise-exceptions,
  author = {Peyton Jones, Simon and Reid, Alastair and Henderson, Fergus and Hoare, Tony and Marlow, Simon},
  title = {A Semantics for Imprecise Exceptions},
  year = {1999},
  isbn = {1581130945},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/301618.301637},
  doi = {10.1145/301618.301637},
  abstract = {Some modern superscalar microprocessors provide only imprecise exceptions. That is, they do not guarantee to report the same exception that would be encountered by a straightforward sequential execution of the program. In exchange, they offer increased performance or decreased chip area (which amount to much the same thing).This performance/precision tradeoff has not so far been much explored at the programming language level. In this paper we propose a design for imprecise exceptions in the lazy functional programming language Haskell. We discuss several designs, and conclude that imprecision is essential if the language is still to enjoy its current rich algebra of transformations. We sketch a precise semantics for the language extended with exceptions.The paper shows how to extend Haskell with exceptions without crippling the language or its compilers. We do not yet have enough experience of using the new mechanism to know whether it strikes an appropriate balance between expressiveness and performance.},
  booktitle = {Proceedings of the ACM SIGPLAN 1999 Conference on Programming Language Design and Implementation},
  pages = {25–36},
  numpages = {12},
  location = {Atlanta, Georgia, USA},
  series = {PLDI '99}
}

@article{Sestoft:97,
  title={Deriving a lazy abstract machine},
  volume={7},
  DOI={10.1017/S0956796897002712},
  number={3},
  journal={Journal of Functional Programming},
  publisher={Cambridge University Press},
  author={Sestoft, Peter},
  year={1997},
  pages={231–264}
}

@book{Nielson:99,
  author    = {Flemming Nielson and
               Hanne Riis Nielson and
               Chris Hankin},
  title     = {Principles of program analysis},
  publisher = {Springer},
  year      = {1999},
  url       = {https://doi.org/10.1007/978-3-662-03811-6},
  doi       = {10.1007/978-3-662-03811-6},
  isbn      = {978-3-540-65410-0},
  timestamp = {Tue, 16 May 2017 01:00:00 +0200},
  biburl    = {https://dblp.org/rec/books/daglib/0098888.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{Cousot:21,
  title={Principles of Abstract Interpretation},
  author={Cousot, Patrick},
  isbn={9780262044905},
  lccn={2020041256},
  url={https://mitpress.mit.edu/9780262044905/principles-of-abstract-interpretation/},
  year={2021},
  publisher={MIT Press}
}

@techreport{Scott:70,
  title = "Outline of a Mathematical Theory of Computation",
  author = "Dana Scott",
  year = "1970",
  institution = "OUCL",
  month = "November",
  number = "PRG02",
  pages = "30",
}

@techreport{ScottStrachey:71,
  title = "Toward a Mathematical Semantics for Computer Languages",
  author = "Dana Scott and Christopher Strachey",
  year = "1971",
  institution = "OUCL",
  month = "August",
  number = "PRG06",
  pages = "49",
}

@inproceedings{Shivers:91,
  Author = {Shivers, Olin Grigsby},
  Title = {Control-Flow Analysis of Higher-Order Languages or Taming Lambda},
  School = {Carnige-Mellon Univeristy},
  Month = {May},
  Year = {1991}
}

@inproceedings{aam,
  author = {Van Horn, David and Might, Matthew},
  title = {Abstracting Abstract Machines},
  year = {2010},
  isbn = {9781605587943},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/1863543.1863553},
  doi = {10.1145/1863543.1863553},
  abstract = {We describe a derivational approach to abstract interpretation that yields novel and transparently sound static analyses when applied to well-established abstract machines. To demonstrate the technique and support our claim, we transform the CEK machine of Felleisen and Friedman, a lazy variant of Krivine's machine, and the stack-inspecting CM machine of Clements and Felleisen into abstract interpretations of themselves. The resulting analyses bound temporal ordering of program events; predict return-flow and stack-inspection behavior; and approximate the flow and evaluation of by-need parameters. For all of these machines, we find that a series of well-known concrete machine refactorings, plus a technique we call store-allocated continuations, leads to machines that abstract into static analyses simply by bounding their stores. We demonstrate that the technique scales up uniformly to allow static analysis of realistic language features, including tail calls, conditionals, side effects, exceptions, first-class continuations, and even garbage collection.},
  booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
  pages = {51–62},
  numpages = {12},
  keywords = {abstract machines, abstract interpretation},
  location = {Baltimore, Maryland, USA},
  series = {ICFP '10}
}

@article{adi,
  author = {Darais, David and Labich, Nicholas and Nguyen, Ph\'{u}c C. and Van Horn, David},
  title = {Abstracting Definitional Interpreters (Functional Pearl)},
  year = {2017},
  issue_date = {September 2017},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {1},
  number = {ICFP},
  url = {https://doi.org/10.1145/3110256},
  doi = {10.1145/3110256},
  abstract = {In this functional pearl, we examine the use of definitional interpreters as a basis for abstract interpretation of higher-order programming languages. As it turns out, definitional interpreters, especially those written in monadic style, can provide a nice basis for a wide variety of collecting semantics, abstract interpretations, symbolic executions, and their intermixings. But the real insight of this story is a replaying of an insight from Reynold's landmark paper, Definitional Interpreters for Higher-Order Programming Languages, in which he observes definitional interpreters enable the defined-language to inherit properties of the defining-language. We show the same holds true for definitional abstract interpreters. Remarkably, we observe that abstract definitional interpreters can inherit the so-called “pushdown control flow” property, wherein function calls and returns are precisely matched in the abstract semantics, simply by virtue of the function call mechanism of the defining-language. The first approaches to achieve this property for higher-order languages appeared within the last ten years, and have since been the subject of many papers. These approaches start from a state-machine semantics and uniformly involve significant technical engineering to recover the precision of pushdown control flow. In contrast, starting from a definitional interpreter, the pushdown control flow property is inherent in the meta-language and requires no further technical mechanism to achieve.},
  journal = {Proc. ACM Program. Lang.},
  month = {aug},
  articleno = {12},
  numpages = {25},
  keywords = {abstract interpreters, interpreters}
}

@inproceedings{Felleisen:87,
  author = {Felleisen, Mattias and Friedman, D. P.},
  title = {A Calculus for Assignments in Higher-Order Languages},
  year = {1987},
  isbn = {0897912152},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/41625.41654},
  doi = {10.1145/41625.41654},
  abstract = {Imperative assignments are abstractions of recurring programming patterns in purely functional programming languages. When added to higher-order functional languages, they provide a higher-level of modularity and security but invalidate the simple substitution semantics. We show that, given an operational interpretation of a denotational semantics for such a language, it is possible to design a two-level extension of the λu-calculus. This calculus provides a location-free rewriting semantics of the language and offers new possibilities for reasoning with assignments. The upper level of the calculus factors out all the steps in a reduction sequence which must be in a linear order; the lower level allows a partial ordering of reduction steps.},
  booktitle = {Proceedings of the 14th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
  pages = {314},
  location = {Munich, West Germany},
  series = {POPL '87}
}

@article{cardinality-ext,
  title={Modular, higher order cardinality analysis in theory and practice},
  volume={27},
  DOI={10.1017/S0956796817000016},
  journal={Journal of Functional Programming},
  publisher={Cambridge University Press},
  author={Sergey, Ilya and Vytiniotis, Dimitrios and Peyton Jones, Simon and Breitner, Joachim},
  year={2017},
  pages={e11}
}

@inproceedings{Ariola:95,
  author = {Ariola, Zena M. and Maraist, John and Odersky, Martin and Felleisen, Matthias and Wadler, Philip},
  title = {A Call-by-Need Lambda Calculus},
  year = {1995},
  isbn = {0897916921},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/199448.199507},
  doi = {10.1145/199448.199507},
  abstract = {The mismatch between the operational semantics of the lambda calculus and the actual behavior of implementations is a major obstacle for compiler writers. They cannot explain the behavior of their evaluator in terms of source level syntax, and they cannot easily compare distinct implementations of different lazy strategies. In this paper we derive an equational characterization of call-by-need and prove it correct with respect to the original lambda calculus. The theory is a strictly smaller theory than the lambda calculus. Immediate applications of the theory concern the correctness proofs of a number of implementation strategies, e.g., the call-by-need continuation passing transformation and the realization of sharing via assignments.},
  booktitle = {Proceedings of the 22nd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  pages = {233–246},
  numpages = {14},
  location = {San Francisco, California, USA},
  series = {POPL '95}
}

@inproceedings{Atkey:18,
  author = {Atkey, Robert},
  title = {Syntax and Semantics of Quantitative Type Theory},
  year = {2018},
  isbn = {9781450355834},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3209108.3209189},
  doi = {10.1145/3209108.3209189},
  abstract = {We present Quantitative Type Theory, a Type Theory that records usage information for each variable in a judgement, based on a previous system by McBride. The usage information is used to give a realizability semantics using a variant of Linear Combinatory Algebras, refining the usual realizability semantics of Type Theory by accurately tracking resource behaviour. We define the semantics in terms of Quantitative Categories with Families, a novel extension of Categories with Families for modelling resource sensitive type theories.},
  booktitle = {Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science},
  pages = {56–65},
  numpages = {10},
  keywords = {Type Theory, Linear Logic},
  location = {Oxford, United Kingdom},
  series = {LICS '18}
}

@inproceedings{Launchbury:93,
  author = {Launchbury, John},
  title = {A Natural Semantics for Lazy Evaluation},
  year = {1993},
  isbn = {0897915607},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/158511.158618},
  doi = {10.1145/158511.158618},
  abstract = {We define an operational semantics for lazy evaluation which provides an accurate model for sharing. The only computational structure we introduce is a set of bindings which corresponds closely to a heap. The semantics is set at a considerably higher level of abstraction than operational semantics for particular abstract machines, so is more suitable for a variety of proofs. Furthermore, because a heap is explicitly modelled, the semantics provides a suitable framework for studies about space behaviour of terms under lazy evaluation.},
  booktitle = {Proceedings of the 20th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  pages = {144–154},
  numpages = {11},
  location = {Charleston, South Carolina, USA},
  series = {POPL '93}
}

@article{AgerDanvyMidtgaard:04,
  title = {A functional correspondence between call-by-need evaluators and lazy abstract machines},
  journal = {Information Processing Letters},
  volume = {90},
  number = {5},
  pages = {223-232},
  year = {2004},
  issn = {0020-0190},
  doi = {https://doi.org/10.1016/j.ipl.2004.02.012},
  url = {https://www.sciencedirect.com/science/article/pii/S0020019004000638},
  author = {Mads Sig Ager and Olivier Danvy and Jan Midtgaard},
  keywords = {Functional programming, Program derivation, Interpreters, Abstract machines, Closure conversion, CPS transformation, Defunctionalization},
  abstract = {We bridge the gap between compositional evaluators and abstract machines for the lambda-calculus, using closure conversion, transformation into continuation-passing style, and defunctionalization of continuations. This article is a followup of our article at PPDP 2003, where we consider call by name and call by value. Here, however, we consider call by need. We derive a lazy abstract machine from an ordinary call-by-need evaluator that threads a heap of updatable cells. In this resulting abstract machine, the continuation fragment for updating a heap cell naturally appears as an ‘update marker’, an implementation technique that was invented for the Three Instruction Machine and subsequently used to construct lazy variants of Krivine's abstract machine. Tuning the evaluator leads to other implementation techniques such as unboxed values. The correctness of the resulting abstract machines is a corollary of the correctness of the original evaluators and of the program transformations used in the derivation.}
}

@article{Milner:78,
  title = {A theory of type polymorphism in programming},
  journal = {Journal of Computer and System Sciences},
  volume = {17},
  number = {3},
  pages = {348-375},
  year = {1978},
  issn = {0022-0000},
  doi = {https://doi.org/10.1016/0022-0000(78)90014-4},
  url = {https://www.sciencedirect.com/science/article/pii/0022000078900144},
  author = {Robin Milner},
  abstract = {The aim of this work is largely a practical one. A widely employed style of programming, particularly in structure-processing languages which impose no discipline of types, entails defining procedures which work well on objects of a wide variety. We present a formal type discipline for such polymorphic procedures in the context of a simple programming language, and a compile time type-checking algorithm W which enforces the discipline. A Semantic Soundness Theorem (based on a formal semantics for the language) states that well-type programs cannot “go wrong” and a Syntactic Soundness Theorem states that if W accepts a program then it is well typed. We also discuss extending these results to richer languages; a type-checking algorithm based on W is in fact already implemented and working, for the metalanguage ML in the Edinburgh LCF system.}
}

@article{Plotkin:77,
  title = {LCF considered as a programming language},
  journal = {Theoretical Computer Science},
  volume = {5},
  number = {3},
  pages = {223-255},
  year = {1977},
  issn = {0304-3975},
  doi = {https://doi.org/10.1016/0304-3975(77)90044-5},
  url = {https://www.sciencedirect.com/science/article/pii/0304397577900445},
  author = {G.D. Plotkin},
  abstract = {The paper studies connections between denotational and operational semantics for a simple programming language based on LCF. It begins with the connection between the behaviour of a program and its denotation. It turns out that a program denotes ⊥ in any of several possible semantics if it does not terminate. From this it follows that if two terms have the same denotation in one of these semantics, they have the same behaviour in all contexts. The converse fails for all the semantics. If, however, the language is extended to allow certain parallel facilities behavioural equivalence does coincide with denotational equivalence in one of the semantics considered, which may therefore be called “fully abstract”. Next a connection is given which actually determines the semantics up to isomorphism from the behaviour alone. Conversely, by allowing further parallel facilities, every r.e. element of the fully abstract semantics becomes definable, thus characterising the programming language, up to interdefinability, from the set of r.e. elements of the domains of the semantics.}
}

@article{Plotkin:81,
    title = {A structural approach to operational semantics},
    volume = {60-61},
    issn = {15678326},
    url = {https://linkinghub.elsevier.com/retrieve/pii/S1567832604000402},
    doi = {10.1016/j.jlap.2004.05.001},
    journal = {The Journal of Logic and Algebraic Programming},
    author = {Plotkin, Gordon D.},
    year = {2004},
    pages = {17--139}
}

@inproceedings{Johnsson:84,
  author = {Johnsson, Thomas},
  title = {Efficient Compilation of Lazy Evaluation},
  year = {1984},
  isbn = {0897911393},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/502874.502880},
  doi = {10.1145/502874.502880},
  abstract = {This paper describes the principles underlying an efficient implementation of a lazy functional language, compiling to code for ordinary computers. It is based on combinator-like graph reduction: the user defined functions are used as rewrite rules in the graph. Each function is compiled into an instruction sequence for an abstract graph reduction machine, called the G-machine, the code reduces a function application graph to its value. The G-machine instructions are then translated into target code. Speed improvements by almost two orders of magnitude over previous lazy evaluators have been measured; we provide some performance figures.},
  booktitle = {Proceedings of the 1984 SIGPLAN Symposium on Compiler Construction},
  pages = {58–69},
  numpages = {12},
  location = {Montreal, Canada},
  series = {SIGPLAN '84}
}

@article{SPJ:92,
  author = {Jones, Peyton and L, Simon and Peyton Jones, Simon},
  title = {Implementing Lazy Functional Languages on Stock Hardware: The Spineless Tagless G-machine},
  year = {1992},
  month = {July},
  abstract = {The Spineless Tagless G-machine is an abstract machine designed to support non- strict higher-order functional languages. This presentation of the machine falls into three parts. Firstly, we give a general discussion of the design issues involved in implementing non-strict functional languages.
  Next, we present the STG language, an austere but recognisably-functional language, which as well as a denotational meaning has a well-defined operational semantics. The STG language is the \abstract machine code" for the Spineless Tagless G-machine.
  Lastly, we discuss the mapping of the STG language onto stock hardware. The success of an abstract machine model depends largely on how efficient this mapping can be made, though this topic is often relegated to a short section. Instead, we give a detailed discussion of the design issues and the choices we have made. Our principal target is the C language, treating the C compiler as a portable assembler.},
  publisher = {Cambridge University Press},
  url = {https://www.microsoft.com/en-us/research/publication/implementing-lazy-functional-languages-on-stock-hardware-the-spineless-tagless-g-machine/},
  pages = {127-202},
  journal = {Journal of Functional Programming},
  volume = {2},
  edition = {Journal of Functional Programming},
}

@article{LeroyGrall:09,
  title = {Coinductive big-step operational semantics},
  journal = {Information and Computation},
  volume = {207},
  number = {2},
  pages = {284-304},
  year = {2009},
  note = {Special issue on Structural Operational Semantics (SOS)},
  issn = {0890-5401},
  doi = {https://doi.org/10.1016/j.ic.2007.12.004},
  url = {https://www.sciencedirect.com/science/article/pii/S0890540108001296},
  author = {Xavier Leroy and Hervé Grall},
  keywords = {Coinduction, Operational semantics, Big-step semantics, Natural semantics, Small-step semantics, Reduction semantics, Type soundness, Compiler correctness, Mechanized proofs, The Coq proof assistant},
  abstract = {Using a call-by-value functional language as an example, this article illustrates the use of coinductive definitions and proofs in big-step operational semantics, enabling it to describe diverging evaluations in addition to terminating evaluations. We formalize the connections between the coinductive big-step semantics and the standard small-step semantics, proving that both semantics are equivalent. We then study the use of coinductive big-step semantics in proofs of type soundness and proofs of semantic preservation for compilers. A methodological originality of this paper is that all results have been proved using the Coq proof assistant. We explain the proof-theoretic presentation of coinductive definitions and proofs offered by Coq, and show that it facilitates the discovery and the presentation of the results.}
}

@article{WrightFelleisen:94,
  title = {A Syntactic Approach to Type Soundness},
  journal = {Information and Computation},
  volume = {115},
  number = {1},
  pages = {38-94},
  year = {1994},
  issn = {0890-5401},
  doi = {https://doi.org/10.1006/inco.1994.1093},
  url = {https://www.sciencedirect.com/science/article/pii/S0890540184710935},
  author = {A.K. Wright and M. Felleisen},
  abstract = {We present a new approach to proving type soundness for Hindley/Milner-style polymorphic type systems. The keys to our approach are (1) an adaptation of subject reduction theorems from combinatory logic to programming languages, and (2) the use of rewriting techniques for the specification of the language semantics. The approach easily extends from polymorphic functional languages to imperative languages that provide references, exceptions, continuations, and similar features. We illustrate the technique with a type soundness theorem for the core of Standard ML, which includes the first type soundness proof for polymorphic exceptions and continuations.}
}

@article{Cousot:02,
  title = {Constructive design of a hierarchy of semantics of a transition system by abstract interpretation},
  journal = {Theoretical Computer Science},
  volume = {277},
  number = {1},
  pages = {47-103},
  year = {2002},
  note = {Static Analysis},
  issn = {0304-3975},
  doi = {https://doi.org/10.1016/S0304-3975(00)00313-3},
  url = {https://www.sciencedirect.com/science/article/pii/S0304397500003133},
  author = {Patrick Cousot},
  abstract = {We construct a hierarchy of semantics by successive abstract interpretations. Starting from the maximal trace semantics of a transition system, we derive the big-step semantics, termination and nontermination semantics, Plotkin's natural, Smyth's demoniac and Hoare's angelic relational semantics and equivalent nondeterministic denotational semantics (with alternative powerdomains to the Egli–Milner and Smyth constructions), D. Scott's deterministic denotational semantics, the generalized and Dijkstra's conservative/liberal predicate transformer semantics, the generalized/total and Hoare's partial correctness axiomatic semantics and the corresponding proof methods. All the semantics are presented in a uniform fixpoint form and the correspondences between these semantics are established through composable Galois connections, each semantics being formally calculated by abstract interpretation of a more concrete one using Kleene and/or Tarski fixpoint approximation transfer theorems.}
}

@article{AppelMcAllester:01,
  author = {Appel, Andrew W. and McAllester, David},
  title = {An Indexed Model of Recursive Types for Foundational Proof-Carrying Code},
  year = {2001},
  issue_date = {September 2001},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {23},
  number = {5},
  issn = {0164-0925},
  url = {https://doi.org/10.1145/504709.504712},
  doi = {10.1145/504709.504712},
  abstract = {The proofs of "traditional" proof carrying code (PCC) are type-specialized in the sense that they require axioms about a specific type system. In contrast, the proofs of foundational PCC explicitly define all required types and explicitly prove all the required properties of those types assuming only a fixed foundation of mathematics such as higher-order logic. Foundational PCC is both more flexible and more secure than type-specialized PCC.For foundational PCC we need semantic models of type systems on von Neumann machines. Previous models have been either too weak (lacking general recursive types and first-class function-pointers), too complex (requiring machine-checkable proofs of large bodies of computability theory), or not obviously applicable to von Neumann machines. Our new model is strong, simple, and works either in λ-calculus or on Pentiums.},
  journal = {ACM Trans. Program. Lang. Syst.},
  month = {sep},
  pages = {657–683},
  numpages = {27}
}

@article{DreyerAhmedBirkedal:11,
  author       = {Derek Dreyer and
                  Amal Ahmed and
                  Lars Birkedal},
  title        = {Logical Step-Indexed Logical Relations},
  journal      = {Log. Methods Comput. Sci.},
  volume       = {7},
  number       = {2},
  year         = {2011},
  url          = {https://doi.org/10.2168/LMCS-7(2:16)2011},
  doi          = {10.2168/LMCS-7(2:16)2011},
  timestamp    = {Sun, 16 Apr 2023 20:31:20 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1103-0510.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{ClarksonSchneider:10,
  author = {Clarkson, Michael R. and Schneider, Fred B.},
  title = {Hyperproperties},
  year = {2010},
  issue_date = {September 2010},
  publisher = {IOS Press},
  address = {NLD},
  volume = {18},
  number = {6},
  issn = {0926-227X},
  abstract = {Trace properties, which have long been used for reasoning about systems, are sets of execution traces. Hyperproperties, introduced here, are sets of trace properties. Hyperproperties can express security policies, such as secure information flow and service level agreements, that trace properties cannot. Safety and liveness are generalized to hyperproperties, and every hyperproperty is shown to be the intersection of a safety hyperproperty and a liveness hyperproperty. A verification technique for safety hyperproperties is given and is shown to generalize prior techniques for verifying secure information flow. Refinement is shown to be applicable with safety hyperproperties. A topological characterization of hyperproperties is given.},
  journal = {J. Comput. Secur.},
  month = {sep},
  pages = {1157–1210},
  numpages = {54},
  keywords = {liveness, safety, Security policies, information flow}
}

@book{Abramsky:94,
  author       = {Samson Abramsky and
                  Dov M. Gabbay and
                  T. S. E. Maibaum},
  title        = {Handbook of logic in computer science. Volume 3. Semantic Structures},
  publisher    = {Clarendon Press},
  year         = {1994},
  url          = {https://global.oup.com/academic/product/handbook-of-logic-in-computer-science-9780198537625},
  isbn         = {019853762X},
  timestamp    = {Tue, 16 Mar 2021 16:16:12 +0100},
  biburl       = {https://dblp.org/rec/books/lib/Abramsky94.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Nakano:00,
  author = {Nakano, Hiroshi},
  title = {A Modality for Recursion},
  year = {2000},
  isbn = {0769507255},
  publisher = {IEEE Computer Society},
  address = {USA},
  abstract = {We propose a modal logic that enables us to handle self-referential formulae, including ones with negative self-references, which on one hand, would introduce a logical contradiction, namely Russell's paradox, in the conventional setting, while on the other hand, are necessary to capture a certain class of programs such as fixed point combinators and objects with so-called binary methods in object-oriented programming. Our logic provides a basis for axiomatic semantics of such a wider range of programs and a new framework for natural construction of recursive programs in the proofs-as-programs paradigm.},
  booktitle = {Proceedings of the 15th Annual IEEE Symposium on Logic in Computer Science},
  pages = {255},
  keywords = {Logics of Programs, Lambda and Combinatory Caluculi, Type Systems and Type Theory, Specifications, Modal and Temporal Logics},
  series = {LICS '00}
}

@inproceedings{gdtt,
  author="Bizjak, Ale{\v{s}} and Grathwohl, Hans Bugge and Clouston, Ranald and M{\o}gelberg, Rasmus E. and Birkedal, Lars", editor="Jacobs, Bart and L{\"o}ding, Christof",
  title="Guarded Dependent Type Theory with Coinductive Types",
  booktitle="Foundations of Software Science and Computation Structures",
  year="2016",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="20--35",
  isbn="978-3-662-49630-5"
}

@inproceedings{Coquand:94,
  author="Coquand, Thierry",
  editor="Barendregt, Henk
  and Nipkow, Tobias",
  title="Infinite objects in type theory",
  booktitle="Types for Proofs and Programs",
  year="1994",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="62--78",
  abstract="We show that infinite objects can be constructively understood without the consideration of partial elements, or greatest fixed-points, through the explicit consideration of proof objects. We present then a proof system based on these explanations. According to this analysis, the proof expressions should have the same structure as the program expressions of a pure functional lazy language: variable, constructor, application, abstraction, case expressions, and local let expressions.",
  isbn="978-3-540-48440-0"
}

@inproceedings{BirkedalMogelbergEjlers:13,
  author = {Birkedal, Lars and Mogelberg, Rasmus Ejlers},
  title = {Intensional Type Theory with Guarded Recursive Types qua Fixed Points on Universes},
  year = {2013},
  isbn = {9780769550206},
  publisher = {IEEE Computer Society},
  address = {USA},
  url = {https://doi.org/10.1109/LICS.2013.27},
  doi = {10.1109/LICS.2013.27},
  booktitle = {Proceedings of the 2013 28th Annual ACM/IEEE Symposium on Logic in Computer Science},
  pages = {213–222},
  numpages = {10},
  series = {LICS '13}
}

@article{Moggi:07,
  title = {Structuring Operational Semantics: Simplification and Computation},
  journal = {Electronic Notes in Theoretical Computer Science},
  volume = {172},
  pages = {479-497},
  year = {2007},
  note = {Computation, Meaning, and Logic: Articles dedicated to Gordon Plotkin},
  issn = {1571-0661},
  doi = {https://doi.org/10.1016/j.entcs.2007.02.016},
  url = {https://www.sciencedirect.com/science/article/pii/S1571066107000898},
  author = {Eugenio Moggi},
  keywords = {Operational Semantics, Confluent Rewriting, Multiset Rewriting},
}

@article{McBridePaterson:08,
  title={Applicative programming with effects},
  volume={18},
  DOI={10.1017/S0956796807006326},
  number={1},
  journal={Journal of Functional Programming},
  publisher={Cambridge University Press},
  author={McBride, Conor and Paterson, Ross},
  year={2008},
  pages={1–13}
}

@inproceedings{Reynolds:72,
  author = {Reynolds, John C.},
  title = {Definitional Interpreters for Higher-Order Programming Languages},
  year = {1972},
  isbn = {9781450374927},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/800194.805852},
  doi = {10.1145/800194.805852},
  abstract = {Higher-order programming languages (i.e., languages in which procedures or labels can occur as values) are usually defined by interpreters which are themselves written in a programming language based on the lambda calculus (i.e., an applicative language such as pure LISP). Examples include McCarthy's definition of LISP, Landin's SECD machine, the Vienna definition of PL/I, Reynolds' definitions of GEDANKEN, and recent unpublished work by L. Morris and C. Wadsworth. Such definitions can be classified according to whether the interpreter contains higher-order functions, and whether the order of application (i.e., call-by-value versus call-by-name) in the defined language depends upon the order of application in the defining language. As an example, we consider the definition of a simple applicative programming language by means of an interpreter written in a similar language. Definitions in each of the above classifications are derived from one another by informal but constructive methods. The treatment of imperative features such as jumps and assignment is also discussed.},
  booktitle = {Proceedings of the ACM Annual Conference - Volume 2},
  pages = {717–740},
  numpages = {24},
  keywords = {GEDANKEN, Lambda calculus, Continuation, Language definition, SECD machine, Higher-order function, PAL, Interpreter, Order of application, Closure, LISP, Programming language, Applicative language, J-operator, Reference},
  location = {Boston, Massachusetts, USA},
  series = {ACM '72}
}

@article{tctt,
  author = {M\o{}gelberg, Rasmus Ejlers and Veltri, Niccol\`{o}},
  title = {Bisimulation as Path Type for Guarded Recursive Types},
  year = {2019},
  issue_date = {January 2019},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {3},
  number = {POPL},
  url = {https://doi.org/10.1145/3290317},
  doi = {10.1145/3290317},
  abstract = {In type theory, coinductive types are used to represent processes, and are thus crucial for the formal verification of non-terminating reactive programs in proof assistants based on type theory, such as Coq and Agda. Currently, programming and reasoning about coinductive types is difficult for two reasons: The need for recursive definitions to be productive, and the lack of coincidence of the built-in identity types and the important notion of bisimilarity. Guarded recursion in the sense of Nakano has recently been suggested as a possible approach to dealing with the problem of productivity, allowing this to be encoded in types. Indeed, coinductive types can be encoded using a combination of guarded recursion and universal quantification over clocks. This paper studies the notion of bisimilarity for guarded recursive types in Ticked Cubical Type Theory, an extension of Cubical Type Theory with guarded recursion. We prove that, for any functor, an abstract, category theoretic notion of bisimilarity for the final guarded coalgebra is equivalent (in the sense of homotopy type theory) to path equality (the primitive notion of equality in cubical type theory). As a worked example we study a guarded notion of labelled transition systems, and show that, as a special case of the general theorem, path equality coincides with an adaptation of the usual notion of bisimulation for processes. In particular, this implies that guarded recursion can be used to give simple equational reasoning proofs of bisimilarity. This work should be seen as a step towards obtaining bisimilarity as path equality for coinductive types using the encodings mentioned above.},
  journal = {Proc. ACM Program. Lang.},
  month = {jan},
  articleno = {4},
  numpages = {29},
  keywords = {cubical type theory, Dependent types, bisimulation, guarded recursion, homotopy type theory, coinductive types, labelled transition systems, CCS}
}

@inproceedings{gca,
  author = {Veltri, Niccol\`{o} and Vezzosi, Andrea},
  title = {Formalizing $\pi$-Calculus in Guarded Cubical Agda},
  year = {2020},
  isbn = {9781450370974},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3372885.3373814},
  doi = {10.1145/3372885.3373814},
  abstract = {Dependent type theories with guarded recursion have shown themselves suitable for the development of denotational semantics of programming languages. In particular Ticked Cubical Type Theory (TCTT) has been used to show that for guarded labelled transition systems (GLTS) interpretation into the denotational semantics maps bisimilar processes to equal values. In fact the two notions are proved equivalent, allowing one to reason about equality in place of bisimilarity. We extend that result to the π-calculus, picking early congruence as the syntactic notion of equivalence between processes, showing that denotational models based on guarded recursive types can handle the dynamic creation of channels that goes beyond the scope of GLTSs. Hence we present a fully abstract denotational model for the early π-calculus, formalized as an extended example for Guarded Cubical Agda: a novel implementation of Ticked Cubical Type Theory based on Cubical Agda.},
  booktitle = {Proceedings of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs},
  pages = {270–283},
  numpages = {14},
  keywords = {denotational semantics, pi-calculus, ticked cubical type theory, guarded recursion},
  location = {New Orleans, LA, USA},
  series = {CPP 2020}
}

@inproceedings{MoranSands:99,
  author = {Moran, Andrew and Sands, David},
  title = {Improvement in a Lazy Context: An Operational Theory for Call-by-Need},
  year = {1999},
  isbn = {1581130953},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/292540.292547},
  doi = {10.1145/292540.292547},
  abstract = {The standard implementation technique for lazy functional languages is call-by-need, which ensures that an argument to a function in any given call is evaluated at most once. A significant problem with call-by-need is that it is difficult -- even for compiler writers -- to predict the effects of program transformations. The traditional theories for lazy functional languages are based on call-by-name models, and offer no help in determining which transformations do indeed optimize a program.In this article we present an operational theory for call-by-need, based upon an improvement ordering on programs: M is improved by N if in all program-contexts C, when C[M] terminates then C[N] terminates at least as cheaply.We show that this improvement relation satisfies a "context lemma", and supports a rich inequational theory, subsuming the call-by-need lambda calculi of Ariola et al. [AFM+95]. The reduction-based call-by-need calculi are inadequate as a theory of lazy-program transformation since they only permit transformations which speed up programs by at most a constant factor (a claim we substantiate); we go beyond the various reduction-based calculi for call-by-need by providing powerful proof rules for recursion, including syntactic continuity -- the basis of fixed-point-induction style reasoning, and an improvement theorem, suitable for arguing the correctness and safety of recursion-based program transformations.},
  booktitle = {Proceedings of the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  pages = {43–56},
  numpages = {14},
  location = {San Antonio, Texas, USA},
  series = {POPL '99}
}

@inbook{MarlowJones:12,
  author = {Marlow, Simon and Peyton Jones, Simon},
  title = {The Glasgow Haskell Compiler},
  booktitle = {The Architecture of Open Source Applications, Volume 2},
  year = {2012},
  month = {January},
  abstract = {The Glasgow Haskell Compiler (GHC) started as part of an academic research project funded by the UK government at the beginning of the 1990’s, with several goals in mind:

   	To make freely available a robust and portable compiler for Haskell that generates high performance code;
   	To provide a modular foundation that other researchers can extend and develop;
   	To learn how real programs behave, so that we can design and build better compilers.

  GHC is now over 20 years old, and has been under continuous active development since its inception. Today, GHC releases are downloaded by hundreds of thousands of people, the online repository of Haskell libraries has over 3,000 packages, GHC is used to teach Haskell in many undergraduate courses, and there are a growing number of instances of Haskell being depended upon commercially.},
  publisher = {Lulu},
  url = {https://www.microsoft.com/en-us/research/publication/the-glasgow-haskell-compiler/},
  edition = {The Architecture of Open Source Applications, Volume 2},
}

@inproceedings{Gustavsson:98,
  author = {Gustavsson, J\"{o}rgen},
  title = {A Type Based Sharing Analysis for Update Avoidance and Optimisation},
  year = {1998},
  isbn = {1581130244},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/289423.289427},
  doi = {10.1145/289423.289427},
  abstract = {Sharing of evaluation is crucial for the efficiency of lazy functional languages, but unfortunately the machinery to implement it carries an inherent overhead. In abstract machines this overhead shows up as the cost of performing updates, many of them actually unnecessary, and also in the cost of the associated bookkeeping, that is keeping track of when and where to update. In spineless abstract machines, such as the STG-machine and the TIM, this bookkeeping consists of pushing, checking for and popping update markers. Checking for update markers is a very frequent operation and indeed the implementation of the STG-machine has been optimised for fast update marker checks at the expense of making the pushing and popping of update markers more costly.In this paper we present a type based sharing analysis that can determine when updates can be safely omitted and marker checks bypassed. The type system is proved sound with respect to the lazy Krivine machine. We have implemented the analysis and the preliminary benchmarks seem very promising. Most notably, virtually all update marker checks can be avoided. This may make the tradeoffs of current implementations obsolete and calls for new abstract machine designs.},
  booktitle = {Proceedings of the Third ACM SIGPLAN International Conference on Functional Programming},
  pages = {39–50},
  numpages = {12},
  location = {Baltimore, Maryland, USA},
  series = {ICFP '98}
}

@article{Birkedal:12,
  TITLE = {{First steps in synthetic guarded domain theory: step-indexing in the
  topos of trees}},
  AUTHOR = {Lars Birkedal and Rasmus Ejlers Møgelberg and Jan Schwinghammer and Kristian Støvring},
  URL = {https://lmcs.episciences.org/1041},
  DOI = {10.2168/LMCS-8(4:1)2012},
  JOURNAL = {{Logical Methods in Computer Science}},
  VOLUME = {{Volume 8, Issue 4}},
  YEAR = {2012},
  MONTH = Oct,
  KEYWORDS = {Computer Science - Logic in Computer Science ; D.3.1 ; F.3.2},
}

@article{Spies:22,
  author = {Spies, Simon and G\"{a}her, Lennard and Tassarotti, Joseph and Jung, Ralf and Krebbers, Robbert and Birkedal, Lars and Dreyer, Derek},
  title = {Later Credits: Resourceful Reasoning for the Later Modality},
  year = {2022},
  issue_date = {August 2022},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {6},
  number = {ICFP},
  url = {https://doi.org/10.1145/3547631},
  doi = {10.1145/3547631},
  abstract = {In the past two decades, step-indexed logical relations and separation logics have both come to play a major role in semantics and verification research. More recently, they have been married together in the form of step-indexed separation logics like VST, iCAP, and Iris, which provide powerful tools for (among other things) building semantic models of richly typed languages like Rust. In these logics, propositions are given semantics using a step-indexed model, and step-indexed reasoning is reflected into the logic through the so-called “later” modality. On the one hand, this modality provides an elegant, high-level account of step-indexed reasoning; on the other hand, when used in sufficiently sophisticated ways, it can become a nuisance, turning perfectly natural proof strategies into dead ends. In this work, we introduce later credits, a new technique for escaping later-modality quagmires. By leveraging the second ancestor of these logics—separation logic—later credits turn “the right to eliminate a later” into an ownable resource, which is subject to all the traditional modular reasoning principles of separation logic. We develop the theory of later credits in the context of Iris, and present several challenging examples of proofs and proof patterns which were previously not possible in Iris but are now possible due to later credits.},
  journal = {Proc. ACM Program. Lang.},
  month = {aug},
  articleno = {100},
  numpages = {29},
  keywords = {Iris, Separation logic, later modality, step-indexing, transfinite}
}

@inproceedings{MontaguJensen:21,
  author = {Montagu, Beno\^{\i}t and Jensen, Thomas},
  title = {Trace-Based Control-Flow Analysis},
  year = {2021},
  isbn = {9781450383912},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3453483.3454057},
  doi = {10.1145/3453483.3454057},
  abstract = {We define a small-step semantics for the untyped λ-calculus, that traces the β-reductions that occur during evaluation. By abstracting the computation traces, we reconstruct k-CFA using abstract interpretation, and justify constraint-based k-CFA in a semantic way. The abstract interpretation of the trace semantics also paves the way for introducing widening operators in CFA that go beyond existing analyses, that are all based on exploring a finite state space. We define ∇CFA, a widening-based analysis that limits the cycles in call stacks, and can achieve better precision than k-CFA at a similar cost.},
  booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  pages = {482–496},
  numpages = {15},
  keywords = {lambda-calculus, control flow analysis, widening, program traces, abstract interpretation},
  location = {Virtual, Canada},
  series = {PLDI 2021}
}

@article{Breitner:18,
  title={The adequacy of Launchbury's natural semantics for lazy evaluation},
  volume={28},
  DOI={10.1017/S0956796817000144},
  journal={Journal of Functional Programming},
  publisher={Cambridge University Press},
  author={Breitner, Joachim},
  year={2018},
  pages={e1}
}

@article{HackettHutton:19,
  author = {Hackett, Jennifer and Hutton, Graham},
  title = {Call-by-Need is Clairvoyant Call-by-Value},
  year = {2019},
  issue_date = {August 2019},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {3},
  number = {ICFP},
  url = {https://doi.org/10.1145/3341718},
  doi = {10.1145/3341718},
  abstract = {Call-by-need evaluation, also known as lazy evaluation, provides two key benefits: compositional programming and infinite data. The standard semantics for laziness is Launchbury’s natural semantics&nbsp;DBLP:conf/popl/Launchbury93, which uses a heap to memoise the results of delayed evaluations. However, the stateful nature of this heap greatly complicates reasoning about the operational behaviour of lazy programs. In this article, we propose an alternative semantics for laziness, clairvoyant evaluation, that replaces the state effect with nondeterminism, and prove this semantics equivalent in a strong sense to the standard semantics. We show how this new semantics greatly simplifies operational reasoning, admitting much simpler proofs of a number of results from the literature, and how it leads to the first denotational cost semantics for lazy evaluation.},
  journal = {Proc. ACM Program. Lang.},
  month = {jul},
  articleno = {114},
  numpages = {23},
  keywords = {lazy evaluation}
}

@article{Mogelberg:21,
  doi = {10.4204/eptcs.351.13},
  url = {https://doi.org/10.4204%2Feptcs.351.13},
  year = 2021,
  month = {dec},
  publisher = {Open Publishing Association},
  volume = {351},
  pages = {200--217},
  author = {Rasmus Ejlers M{\o}gelberg and Andrea Vezzosi},
  title = {Two Guarded Recursive Powerdomains for Applicative Simulation},
  journal = {Electronic Proceedings in Theoretical Computer Science}
}

@article{interaction-trees,
  author = {Xia, Li-yao and Zakowski, Yannick and He, Paul and Hur, Chung-Kil and Malecha, Gregory and Pierce, Benjamin C. and Zdancewic, Steve},
  title = {Interaction Trees: Representing Recursive and Impure Programs in Coq},
  year = {2019},
  issue_date = {January 2020},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {4},
  number = {POPL},
  url = {https://doi.org/10.1145/3371119},
  doi = {10.1145/3371119},
  abstract = {Interaction trees (ITrees) are a general-purpose data structure for representing the behaviors of recursive programs that interact with their environments. A coinductive variant of “free monads,” ITrees are built out of uninterpreted events and their continuations. They support compositional construction of interpreters from event handlers, which give meaning to events by defining their semantics as monadic actions. ITrees are expressive enough to represent impure and potentially nonterminating, mutually recursive computations, while admitting a rich equational theory of equivalence up to weak bisimulation. In contrast to other approaches such as relationally specified operational semantics, ITrees are executable via code extraction, making them suitable for debugging, testing, and implementing software artifacts that are amenable to formal verification. We have implemented ITrees and their associated theory as a Coq library, mechanizing classic domain- and category-theoretic results about program semantics, iteration, monadic structures, and equational reasoning. Although the internals of the library rely heavily on coinductive proofs, the interface hides these details so that clients can use and reason about ITrees without explicit use of Coq’s coinduction tactics. To showcase the utility of our theory, we prove the termination-sensitive correctness of a compiler from a simple imperative source language to an assembly-like target whose meanings are given in an ITree-based denotational semantics. Unlike previous results using operational techniques, our bisimulation proof follows straightforwardly by structural induction and elementary rewriting via an equational theory of combinators for control-flow graphs.},
  journal = {Proc. ACM Program. Lang.},
  month = {dec},
  articleno = {51},
  numpages = {32},
  keywords = {Coq, coinduction, monads, compiler correctness}
}

@inproceedings{Reynolds:02,
  author={Reynolds, J.C.},
  booktitle={Proceedings 17th Annual IEEE Symposium on Logic in Computer Science},
  title={Separation logic: a logic for shared mutable data structures},
  year={2002},
  volume={},
  number={},
  pages={55-74},
  doi={10.1109/LICS.2002.1029817}
}

@phdthesis{Morris:69,
  author  = "Morris, James Hiram Jr",
  title   = "Lambda-calculus models of programming languages",
  school  = "Massachusetts Institute of Technology",
  year    = "1969",
}

@article{Lamport:77,
  author={Lamport, L.},
  journal={IEEE Transactions on Software Engineering},
  title={Proving the Correctness of Multiprocess Programs},
  year={1977},
  volume={SE-3},
  number={2},
  pages={125-143},
  doi={10.1109/TSE.1977.229904}
}

@article{Capretta:05,
  TITLE = {{General Recursion via Coinductive Types}},
  AUTHOR = {Venanzio Capretta},
  URL = {http://lmcs.episciences.org/2265},
  DOI = {10.2168/LMCS-1(2:1)2005},
  JOURNAL = {{Logical Methods in Computer Science}},
  VOLUME = {{Volume 1, Issue 2}},
  YEAR = {2005},
  MONTH = Jul,
  KEYWORDS = {Computer Science - Logic in Computer Science ; F.3.1},
}

@inproceedings{Carette:07,
  author="Carette, Jacques
  and Kiselyov, Oleg
  and Shan, Chung-chieh",
  editor="Shao, Zhong",
  title="Finally Tagless, Partially Evaluated",
  booktitle="Programming Languages and Systems",
  year="2007",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="222--238",
  abstract="We have built the first family of tagless interpretations for a higher-order typed object language in a typed metalanguage (Haskell or ML) that require no dependent types, generalized algebraic data types, or postprocessing to eliminate tags. The statically type-preserving interpretations include an evaluator, a compiler (or staged evaluator), a partial evaluator, and call-by-name and call-by-value CPS transformers.",
  isbn="978-3-540-76637-7"
}

@article{Keidel:18,
  author = {Keidel, Sven and Poulsen, Casper Bach and Erdweg, Sebastian},
  title = {Compositional Soundness Proofs of Abstract Interpreters},
  year = {2018},
  issue_date = {September 2018},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {2},
  number = {ICFP},
  url = {https://doi.org/10.1145/3236767},
  doi = {10.1145/3236767},
  abstract = {Abstract interpretation is a technique for developing static analyses. Yet, proving abstract interpreters sound is challenging for interesting analyses, because of the high proof complexity and proof effort. To reduce complexity and effort, we propose a framework for abstract interpreters that makes their soundness proof compositional. Key to our approach is to capture the similarities between concrete and abstract interpreters in a single shared interpreter, parameterized over an arrow-based interface. In our framework, a soundness proof is reduced to proving reusable soundness lemmas over the concrete and abstract instances of this interface; the soundness of the overall interpreters follows from a generic theorem. To further reduce proof effort, we explore the relationship between soundness and parametricity. Parametricity not only provides us with useful guidelines for how to design non-leaky interfaces for shared interpreters, but also provides us soundness of shared pure functions as free theorems. We implemented our framework in Haskell and developed a k-CFA analysis for PCF and a tree-shape analysis for Stratego. We were able to prove both analyses sound compositionally with manageable complexity and effort, compared to a conventional soundness proof.},
  journal = {Proc. ACM Program. Lang.},
  month = {jul},
  articleno = {72},
  numpages = {26},
  keywords = {Abstract Interpretation, Soundness}
}

@inproceedings{Nakata:10,
  author       = {Keiko Nakata},
  editor       = {Luigi Santocanale},
  title        = {Denotational Semantics for Lazy Initialization of letrec},
  booktitle    = {7th Workshop on Fixed Points in Computer Science, {FICS} 2010, Brno,
                  Czech Republic, August 21-22, 2010},
  pages        = {61--67},
  publisher    = {Laboratoire d'Informatique Fondamentale de Marseille},
  year         = {2010},
  url          = {https://hal.archives-ouvertes.fr/hal-00512377/document\#page=62},
  timestamp    = {Tue, 21 Jul 2020 00:40:32 +0200},
  biburl       = {https://dblp.org/rec/conf/fics/Nakata10.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Nakata:06,
  author = {Nakata, Keiko and Garrigue, Jacques},
  title = {Recursive Modules for Programming},
  year = {2006},
  issue_date = {September 2006},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {41},
  number = {9},
  issn = {0362-1340},
  url = {https://doi.org/10.1145/1160074.1159813},
  doi = {10.1145/1160074.1159813},
  abstract = {TheML module system is useful for building large-scale programs. The programmer can factor programs into nested and parameterized modules, and can control abstraction with signatures. Yet ML prohibits recursion between modules. As a result of this constraint, the programmer may have to consolidate conceptually separate components into a single module, intruding on modular programming. Introducing recursive modules is a natural way out of this predicament. Existing proposals, however, vary in expressiveness and verbosity. In this paper, we propose a type system for recursive modules, which can infer their signatures. Opaque signatures can also be given explicitly, to provide type abstraction either inside or outside the recursion. The type system is decidable, and is sound for a call-by-value semantics. We also present a solution to the expression problem, in support of our design choices.},
  journal = {SIGPLAN Not.},
  month = {sep},
  pages = {74–86},
  numpages = {13},
  keywords = {the expression problem, type systems, recursive modules, applicative functors, type inference}
}

@article{stg,
  abstract = {The Spineless Tagless G-machine is an abstract machine designed to support non-strict higher-order functional languages. This presentation of the machine falls into three parts. Firstly, we give a general discussion of the design issues involved in implementing non-strict functional languages. Next, we present the STG language, an austere but recognizably-functional language, which as well as a denotational meaning has a well-defined operational semantics. The STG language is the abstract machine code for the Spineless Tagless G-machine. Lastly, we discuss the mapping of the STG language onto stock hardware. The success of an abstract machine model depends largely on how efficient this mapping can be made, though this topic is often relegated to a short section. Instead, we give a detailed discussion of the design issues and the choices we have made. Our principal target is the C language, treating the C compiler as a portable assembler.},
  author = {Peyton Jones, Simon L.},
  doi = {10.1017/S0956796800000319},
  issn = {14697653},
  journal = {Journal of Functional Programming},
  title = {Implementing lazy functional languages on stock hardware: The Spineless Tagless G-machine},
  year = {1992},
}

@inproceedings{Mangal:14,
  author="Mangal, Ravi
  and Naik, Mayur
  and Yang, Hongseok",
  editor="Shao, Zhong",
  title="A Correspondence between Two Approaches to Interprocedural Analysis in the Presence of Join",
  booktitle="Programming Languages and Systems",
  year="2014",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="513--533",
  abstract="Many interprocedural static analyses perform a lossy join for reasons of termination or efficiency. We study the relationship between two predominant approaches to interprocedural analysis, the summary-based (or functional) approach and the call-strings (or k-CFA) approach, in the presence of a lossy join. Despite the use of radically different ways to distinguish procedure contexts by these two approaches, we prove that post-processing their results using a form of garbage collection renders them equivalent. Our result extends the classic result by Sharir and Pnueli that showed the equivalence between these two approaches in the setting of distributive analysis, wherein the join is lossless.",
  isbn="978-3-642-54833-8"
}

@article{Kalita:2022,
  author = {Kalita, Pankaj Kumar and Muduli, Sujit Kumar and D’Antoni, Loris and Reps, Thomas and Roy, Subhajit},
  title = {Synthesizing Abstract Transformers},
  year = {2022},
  issue_date = {October 2022},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {6},
  number = {OOPSLA2},
  url = {https://doi.org/10.1145/3563334},
  doi = {10.1145/3563334},
  abstract = {This paper addresses the problem of creating abstract transformers automatically. The method we present automates the construction of static analyzers in a fashion similar to the way yacc automates the construction of parsers. Our method treats the problem as a program-synthesis problem. The user provides specifications of (i) the concrete semantics of a given operation op, (ii) the abstract domain A to be used by the analyzer, and (iii) the semantics of a domain-specific language L in which the abstract transformer is to be expressed. As output, our method creates an abstract transformer for op in abstract domain A, expressed in L (an “L-transformer for op over A”). Moreover, the abstract transformer obtained is a most-precise L-transformer for op over A; that is, there is no other L-transformer for op over A that is strictly more precise. We implemented our method in a tool called AMURTH. We used AMURTH to create sets of replacement abstract transformers for those used in two existing analyzers, and obtained essentially identical performance. However, when we compared the existing transformers with the transformers obtained using AMURTH, we discovered that four of the existing transformers were unsound, which demonstrates the risk of using manually created transformers.},
  journal = {Proc. ACM Program. Lang.},
  month = {oct},
  articleno = {171},
  numpages = {29},
  keywords = {DSL, abstract transformer, program synthesis}
}

@article{Danielsson:06,
  author = {Danielsson, Nils Anders and Hughes, John and Jansson, Patrik and Gibbons, Jeremy},
  title = {Fast and Loose Reasoning is Morally Correct},
  year = {2006},
  issue_date = {January 2006},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {41},
  number = {1},
  issn = {0362-1340},
  url = {https://doi.org/10.1145/1111320.1111056},
  doi = {10.1145/1111320.1111056},
  abstract = {Functional programmers often reason about programs as if they were written in a total language, expecting the results to carry over to non-total (partial) languages. We justify such reasoning.Two languages are defined, one total and one partial, with identical syntax. The semantics of the partial language includes partial and infinite values, and all types are lifted, including the function spaces. A partial equivalence relation (PER) is then defined, the domain of which is the total subset of the partial language. For types not containing function spaces the PER relates equal values, and functions are related if they map related values to related values.It is proved that if two closed terms have the same semantics in the total language, then they have related semantics in the partial language. It is also shown that the PER gives rise to a bicartesian closed category which can be used to reason about values in the domain of the relation.},
  journal = {SIGPLAN Not.},
  month = {jan},
  pages = {206–217},
  numpages = {12},
  keywords = {partial and total languages, equational reasoning, inductive and coinductive types, partial and infinite values, lifted types, non-strict and strict languages}
}

@inproceedings{Hughes:96,
  author = {Hughes, John and Pareto, Lars and Sabry, Amr},
  title = {Proving the Correctness of Reactive Systems Using Sized Types},
  year = {1996},
  isbn = {0897917693},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/237721.240882},
  doi = {10.1145/237721.240882},
  abstract = {We have designed and implemented a type-based analysis for proving some basic properties of reactive systems. The analysis manipulates rich type expressions that contain information about the sizes of recursively defined data structures. Sized types are useful for detecting deadlocks, nontermination, and other errors in embedded programs. To establish the soundness of the analysis we have developed an appropriate semantic model of sized types.},
  booktitle = {Proceedings of the 23rd ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
  pages = {410–423},
  numpages = {14},
  location = {St. Petersburg Beach, Florida, USA},
  series = {POPL '96}
}

@misc{gitrees,
  title={Modular Denotational Semantics for Effects with Guarded Interaction Trees},
  author={Dan Frumin and Amin Timany and Lars Birkedal},
  year={2023},
  eprint={2307.08514},
  archivePrefix={arXiv},
  primaryClass={cs.PL}
}

@article{Backhouse:04,
  title = {Safety of abstract interpretations for free, via logical relations and Galois connections},
  journal = {Science of Computer Programming},
  volume = {51},
  number = {1},
  pages = {153-196},
  year = {2004},
  note = {Mathematics of Program Construction (MPC 2002)},
  issn = {0167-6423},
  doi = {https://doi.org/10.1016/j.scico.2003.06.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0167642304000164},
  author = {Kevin Backhouse and Roland Backhouse},
  keywords = {Abstract interpretation, Logical relations, Parametricity, Theorems for free, Galois connections},
  abstract = {Algebraic properties of logical relations on partially ordered sets are studied. It is shown how to construct a logical relation that extends a collection of base Galois connections to a Galois connection of arbitrary higher-order type. “Theorems-for-free” is used to show that the construction ensures safe abstract interpretation of parametrically polymorphic functions. The properties are used to show how abstract interpretations of program libraries can be constructed.}
}

@mastersthesis{Boehme:07,
  author = {Sascha B\"ohme},
  title = {Free Theorems for Sublanguages of Haskell},
  school = {Technische Universit\"at Dresden},
  year = 2007
}

@inproceedings{Reynolds:83,
  author       = {John C. Reynolds},
  editor       = {R. E. A. Mason},
  title        = {Types, Abstraction and Parametric Polymorphism},
  booktitle    = {Information Processing 83, Proceedings of the {IFIP} 9th World Computer
                  Congress, Paris, France, September 19-23, 1983},
  pages        = {513--523},
  publisher    = {North-Holland/IFIP},
  year         = {1983},
  timestamp    = {Sun, 28 Jul 2019 17:03:41 +0200},
  biburl       = {https://dblp.org/rec/conf/ifip/Reynolds83.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Wadler:89,
  author       = {Philip Wadler},
  editor       = {Joseph E. Stoy},
  title        = {Theorems for Free!},
  booktitle    = {Proceedings of the fourth international conference on Functional programming
                  languages and computer architecture, {FPCA} 1989, London, UK, September
                  11-13, 1989},
  pages        = {347--359},
  publisher    = {{ACM}},
  year         = {1989},
  url          = {https://doi.org/10.1145/99370.99404},
  doi          = {10.1145/99370.99404},
  timestamp    = {Wed, 14 Nov 2018 10:57:36 +0100},
  biburl       = {https://dblp.org/rec/conf/fpca/Wadler89.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Ghani:16,
  title = {Bifibrational Functorial Semantics of Parametric Polymorphism},
  journal = {Electronic Notes in Theoretical Computer Science},
  volume = {319},
  pages = {165-181},
  year = {2015},
  note = {The 31st Conference on the Mathematical Foundations of Programming Semantics (MFPS XXXI).},
  issn = {1571-0661},
  doi = {https://doi.org/10.1016/j.entcs.2015.12.011},
  url = {https://www.sciencedirect.com/science/article/pii/S157106611500078X},
  author = {Neil Ghani and Patricia Johann and Fredrik Nordvall Forsberg and Federico Orsanigo and Tim Revell},
  keywords = {Parametricity, logical relations, System F, fibred category theory},
  abstract = {Reynolds' theory of parametric polymorphism captures the invariance of polymorphically typed programs under change of data representation. Semantically, reflexive graph categories and fibrations are both known to give a categorical understanding of parametric polymorphism. This paper contributes further to this categorical perspective by showing the relevance of bifibrations. We develop a bifibrational framework for models of System F that are parametric, in that they verify the Identity Extension Lemma and Reynolds' Abstraction Theorem. We also prove that our models satisfy expected properties, such as the existence of initial algebras and final coalgebras, and that parametricity implies dinaturality.}
}

@article{Hall:96,
  author = {Hall, Cordelia V. and Hammond, Kevin and Peyton Jones, Simon L. and Wadler, Philip L.},
  title = {Type Classes in Haskell},
  year = {1996},
  issue_date = {March 1996},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {18},
  number = {2},
  issn = {0164-0925},
  url = {https://doi.org/10.1145/227699.227700},
  doi = {10.1145/227699.227700},
  abstract = {This article defines a set of type inference rules for resolving overloading introduced by type classes, as used in the functional programming language Haskell. Programs including type classes are transformed into ones which may be typed by standard Hindley-Milner inference rules. In contrast to other work on type classes, the rules presented here relate directly to Haskell programs. An innovative aspect of this work is the use of second-order lambda calculus to record type information in the transformed program.},
  journal = {ACM Trans. Program. Lang. Syst.},
  month = {mar},
  pages = {109–138},
  numpages = {30},
  keywords = {types, Haskell, functional programming, type classes}
}

@inproceedings{Spies:21,
  author = {Spies, Simon and G\"{a}her, Lennard and Gratzer, Daniel and Tassarotti, Joseph and Krebbers, Robbert and Dreyer, Derek and Birkedal, Lars},
  title = {Transfinite Iris: Resolving an Existential Dilemma of Step-Indexed Separation Logic},
  year = {2021},
  isbn = {9781450383912},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3453483.3454031},
  doi = {10.1145/3453483.3454031},
  abstract = {Step-indexed separation logic has proven to be a powerful tool for modular reasoning about higher-order stateful programs. However, it has only been used to reason about safety properties, never liveness properties. In this paper, we observe that the inability of step-indexed separation logic to support liveness properties stems fundamentally from its failure to validate the existential property, connecting the meaning of existential quantification inside and outside the logic. We show how to validate the existential property—and thus enable liveness reasoning—by moving from finite step-indices (natural numbers) to transfinite step-indices (ordinals). Concretely, we transform the Coq-based step-indexed logic Iris to Transfinite Iris, and demonstrate its effectiveness in proving termination and termination-preserving refinement for higher-order stateful programs.},
  booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
  pages = {80–95},
  numpages = {16},
  keywords = {Iris, step-indexing, transfinite, ordinals, liveness properties, Separation logic},
  location = {Virtual, Canada},
  series = {PLDI 2021}
}

@manual{iris-lecture-notes,
  title = {Lecture Notes on Iris: Higher-Order Concurrent Separation Logic},
  author = {Lars Birkedal and Aleš Bizjak},
  year = {2023},
  month = {August},
  organization = {Aarhus University},
  address = {Aarhus, Denmark},
  note = {\url{https://iris-project.org/tutorial-pdfs/iris-lecture-notes.pdf}},
}

@book{SharirPnueli:78,
  title={Two approaches to interprocedural data flow analysis},
  author={Sharir, Micha and Pnueli, Amir and others},
  year={1978},
  publisher={New York University. Courant Institute of Mathematical Sciences~…}
}
