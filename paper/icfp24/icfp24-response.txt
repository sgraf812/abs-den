First off, we would like to thank the reviewers for reading our work; we are
well aware about its extent and are grateful for gifting us their time.

# Overview

We acknowledge that this paper contains enough ideas for multiple publications,
but we submitted it as a monograph nonetheless because each individual
contribution is too weak to be published by itself.

For example, while the idea of defining a trace-generating denotational
semantics using guarded recursive types to enable higher-order state might not
be standard practice (yet), the building blocks are not novel, as Reviewer
A notes; thus it would be quite difficult to advertise the trace-generating
call-by-need semantics as the main contribution without a convincing use case,
novel as it may be.

However, without discussing this non-standard kind of trace-generating semantics
and its adequacy at length --- which is perhaps boring to expert readers ---
we would quickly lose a large fraction of our audience, that is, functional
programmers interested in deriving correct static program analyses from a
familiar, executable (and perhaps by-value) semantics. For similar reasons, we
think the space explaining absence and usage analysis is well spent.

The drawback of striving to make our work accessible *and* relevant is that there is not
much space left in the main body to delve into formal detail, but we think
that accessibility and relevance are worth deferring this detail to the
appendix and hope to convince the reviewers that this compromise is acceptable.

# Change list

In light of these reviews we plan to make a substantial revision of the paper as follows:

- (I do not know have anything concrete in mind yet)

# Detailed response

## Reviewer A

We will address questions as they appear chronologically in the text.

We gave our best to address "self-containment of the article body" and
"denotational interpreters are not novel" above.

> The choices for the decomposition of the interpreter is non-standard, sometimes surprising.

Indeed it is! That is why we have explained it in the paper. Perhaps another
design works as well or better, but this design worked well for us.

> Are the calls to step inserted only for soundness reasons, or for termination reasons?

Both. Guarding the recursion is essential for totality of the interpreter,
as explained in the proof sketch of Theorem 5.
To repeat line 785 and following, while some steps are only there for adequacy
wrt. the LK machine, at least the steps before variable lookup are mandatory to
guarantee totality.
That is, removing `step` from the interface would give up on totality.

> It seems the interpreter that is presented could be obtained as a particular
> instance of a standard denotational semantics

Yes, but traditional algebraic domains require proving that all operations are
monotone and ω-continuous.
Omitting such proofs means that the semantics might not be well-defined in the
first place.
And then you would *still* need to prove totality in the sense that all total
inputs lead to total outputs, to rule out that the output contains bottom.
It is a path not taken because synthetic guarded domains are simply more
appealing and less difficult.

> Interestingly, the authors make several remarks on whether this was an
> appropriate choice, since, after all, they are interested in safety
> properties.

Yes, and we feel pressed to clarify here that trace predicates defined by Löb
induction naturally define safety properties; a perfect fit, see [4,5] for details.
[5] discusses how to extend a step-indexed logic with Löb induction to express
liveness properties.

> Why didn't you start with a semantics of partial traces in the first place?
> This would have saved you the difficult work of dealing with co-inductive
> traces.

In contrast to [1], our object language is deterministic.
In that case we can simply take the prefix closure of the maximal trace
generated by our fixpoint (maximal) trace semantics (to use Cousot's language [6])
to recover an equivalent partial trace semantics as in 4.2 of [1].
Chapter 17.2 in [6] discusses the equivalence.

That said, we find it in fact *less difficult* to generate the
single, coinductive maximal trace instead of the set of its finite prefixes,
because then we do not need to come up with a language to lift operations
to sets. Compare Definition (17.4) to Definition (17.18) in [6] for a taste.
The fixpoint maximal trace semantics in [6] was a huge inspiration to our
approach.

> Figure 13, MONO: This is in practice very constraining, and can rule out
> several useful analyses. Widening breaks MONO.

We are a bit unsure what kind of widening operators you had in mind. Yes,
widening operators may well be non-monotonic, but they are not part of the type
class interface and thus not subject to MONO. We need `bind` to be monotonic,
but we do not necessarily need monotonicity of widening operators to prove that;
there are many simple widening strategies that enable a monotonic `bind`.

Independently, we do not see a fundamental reason for why it would be
impossible to relax the MONO law for `bind` along the lines of what you
propose and generalise the proof as well, at the cost of making the abstraction
laws more complicated.

> It is extremely surprising that the soundness of the pre-order of the abstract
> domain is never mentioned or required.

We are a bit unsure what "soundness of the pre-order" means.
The definition of ⊑ follows structurally from the order `U0 ⊏ U1 ⊏ Uω` (line 954.5),
and *structurally* means pointwise, pairwise, etc..
The partial order laws follow by parametricity, as detailed in [2].
The only non-structural ordering is for ValueU because of the additional
syntactic equality as explained on lines 151 and line 912.

> Theorem 6 mentions the abstract function, that is never defined.

As written on lines 1024-1025, the abstract function is defined in
the proof of Theorem 6.
We agree that the definition of the abstraction function is important to see
whether Theorem 6 is useful, but (1) the definition needs a generalised
abstraction function for open terms, the precise definition of which is not
easily abbreviated (we tried), and (2) we explain what abstract
computes in the same paragraph, so that readers may build an
intuition before buying into pages worth of formalisation in (1).

> Can the abstraction laws be proved in a modular way?

We are a bit unsure what "non-modular" means in this context.
Presumably it refers to "knowing the definition of the whole analysis function".
We do not think that is an unreasonable assumption when trying to prove an
analysis correct.
In case we had two variants of an (e.g. usage) analysis that differ only in
their, e.g. `ConApp` case, it would not be difficult to factor analysis,
substitution lemma and correctness proof in a way that proofs are shared.
As explained in the paragraph starting on line 1055.5, the laws are indeed
*simpler* to prove than the typical Galois Connection identities, simply
because we know the abstraction function.

> Finally, it seems the authors use the vocable "summary-based analysis" to
> denote two very different things.

This critique resonates with us, and we are curious to know whether you have
particular terminology in mind to separate both uses?
We would suggest "monovariadic" summary-based analysis vs. "polyvariadic"
summary-based analyses and would be happy to clarify that we refer to former
in the main body of the paper and the latter in the context of 0CFA in the
appendix, for example.
Our approach can derive both flavours of analyses.

> Please elaborate on the connections with interaction trees, that also
> represent the traces of programs as a co-inductive value.

As we wrote on line 439 and lines 1137.5-1139.5, we think it would be possible
to define a Trace instance for interaction trees (ITs), which would then
replace the vanilla trace type T.
Doing so seems viable when the object language features input/output
side-effects, or when certain kinds of transitions should not be observable
(IT's Tau).
Compared with ITs, The vanilla T regards every transition as a visible
output "side-effect".
Our work is not concerned with generalising this kind of "side-effect", but
we are quite happy that these co-existing research strands appear to be
compatible.
It is no surprise to us that guarded ITs can be used to define
similar denotational semantics.
The main contribution of our work is not the *definition* of a semantics, but
what we accomplish with it.

> Game semantics

Our denotional interpreter generates a program's execution trace in a small-step
transition system.
To our knowledge, game semantics denotes programs by *sets of traces* where
every trace corresponds to a *play* that can be thought of as an semantic
interaction of an program context with the denoted program.
These two notions of trace are quite disparate.
Game semantics would be interesting if we were to define a non-standard
equivalence relation on denotations, which we (consciously) do not.
That is why we define absence in terms of syntactic evaluation contexts, for
example.

> How does this paper compare to work that also use sets of traces for the λ-calculus to derive CFA, e.g. [3]?

(Incidentally, we removed the following paragraph in Related Work for space reasons.)
[3] derive CFA from small-step traces in an impressive chain of abstractions.
We think that a variant of our denotational interpreter would be a good fit
for their collecting semantics.
Specifically, the semantic inclusions of Lemma 2.10 that govern the
transition to a big-step style interpreter follow simply by adequacy of our
interpreter, Theorem 4.

> Which parts have you mechanized in Agda? Which parts are not mechanized?

We proved totality of our interpreter by encoding the by-name and by-need
interpreter instances in Agda. We did not mechanise any further proofs.


# Bibliography

[1] Cousot and Cousot
    An abstract interpretation framework for termination.
    2012.

[2] Backhouse and Backhouse
    Safety of abstract interpretations for free, via logical relations and Galois connections.
    2004

[3] Montagu, Benoît and Jensen, Thomas
    Trace-Based Control-Flow Analysis.
    PLDI 2021.

[4] Birkedal and Bizjak
    Lecture Notes on Iris: Higher-Order Concurrent Separation Logic.
    https://iris-project.org/tutorial-pdfs/iris-lecture-notes.pdf

[5] Spies et al.
    Transfinite Iris: resolving an existential dilemma of step-indexed separation logic.
    PLDI 2021

[6] Cousot
    Principles of Abstract Interpretation.
    MIT Press, 2021

