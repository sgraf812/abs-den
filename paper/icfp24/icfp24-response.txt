First off, we would like to thank the reviewers for reading our work; we are
well aware about its extent and are grateful for gifting us their time.

# Overview

We acknowledge that this paper contains enough ideas for multiple publications,
but we submitted it as a monograph nonetheless because each individual
contribution is too weak to be published by itself.

For example, while the idea of defining a trace-generating denotational
semantics using guarded recursive types to enable higher-order state might not
be standard practice (yet), the building blocks are not novel, as Reviewer
A notes; thus it would be quite difficult to advertise the trace-generating
call-by-need semantics as the main contribution without a convincing use case,
novel as it may be.

However, without discussing this non-standard kind of trace-generating semantics
and its adequacy at length --- which is perhaps boring to expert readers ---
we would quickly lose a large fraction of our audience, that is, functional
programmers interested in deriving correct static program analyses from a
familiar, executable (and perhaps by-value) semantics. For similar reasons, we
think the space explaining absence and usage analysis is well spent.

The drawback of striving to make our work accessible *and* relevant is that there is not
much space left in the main body to delve into formal detail, but we think
that accessibility and relevance are worth deferring this detail to the
appendix and hope to convince the reviewers that this compromise is acceptable.

# Change list

In light of these reviews we plan to make a substantial revision of the paper as follows:

- (I do not know have anything concrete in mind yet)

# Detailed response

## Reviewer A

- Why didn't you start with a semantics of partial traces in the first place?
  This would have saved you the difficult work of dealing with co-inductive traces.

We gave our best to address "self-containment of the article body" and
"denotational interpreters are not novel" above.

> The choices for the decomposition of the interpreter is non-standard, sometimes surprising.

Indeed it is! That is why we have explained it in the paper.
Perhaps another design works as well or better, but this design worked for
us.

> Are the calls to step inserted only for soundness reasons, or for termination reasons?

It is both. Guarding the recursion is essential to totality of the interpreter,
as explained in the proof sketch of Theorem 5.
To repeat line 785 and following, while some steps are only there for adequacy
wrt. the LK machine, at least the steps before variable lookup are mandatory to
guarantee totality.
That is, removing `step` from the interface would give up on totality.

> It seems the interpreter that is presented could be obtained as a particular instance of a standard denotational semantics

Yes, but traditional algebraic domains require to prove that all operations are
monotone and ω-continuous.
Omitting such proofs means that the semantic domain is not defined in the first
place.
And then you would still need to prove totality in the sense that all total
inputs lead to total outputs, to rule out that the output contains bottoms.
It is a path not taken because guarded recursive types are simply more
appealing.

> Interestingly, the authors make several remarks on whether this was an
> appropriate choice, since, after all, they are interested in safety
> properties.

Yes, and we feel we should make clear here that the conclusion is that a guarded
formulation is *ideal* to formulate safety properties, because predicates
defined by Löb induction define safety properties; see [2,3] for details.
We expand on the topic a bit in Appendix D.2, where it can satiate hungry minds.

> Why didn't you start with a semantics of partial traces in the first place?
> This would have saved you the difficult work of dealing with co-inductive
> traces.

First off, a *prefix trace semantics* such as in [4] can be recovered from our
*maximal trace semantics* (to use terminology from Cousot [5]) simply by taking
the prefix closure of the maximal trace, so they are equally expressive for the
language considered [5].
That said, it is *far more intuitive* to generate the maximal traces instead,
because then you do not need to come up with a language to lift operations
to sets. Compare page TODO to page TODO for a taste.


1. Figure 13, MONO: This is in practice very constraining, and can rule out several useful analyses. Widening breaks MONO.
  - We are a bit unsure what kind of widening operators you had in mind.
    Yes, widening operators may well be non-monotonic, but they are not part
    of the type class interface and thus not subject to MONO.
    We need that `bind` is monotonic, but we do not necessarily need
    monotonicity of widening operators to prove that; there are many simple
    widening strategies enable a monotonic `bind`.
  - Independently, we do not see a fundamental reason for why it would be
    impossible to relax the MONO law for `bind` along the lines of what you
    propose and generalise the proof as well, at the cost of making the laws
    more complicated.
2. It is extremely surprising that the soundness of the pre-order of the abstract domain is never mentioned or required.
  - We are a bit unsure what "soundness of the pre-order" means.
    The definition of ⊑ follows structurally from the order `U0 ⊏ U1 ⊏ Uω` (line 954.5),
    and *structurally* means pointwise, pairwise, etc..
    The partial order laws follow by parametricity, as detailed in [1].
    The only non-structural ordering is for ValueU because of the additional
    syntactic equality as explained on lines 151 and line 912.
3. Theorem 6 mentions the abstract function, that is never defined.
  - As written on lines 1024-1025, the abstract function is defined in
    the proof of Theorem 6.
    We agree that the definition of the abstraction function is important to see
    whether Theorem 6 is useful, but (1) the definition needs a generalised
    abstraction function for open terms, the precise definition of which is not
    easily abbreviated (we tried), and (2) we explain what abstract
    computes in the same paragraph, so that readers may build an
    intuition before buying into pages worth of formalisation in (1).
4. Can the abstraction laws be proved in a modular way?
  - We are a bit unsure what "non-modular" means in this context.
    Apparently it refers to "knowing the definition of the whole analysis function".
    We do not think that is an unreasonable assumption when trying to prove an
    analysis correct.
    In case we had two variants of an (e.g. usage) analysis that differ only in
    their, e.g. `ConApp` case, it would not be difficult to factor analysis,
    substitution lemma and correctness proof in a way that proofs are shared.
    As explained in the paragraph starting on line 1055.5, the laws are indeed
    *simpler* to prove than the typical Galois Connection identities, simply
    because we know the abstraction function.
5. Finally, it seems the authors use the vocable "summary-based analysis" to denote two very different things.
  - This critique resonates with us, and we are curious to know whether the reviewer
    has a particular terminology in mind to separate both uses?
    We would suggest "monovariadic" summary-based analysis vs. "polyvariadic"
    summary-based analyses and would be happy to clarify that we refer to former
    in the main body of the paper and the latter in the context of 0CFA in the
    appendix, for example.
    Our approach can derive both flavours of analyses.
6. Please elaborate on the connections with interaction trees, that also
   represent the traces of programs as a co-inductive value.
  - As we wrote on line 439 and lines 1137.5-1139.5, we think it would be possible
    to define a Trace instance for interaction trees (ITs), which would then
    replace the vanilla trace type T.
    Doing so seems viable when the intermediate representation features
    input/output side-effects, or when certain kinds of transitions should not
    be observable (IT's Tau).
    Compared with ITs, The vanilla T regards every transition as a visible
    output "side-effect".
    Our work is not concerned with generalising this kind of "side-effect", but
    we are quite happy that these co-existing research strands appear to be
    compatible.
    It is no surprise to us that guarded ITs can be used to define
    similar denotational semantics.
    The main contribution of our work is not the *definition* of a semantics but
    what we accomplish with it.
7. Game semantics
  - Our denotional interpreter generates a small-step trace (of a program).
    To our knowledge, game semantics denotes programs by *sets of traces* where
    every trace corresponds to a *play* that can be thought of as an semantic
    interaction of an program context with the denoted program.
    This notion of trace is quite disparate from a trace in a transition system
    modelling call-by-need, for example.
    Game semantics would be interesting if we were to define a non-standard
    equivalence relation on denotations, which we (consciously) do not.
    That is why we define absence in terms of syntactic evaluation contexts.
8. How does this paper compare to work that also use sets of traces for the λ-calculus to derive CFA, e.g. [3]?
  - (Incidentally, we removed the following paragraph in Related Work for space reasons.)
    [3] derive CFA from small-step traces in an impressive chain of abstractions.
    We think that a variant of our denotational interpreter would be a good fit
    for their collecting semantics.
    Specifically, the semantic inclusions of Lemma 2.10 that govern the
    transition to a big-step style interpreter follow simply by adequacy of our
    interpreter, Theorem 4.
9. Which parts have you mechanized in Agda? Which parts are not mechanized?
  - We proved totality of our interpreter by encoding the by-name and by-need
    interpreter instances in Agda. We did not mechanise any further proofs.

bfSince
    we do not define any non-standard equivalence relation,


[1] Backhouse and Backhouse, Safety of abstract interpretations for free, via logical relations and Galois connections, 2004

[2] Birkedal and Bizjak, Lecture Notes on Iris: Higher-Order Concurrent Separation Logic, https://iris-project.org/tutorial-pdfs/iris-lecture-notes.pdf

[3] Spies et al., Transfinite Iris: resolving an existential dilemma of step-indexed separation logic, PLDI 2021
