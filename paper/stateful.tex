\section{A Denotational Semantics for Call-by-need}
\label{sec:stateful}

\subsection{Labelled Syntax}

Recall the syntax definition of our object language in
\Cref{sec:usage-intuition} in the style of \citet{Launchbury:93} and
\citet{Sestoft:97}.
Any (sub-)expression has a unique \emph{label} (think of it as the AST node's
pointer identity) that we usually omit. For example, a correct labelling of
$\Let{x}{f~y}{f~x}$ would be
\[
  (\slbln{1} \Let{x}{(\slbln{2} (\slbln{3} f)~y)}{(\slbln{4} (\slbln{5} f)~x)}).
\]
Labels are there so that we do not conflate the (otherwise structurally equal)
sub-terms $(\slbln{3} f)$ and $(\slbln{5} f)$ as equivalent. This is an important
distinction for, \eg, control-flow analysis. Since labels introduce excessive
clutter, we will omit them unless they are distinctively important. If anything,
labels make it so that everything ``works as expected''.

\subsection{Transition System}

\Cref{fig:lk-semantics} gave an operational semantics in terms of
a small-step transition system closest to the lazy Krivine machine
\citep{AgerDanvyMidtgaard:04} for Launchbury's language as presented
in \citet{Sestoft:97}.
It is worth having a second look at the workings of our Gold Standard.

When the control expression $\ctrl(σ)$ of a state $σ$ is a value $\pv$, we
call $σ$ a \emph{return} state and say that the continuation $\cont(σ)$ drives
evaluation.
Otherwise, $σ$ is an \emph{evaluation} state and $\ctrl(σ)$ drives evaluation.
The entries in the heap $μ$ are \emph{closures} of the form $(ρ,e)$, where the
environment $ρ$ closes over the expression $e$.
Finally, the $\cont(σ)$ lists actions to be taken in a return state, such as
applying the result to an argument address or updating a heap entry with its
value.

Heap entries are introduced via $\BindT$ transitions under a \emph{fresh} address
$\pa \not∈ \dom(μ)$ that we call an \emph{activation} of the let-bound variable
$\px$. The lexical activation of every variable in scope is maintained
in $ρ$. The $\AppIT$ rule pushes an \emph{application frame} with the address of
the argument variable onto the stack, while the rule $\LookupT$ pushes an
\emph{update frame} with the address of the variable the heap entry of which is
accessed. When a return state is reached, the original heap entry is overwritten
with the value in the control.

Let us conclude with an example trace in this transition system, evaluating
$\pe \triangleq \Let{i}{\Lam{x}{x}}{i~i}$ to completion:
\[\begin{array}{c}
  \arraycolsep2pt
  \begin{array}{clclclcl}
             & (\pe, [], [], \StopF)         & \smallstep & (i~i, ρ_1, μ, \StopF)
             & \smallstep & (i, ρ_1, μ, κ_1) & \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_2)
             \\
  \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_1)     & \smallstep & (x, ρ_2, μ, \StopF) & \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_3)
             & \smallstep & (\Lam{x}{x}, ρ_1, μ, \StopF) \\
  \end{array} \\
  \\[-0.5em]
  \quad \text{where} \quad \begin{array}{lll}
  ρ_1 = [i ↦ \pa_1] & ρ_2 = [i ↦ \pa_1, x ↦ \pa_1] & μ = [\pa_1 ↦ (ρ_1,\Lam{x}{x})] \\
  κ_1 = \ApplyF(\pa_1) \pushF \StopF & κ_2 = \UpdateF(\pa_1) \pushF κ_1 & κ_3 = \UpdateF(\pa_1) \pushF \StopF
  \end{array}
\end{array}\]

\subsection{Domain Theory}
\label{sec:domain-theory}

The challenge that domain theory sets out to solve is that the ``inductive
datatype''
\[
  D ::= \FunV(f ∈ D \to D) \mid \bot
\]
is ill-defined:
The usual interpretation of such a declaration as the least fixed-point of
the implied set-valued functional
$F(X) \triangleq \{ f \mid ∀a∈X.\ ∃b∈X.\ f(a) = b \} ∪ \{ \bot \}$
does not exist.

To see that, suppose $μF$ was that set.
Then there exists an injection (``data constructor'') $\FunV$ from $μF \to μF =
μF^{μF}$ into $μF$.
We can see that $\{\bot, (\fn{\wild}{\bot}) \} \subseteq μF$, so there are at
least two elements in $μF$.
Then to accomodate $μF^{μF}$, $μF$ must be at least as large as $2^{μF}$, the
set of two-valued functions on $μF$.
But this latter set is one-to-one with $\poset{μF}$ and it is a known result by
Cantor that the $\poset{μF}$ has greater cardinality than $μF$, in contradiction
to the existence of the injection $\FunV$.

Domain theory, on the other hand, interprets the implied recursion equation
in terms of topology and continuous functions, where the fixed-point exists
when restricted to \emph{algebraic domains}.
At the same time, algebraic domains are expressive enough to encode any
computable function as a continuous function.

\subsection{Guarded Domain Theory}

As we have discussed in \Cref{sec:continuity}, there are a few strings attached
to working with continuity and partiality in the context of denotational
semantics.

The key to getting rid of partiality and thus denoting infinite computations
with total elements is to avoid working with algebraic domains altogether and
instead work in a total type theory with \emph{guarded recursive types}, such
as Guarded Dependent Type Theory (GDTT)~\citep{gdtt} or Ticked Cubical Type
Theory~\citep{tctt}.%
\footnote{Of course, in reality we are just using GDTT as a meta
language~\citep{Moggi:07} with a known domain-theoretic model in terms
of the topos of trees~\citep{gdtt}.
This meta language is sufficiently expressive as a logic to
express proofs, though, justifying the view that we are extending ``math''
with the ability to conveniently reason about computable functions on infinite
data without needing to think about topology and approximation directly.}
The fundamental innovation of these theories is the integration of the
``later'' modality $\later$ which allows to define coinductive data types
with negative recursive occurrences such in our ``data type'' $D$ from
\Cref{sec:domain-theory}, as first realised by \citet{Nakano:00}.

GDTT walks a fine line:
The theory guarantees that all well-typed functions (naturally) correspond
to continuous functions in the underlying model, while it also allows for
embedding of a sufficiently expressive restriction to give meaning to $D$.

Whereas previous theories of coinduction require syntactic productivity
checks~\citep{Coquand:94}, requiring tiresome constraints on the form of guarded
recursive functions, the appeal of GDTT is that productivity is instead proven
semantically, in the type system.

The way that GDTT achieves this is roughly as follows: The type $\later T$
represents data of type $T$ that will become available after a finite amount
of computation, such as unrolling one layer of a fixpoint definition.
It comes with a general fixpoint combinator $\fix : \forall A.\ (\later A \to
A) \to A$ that can be used to define both coinductive \emph{types} (via guarded
recursive functions on the universe of types~\citep{BirkedalMogelbergEjlers:13})
as well as guarded recursive \emph{terms} inhabiting said types.
The classic example is that of coinductive streams:
\[
  Str = ℕ \times \later Str \qquad ones = \fix (r : \later Str).\ (1,r),
\]
where $ones : Str$ is the constant stream of $1$.
In particular, $Str$ is the fixpoint of a locally contractive functor $F(X) =
ℕ \times \later X$.
According to \citet{BirkedalMogelbergEjlers:13}, any type expression in simply
typed lambda calculus defines a locally contractive functor as long as any
occurrence of $X$ is under a $\later$, so we take that as the well-formedness
criterion of coinductive types in this work.
The most exciting consequence is that
$D ::= \FunV(f ∈ \later D \to D) \mid \bot$ (where $\bot$ is interpreted as a
plain nullary data constructor rather than as the least element of some partial
order) is a sound coinductive encoding of the data type in
\Cref{sec:domain-theory}.

As a type constructor, $\later$ is an applicative
functor~\citep{McBridePaterson:08} via functions
\[
  \purelater : \forall A.\ A \to \later A \qquad \wild \aplater \wild : \forall A,B.\ \later (A \to B) \to \later A \to \later B,
\]
allowing us to apply a familiar framework of reasoning around $\later$.
In order not to obscure our work with pointless symbol pushing
in, \eg, \Cref{fig:semst}, we will often omit the idiom
brackets~\citep{McBridePaterson:08} $\idiom{\wild}$
to indicate where the $\later$ ``effects'' happen.
Rest assured, they are still there in the Guarded Cubical Agda development in
the Appendix \sg{TODO link}.

\sg{The Guarded Cubical Agda prototype type-checks and is available at
\url{https://github.com/sgraf812/comp-trace/blob/main/paper/agda}}

\begin{figure}
\[\begin{array}{c}
 \begin{array}{rrclclrrclcl}
  \text{State}        & σ   & ∈ & \States        & =      & \Controls \times \Heaps
  &
  \text{Environment}  & ρ   & ∈ & \Environments  & =      & \Var \pfun \StateD
  \\
  \text{Control}      & \pc & ∈ & \Controls      & ::=    & \pe \mid (\lbl, v)
  &
  \text{Heap}         & μ   & ∈ & \Heaps         & =      & \Addresses \pfun \later\StateD
  \\
  \\[-0.5em]
 \end{array} \\
 \begin{array}{rrclclrrclcl}
  \text{Stateful trace} & τ      & ∈          & \STraces & ::= & \goodend{σ} \mid \stuckend{σ} \mid σ \cons τ^{\later}
  &
  \text{Delayed trace} & τ^{\later} & ∈ & \later\STraces &   &
  \\
  \text{Stateful domain} & d & ∈ & \StateD & = & \Heaps \to \STraces
  &
  \text{Delayed element} & d^{\later} & ∈ & \later\StateD &   &
  \\
  \\[-0.5em]
 \end{array} \\
 \begin{array}{rrclcl}
  \text{Stateful value} & v & ∈ & \StateV & ::= & \FunV(f ∈ (\later\StateD \to \later\StateD)) \mid \ConV(K,\many{d^{\later}}^{α_K}) \\
 \end{array} \\
  \\[-0.5em]
\end{array}\]
\[\begin{array}{c}
 \begin{array}{rcl}
  \multicolumn{3}{c}{ \ruleform{
    \begin{array}{c}
      (\betastep) : \STraces \to (\States \pfun \later\STraces) \to \STraces \quad  \ret : (\Lab \times \StateV) \to \StateD \\
      \deref : \Addresses \to \StateD \quad \apply : \STraces \to \StateD \to \STraces \\
      \select : \STraces \to ((K:\Con) \to (\later\StateD)^{α_K} \pfun \later\StateD) \to \STraces \\
    \end{array}
  }} \\
  \\[-0.5em]
  τ \betastep f & = & \begin{cases}
      τ :: f(σ) & \text{$τ = ... \cons \goodend{σ}$ and $σ ∈ \dom(f)$} \\
      τ' :: \stuckend{σ} & \text{$τ = τ' \cons \goodend{σ}$ and $σ \not∈ \dom(f)$} \\
      τ & \text{otherwise} \\
    \end{cases} \\
  \\[-0.5em]
  \ret(\lbl,v)(μ) & = & \goodend{((\lbl,v),μ)} \\
  \deref(\pa)(μ) & = & μ(\pa)(μ) \betastep \fn{((\lbl,v),μ)}{\goodend{((\lbl,v),μ[\pa ↦ \ret(\lbl,v)])}} \\
  \apply(τ,d) & = & τ \betastep \fn{((\wild,\FunV(f)),μ)}{f(d)(μ)} \\
  \select(τ,\alts) & = & τ \betastep \fn{((\wild,\ConV(K_s,\many{d_s^\later})),μ)}{\alts(K_s, \many{d_s^\later})} \\
                   &   & \hspace{8em} \text{where } (K_s, \many{d_s^\later}) ∈ \dom(\alts) \\
 \end{array} \\
 \\[-0.5em]
 \begin{array}{rcl}
  \multicolumn{3}{c}{ \ruleform{ \semst{\wild} \colon \Exp → (\Var \pfun \StateD) → \StateD } } \\
  \\[-0.5em]
  \semst{\px}_ρ(μ) & = & \begin{cases}
    (\px,μ) \cons ρ(\px)(μ) & \px ∈ \dom(ρ) \\
    \stuckend{(\px,μ)} & \text{otherwise}
    \end{cases} \\
  \\[-0.5em]
  \semst{\slbl \Lam{\px}{\pe}}_ρ & = & \ret(\lbl,\FunV(\fn{d^\later}{\semst{\pe}_{ρ[\px↦d^\later]}})) \\
  \\[-0.5em]
  \semst{\pe~\px}_ρ(μ) & = & \begin{cases}
      (\pe~\px,μ) \cons \apply(\semst{\pe}_ρ(μ),ρ(\px)) & \px ∈ \dom(ρ) \\
      \stuckend{(\pe~\px,μ)} & \text{otherwise} \\
    \end{cases} \\
  \\[-0.5em]
  \semst{\Let{\px}{\pe_1}{\pe_2}}_ρ(μ) & = & \begin{letarray}
    \text{let} & ρ' = ρ[\px ↦ \deref(\pa)] \quad \text{where $\pa \not∈ \dom(μ)$} \\
               & μ^\later = μ[\pa ↦ \semst{\pe_1}_{ρ'}] \\
    \text{in}  & (\Let{\px}{\pe_1}{\pe_2},μ) \cons \semst{\pe_2}_{ρ'}(μ^\later) \\
  \end{letarray} \\
  \\[-0.5em]
  \semst{\slbl K~\many{\px}}_ρ & = & \ret(\lbl,\ConV(K,\many{\semst{\px}_ρ})) \\
  \\[-0.5em]
  \semst{\pe@(\Case{\pe_s}{\Sel[r]})}_ρ(μ) & = &
    \begin{letarray}
      \text{let} & \alts = \fn{K}{\fn{\many{d^\later}}{\semst{\pe_r}_{ρ[\many{\px↦d^\later}]}}} \\
      \text{in} & (\pe,μ) \cons \select(\semst{\pe_s}_ρ(μ), \alts)  \\
    \end{letarray}
 \end{array}
  \\[-0.5em]
\end{array}\]
\caption{Stateful Trace Semantics $\semst{-}$}
  \label{fig:semst}
\end{figure}

\subsection{Definition}

\Cref{fig:semst} finally gives the definition for $\semst{\wild}$, a function
defined by structural recursion on an input expression $\pe$. Given a denotation
for free variables $ρ$, $\semst{\pe}_ρ$ assigns $\pe$ a denotation $d$ in terms of
the semantic domain $\StateD$ of stateful call-by-need trace functions.
If such a trace function is supplied the heap $μ$ just before $\pe$ takes
control, then $d(μ)$ is a trace $τ$ starting at $\pe$ in that heap $μ$.
If evaluation of $\pe$ terminates, then $τ$ will be a finite list of states
ending with $\goodend{σ}$ for some return state $σ$. Otherwise, it might be
finite but stuck ($\stuckend{σ}$), or diverge without ever leaving $\pe$, in
which case $τ$ will be infinite.

Compared to the LK transition semantics, the most striking difference in state
structure is the lack of environment and stack components. The former is
maintained as a parameter to $\semst{\wild}$, while the latter is implicit in
the recursive call structure.
As we have seen in \Cref{sec:problem} at the example of $\semscott{\wild}$,
this reflection of machine state into ``math'' bears great potential for
program analysis, one we will exploit in \Cref{sec:abstractions}.
The second difference is that the environment $ρ$ and the heap $μ$ do not map to
addresses or syntactic closures but to delayed semantic values $\later \StateD$,
offering further abstraction possibilities compared to the rigid and indirect
syntactic domain.
The third difference is in control structure which explicitly signals the
distinction between evaluation states and return states.
In a return state $((\lbl,v),μ)$, the syntactic value's label $\lbl$ travels
together with a \emph{semantic} value $v ∈ \StateV$.
Crucially, this allows the embedding of function values $\FunV(f)$ in the
lambda case $\semst{\Lam{\px}{\pe}}$, enabling a compositional definition of the
application case $\semst{\pe~\px}$, just as in $\semscott{\wild}$.

It is worth noting that without guarded recursive types, the definition of
$\StateV$ would not be well-founded; a nuisance usually solved via restriction
to continuous functions on Scott domains and solving the corresponding domain
equation.

Note that we will continue to use the cons notation $τ \cons τ'$ quite liberally
to denote concatenation of traces. Doing so is unambiguous (because states are
distinct from traces) and well-defined via the following guarded fixpoint:
\[
  \fix (f : \later (\STraces \to \STraces \to \STraces)).\ λ(τ : \STraces)~(τ' : \STraces).\ \begin{cases}
    \stuckend{σ} & τ = \stuckend{σ} \\
    σ \cons τ'   & τ = \goodend{σ} \\
    σ \cons f \aplater τ^{\later} \aplater \purelater τ' & τ = σ \cons τ^{\later} \\
  \end{cases}
\]
We usually write $f \aplater τ^{\later} \aplater \purelater τ'$ with idiom
bracket notation as $\idiom{f(τ^{\later})(τ')}$.
A similar productive definition can be given for $\betastep$, which is to be
understood as yielding from the input trace $τ$ until it hits either end case of
the trace.
We have left out the idiom brackets to avoid distraction from the payload.

Intuitively, the heap lists the denotation of the expression bound at a
particular address, while the environment passed to $\semst{\wild}$ assigns each
free variable $\px$ a $\deref(\pa)$ action for the particular address that $\px$
should be bound to.

Let us now understand $\semst{\wild}$ by way of evaluating the example program
from earlier, $\pe \triangleq \Let{i}{\Lam{x}{x}}{i~i}$:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[mymatrixenv,anchor=center]
      \matrix [mymatrix] (m)
      {
        1 & (\pe, []) \cons {} & \hspace{3.7em} & \hspace{4.2em} & \hspace{3.9em} & \hspace{2.5em} \\
        2 & (i~i, μ) \cons {} & & & & \\
        3 & (i, μ) \cons {} & & & & \\
        4 & ((\Lam{x}{x}, \FunV(f)), μ) \cons {} & & & & \\
        5 & ((\Lam{x}{x}, \FunV(f)), μ) \cons {} & & & & \\
        6 & (x, μ) \cons {} & & & & \\
        7 & ((\Lam{x}{x}, \FunV(f)), μ) \cons {} & & & & \\
        8 & \goodend{((\Lam{x}{x}, \FunV(f)), μ)} & & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{8}{$\semst{\pe}_{[]}$}
      \myleftbrace{4}{1}{2}{$\BindT$}
      \myleftbrace{4}{2}{8}{$\semst{i~i}_{ρ_1}$}
      \myleftbrace{5}{2}{3}{$\AppIT$}
      \myleftbrace{5}{3}{5}{$\semst{i}_{ρ_1}$}
      \myleftbrace{5}{5}{6}{$\AppET$}
      \myleftbrace{5}{6}{8}{$\semst{x}_{ρ_2}$}
      \myleftbrace{6}{3}{4}{$\LookupT$}
      \myleftbrace{6}{4}{5}{$\UpdateT$}
      \myleftbrace{6}{6}{7}{$\LookupT$}
      \myleftbrace{6}{7}{8}{$\UpdateT$}
  \end{tikzpicture}
  $}} &
  \!\!\!\!\text{where}  \begin{array}{ll}
  ρ_1 = [i ↦ \deref(\pa_1)] & \\
  ρ_2 = ρ_1[x ↦ \deref(\pa_1)] &  \\
  μ = [\pa_1 ↦ \semst{\Lam{x}{x}}_{ρ_1}] & \\
  f = d \mapsto \semst{\px}_{ρ_1[\px↦d]}
  \end{array}
\end{array}\]
The annotations to the right of the trace can be understood as denoting the
``call graph'' of $\semst{\pe}_{[]}$, with the corresponding LK transitions
as leaves.
Evaluation begins with a $\BindT$ transition from state 1 to state 2.
A fresh address $\pa_1$ is allocated for variable $i$ and the heap is extended
with $\semst{\Lam{x}{x}}_{ρ_1}$.
It is interesting to realise that this process does not involve a fixpoint
despite the recursive semantics of let.
Of course, the self-application in $\deref$ does the job just as well, as we will
see in due course.

Evaluation recurses into the body $\semst{i~i}_{ρ_1}$ in the extended
environment $ρ_1$ to produce state 2, also yielding another $\AppIT$ transition
into $\semst{i}_{ρ_1}$.
Note that the target state 5 of $\semst{i}_{ρ_1}$ will later be fed (via
$\betastep$) into the anonymous function in $\apply$.
This scheme is quite common: Continuation items of the transition semantics
(``data'') are reflected into the call stack of the trace semantics (``code'').
The reverse process an be recognised as defunctionalisation~\citep{Reynolds:72}.

$\semst{i}_{ρ_1}$ guides the trace through a heap lookup:
A $\LookupT$ goes straight into the $\deref(\pa_1)$ action stored in the
environment entry for $i$, which performs the aforementioned self-application
to run the heap action $μ(\pa_1) = \semst{\Lam{x}{x}}_{ρ_1}$ starting in the
current heap $μ$.
Evaluation of $\semst{\Lam{x}{x}}_{ρ_1}$ terminates immediately in return state
4.
Returning to $\deref(\pa_1)$, we witness for the first time a reduction
operation via $\betastep$:
Since the trace terminates, the anonymous function in $\deref(\pa_1)$ is called
(in $\betastep$) with state 4, making an $\UpdateT$ transition to state 5.
Note that there is no observable change to the heap $μ$ because
$\ret(\Lam{x}{x}, \FunV(f))$ is precisely the same as $\semst{\Lam{x}{x}}_{ρ_1}$.

After the heap update we leave $\semst{i}$ in return state 5, where $\betastep$
yields to the anonymous function in $\apply$ (from the call to
$\semst{i~i}_{ρ_1}$), yielding another $\AppET$ reduction and giving control
to $f(ρ_1(i)) = \semst{x}_{ρ_1[x ↦ ρ_1(i)]}$.
Since $x$ is an alias for $i$, steps 6 to 8 just repeat the same same heap
update sequence we observed in steps 3 to 5, concluding the example.

It is useful to review another example involving an observable heap
update. The following trace begins right before the heap update occurs in
$\Let{i}{(\Lam{y}{\Lam{x}{x}})~i}{i~i}$, that is, after reaching the value
in $\semst{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1}$:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[baseline={-0.5ex},mymatrixenv]
      \matrix [mymatrix] (m)
      {
        1 & ((\Lam{x}{x},\FunV(f)), μ_1) \cons {} & \hspace{4em} & \hspace{4em} & \hspace{2.5em} \\
        2 & ((\Lam{x}{x},\FunV(f)), μ_2) \cons {} & & & \\
        3 & (x, μ_2) \cons {} & & & \\
        4 & ((\Lam{x}{x}, \FunV(f)), μ_2) \cons {} & & & \\
        5 & \goodend{((\Lam{x}{x}, \FunV(f)), μ_2)} & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{5}{$\semst{i~i}_{ρ_1}$}
      \myleftbrace{4}{1}{2}{$\semst{i}_{ρ_1}$}
      \myleftbrace{4}{2}{3}{$\AppET$}
      \myleftbrace{4}{3}{5}{$\semst{x}_{ρ_3}$}
      \myleftbrace{5}{1}{2}{$\UpdateT$}
      \myleftbrace{5}{3}{4}{$\LookupT$}
      \myleftbrace{5}{4}{5}{$\UpdateT$}
    \end{tikzpicture}
  $}} &
  \!\!\!\text{where} \begin{array}{l}
  ρ_1 = [i ↦ \pa_1] \\
  ρ_2 = [i ↦ \pa_1, y ↦ \pa_1] \\
  ρ_3 = [i ↦ \pa_1, y ↦ \pa_1, x ↦ \pa_1] \\
  μ_1 = [\pa_1 ↦ \semst{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1}] \\
  μ_2 = [\pa_1 ↦ \semst{\Lam{x}{x}}_{ρ_2}] \\
  f = \fn{d}{\semst{\px}_{ρ_2[\px↦d]}} \\
  \end{array} \\
\end{array}\]
Note that both the denotation in the heap \emph{and} its environment are updated
in state 2, and that the new denotation is immediately visible on the next heap
lookup in state 3, so that $\semst{\Lam{x}{x}}_{ρ_2}$ takes control rather than
$\semst{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1}$, just as the transition system requires.

The handling of data types and case expressions is routine (if a bit
syntactically heavy) and not different to denotational semantics in call-by-name
or call-by-value.
It is a useful inclusion because it allows us to observe type errors other than
scoping errors.
Let us consider evaluation of the closed expression
$\pe \triangleq \Let{x}{\ttrue}{\ttrue~x}$
(where $\ttrue$ is one of two nullary data constructors of the data type $\bool
::= \ttrue \mid \ffalse$).
$\semst{\wild}$ makes it is easy to observe that the trace gets stuck:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[baseline={-0.5ex},mymatrixenv]
      \matrix [mymatrix] (m)
      {
        1 & (\pe, []) \cons {} & \hspace{4em} & \hspace{5em} & \hspace{2.5em} \\
        2 & (\ttrue~x, μ) \cons {} & & & \\
        3 & \stuckend{((\ttrue,\ConV(\ttrue)), μ)} & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{3}{$\semst{\pe}_{[]}$}
      \myleftbrace{4}{1}{2}{$\BindT$}
      \myleftbrace{4}{2}{3}{$\semst{\ttrue~x}_{ρ}$}
      \myleftbrace{5}{2}{3}{$\AppIT$}
    \end{tikzpicture}
  $}} &
  \!\!\!\text{where} \begin{array}{l}
  ρ = [x ↦ \pa_1] \\
  μ = [\pa_1 ↦ \semst{\ttrue}_ρ] \\
  \end{array} \\
\end{array}\]
Crucially, $\betastep$ is equipped to propagate $\stuckend{\wild}$ up the call
stack (through potential $\UpdateT$ transitions, in particular), similar to
\citeauthor{Milner:78}'s $\mathbf{wrong}$.

Diverging traces hold no new surprises, other than they are observably different
to stuck traces.

\subsection{Maximal LK Traces}
\label{sec:maximal-traces}

It turns out that the traces $\semst{\pe}$ generates correspond to
\emph{maximal} traces in the LK transition system.
Let us make precise what that means.

A transition system is characterised by the set of \emph{traces} it generates.
An \emph{LK trace} is a trace in $(\smallstep)$, \eg, a non-empty and
potentially infinite sequence of LK states $(σ_i)_{i∈\overline{n}}$
(where $\overline{n} = \{ m ∈ ℕ_+ \mid m ≤ n \}$ when $n∈ℕ_+$, $\overline{ω} = ℕ_+$),
such that $σ_i \smallstep σ_{i+1}$ for $i,(i+1)∈\overline{n}$.

The \emph{source} state $σ_1$ exists for finite and infinite traces, while the
\emph{target} state $σ_n$ is only defined when $n \not= ω$ is finite.

For proofs, we will often regard $(σ_i)_{i∈\overline{n}}$ as an object of type
$\LKTraces \triangleq ∃n∈ℕ_ω.\ \overline{n} \to \States$, where $ℕ_ω$ is defined by guarded recursion
as $ℕ_ω = \{1\} + \later ℕ_ω$.
The constructor for the right sum alternative is written $\mathit{succ}$.
Now $ℕ_ω$ contains all natural numbers (where $n$ is encoded as
$(\mathit{succ})^{n-1}(1)$) and the transfinite limit ordinal
$ω = \mathit{succ}(\mathit{succ}(...))$.
We will write $1+m$ to denote $\mathit{succ}(m)$ (a different kind of $+$ than
in the recursive equation for $ℕ_ω$), just as we are used to from $ℕ_+$.
Hence, when $(σ_i)_{i∈\overline{n}} ∈ \LKTraces$ is an LK trace and $n > 1$, then
$(σ_{i+1})_{i∈\overline{n-1}} ∈ \later \LKTraces$ is the guarded tail of the
trace with an associated induction principle.

An important kind of trace is one that never leaves the evaluation context of
its source state:

\begin{definition}[Deep, interior and balanced traces]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is
  \emph{$κ$-deep} if every intermediate continuation
  $κ_i = \cont(σ_i)$ extends $κ$ (so $κ_i = κ$ or $κ_i = ... \pushF κ$,
  abbreviated $κ_i = ...κ$).

  A trace $(σ_i)_{i∈\overline{n}}$ is called \emph{interior} if it is
  $\cont(σ_1)$-deep.
  Furthermore, an interior trace $(σ_i)_{i∈\overline{n}}$ is
  \emph{balanced}~\citep{Sestoft:97} if the target state exists and is a return
  state with continuation $κ_1$.

  We notate $κ$-deep, interior and balanced traces as
  $\deep{κ}{(σ_i)_{i∈\overline{n}}}$, $\interior{(σ_i)_{i∈\overline{n}}}$ and
  $\balanced{(σ_i)_{i∈\overline{n}}}$, respectively.
\end{definition}

\begin{example}
  Let $ρ=[x↦\pa_1],μ=[\pa_1↦([], \Lam{y}{y})]$ and $κ$ an arbitrary
  continuation. The trace
  \[
     (x, ρ, μ, κ) \smallstep (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, κ)
  \]
  is interior and balanced. Its prefixes are interior but not balanced.
  The trace suffix
  \[
     (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, κ)
  \]
  is neither interior nor balanced.
\end{example}

We will say that the transition rules $\LookupT$, $\AppIT$, $\CaseIT$ and $\BindT$
are interior, because the lifting into a trace is, whereas the returning
transitions $\UpdateT$, $\AppET$ and $\CaseET$ are not.

A balanced trace starting at a focus expression $\pe$ and ending with $\pv$
loosely corresponds to a derivation of $\pe \Downarrow \pv$ in a natural
big-step semantics~\citep{Sestoft:97} or a non-$⊥$ result in a denotational
semantics.

It is when a derivation in a natural semantics does not exist that a small-step
semantics shows finesse, in that it differentiates two different kinds of
\emph{maximally interior} (or, just \emph{maximal}) traces:

\begin{definition}[Maximal trace]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is \emph{maximal} if and only if it is
  interior and there is no $σ_{n+1}$ such that $(σ_i)_{i∈\overline{n+1}}$ is
  interior.
  More formally (and without a negative occurrence of ``interior''),
  \[
    \maxtrace{(σ_i)_{i∈\overline{n}}} \triangleq \interior{(σ_i)_{i∈\overline{n}}} \wedge (\not\exists σ_{n+1}.\ σ_n \smallstep σ_{n+1} \wedge \cont(σ_{n+1}) = ...\cont(σ_1))
  \]
  We notate maximal traces as $\maxtrace{(σ_i)_{i∈\overline{n}}}$.
\end{definition}

We call infinite and interior traces \emph{diverging}.
A maximally finite, but unbalanced trace is called \emph{stuck}.
Note that usually stuckness is associated with a state of a transition
system rather than a trace.
That is not possible in our framework; the following example clarifies.

\begin{example}[Stuck and diverging traces]
Consider the interior trace
\[
             (\ttrue~x, [x↦\pa_1], [\pa_1↦...], κ)
  \smallstep (\ttrue, [x↦\pa_1], [\pa_1↦...], \ApplyF(\pa_1) \pushF κ)
\]
It is stuck, but its singleton suffix is balanced.
An example for a diverging trace where $ρ=[x↦\pa_1]$ and $μ=[\pa_1↦(x,ρ,())]$ is
\[
  (\Let{x}{x}{x}, [], [], κ) \smallstep (x, ρ, μ, κ) \smallstep (x, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep ...
\]
\end{example}

A maximal trace that is not balanced either diverges or is stuck:

\begin{lemma}[Characterisation of maximal traces]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is maximal if and only if it is balanced,
  diverging or stuck.
\end{lemma}
\begin{proof}
  $\Rightarrow$: Let $(σ_i)_{i∈\overline{n}}$ be maximal.
  If $n=ω$ is infinite, then it is diverging due to interiority, and if
  $(σ_i)_{i∈\overline{n}}$ is stuck, the goal follows immediately.
  So we assume that $(σ_i)_{i∈\overline{n}}$ is maximal, finite and not stuck,
  so it must be balanced by the definition of stuckness.

  $\Leftarrow$: Both balanced and stuck traces are maximal.
  A diverging trace $(σ_i)_{i∈\overline{n}}$ is interior and infinite,
  hence $n=ω$.
  Indeed $(σ_i)_{i∈\overline{ω}}$ is maximal, because the expression $σ_ω$
  is undefined and hence does not exist.
\end{proof}

Interiority guarantees that the particular initial stack $κ$ of a maximal trace
is irrelevant to execution, so maximal traces that differ only in the initial
stack are bisimilar.

One class of maximal traces is of particular interest:
The maximal trace starting in $\inj(\pe)$ (or, rather whether it is infinite,
stuck or balanced) is the defining operational characteristic of $\pe$.

If we can show that $\semst{\pe}$ associates similar meaning to $\pe$, we have
proven it an adequate replacement for the LK transition system.

\subsection{Adequacy}

\Cref{fig:semst-correctness} shows the correctness predicate $\mathcal{C}$ in
our endeavour to prove $\semst{\wild}$ adequate.
It builds on the framework of maximal LK traces established in the last section;
specifically it encodes that an abstraction of every maximal LK trace can be
recovered by running $\semst{\wild}$ starting from the abstraction of an initial
state.

\begin{figure}
\[\begin{array}{rcl}
  α_\Environments(ρ) & = & \deref \circ ρ \\
  α_\Heaps([\many{\pa ↦ (ρ,\pe)}]) & = & [\many{\pa ↦ \idiom{\semst{\pe}_{α_\Environments(ρ)}}}] \\
  α_\States(\slbl \Lam{\px}{\pe},ρ,μ,κ) & = & ((\lbl,\FunV(\fn{d^\later}{\idiom{\semst{\pe}_{α_\Environments(ρ)[\px↦d^\later]}}})),α_\Heaps(μ)) \\
  α_\States(\slbl K~\overline{\px},ρ,μ,κ) & = & ((\lbl,\ConV(K,\overline{\idiom{\semst{\px}_{α_\Environments(ρ)}}})),α_\Heaps(μ)) \\
  α_\States(\pe,ρ,μ,κ) & = & (\pe,α_\Heaps(μ)) \\
  α_{\STraces}((σ_i)_{i∈\overline{n}},κ) & = & \begin{cases}
    α_\States(σ_1) \cons \idiom{α_{\STraces}((σ_{i+1})_{i∈\overline{n-1}},κ)} & n > 1 \\
    \goodend{α_\States(σ_1)} & \ctrl(σ_1) \text{ value } \wedge \cont(σ_1) = κ \\
    \stuckend{α_\States(σ_1)} & \text{otherwise} \\
  \end{cases} \\
  \mathcal{C}((σ_i)_{i∈\overline{n}}) & = & \maxtrace{(σ_i)_{i∈\overline{n}}} \Longrightarrow ∀((\pe,ρ,μ,κ) = σ_1).\ α_{\STraces}((σ_i)_{i∈\overline{n}},κ) = \semst{\pe}_{α_\Environments(ρ)}(α_\Heaps(μ)) \\
\end{array}\]
\caption{Correctness predicate for $\semst{\wild}$, defining the family of functions $α_\LKStates$}
  \label{fig:semst-correctness}
\end{figure}

The family of abstraction functions (which we henceworth refer to as
$α_\LKStates$ and treat as overloaded for $\Environments,\Heaps,\States$ and
$\STraces$) makes precise the intuitive connection between the semantic objects
in $\semst{\wild}$ and the syntactic objects in the transition system.

We will sometimes need to disambiguate the clashing definitions from
\Cref{sec:stateful} and \Cref{sec:problem}.
We do so by adorning semantic objects with a tilde, so $\tr \triangleq
α_\Environments(ρ)$ denotes a semantic environment which in this instance is
defined to be the abstraction of a syntactic environment $ρ$.

Note first that $α_\STraces$ is defined by guarded recursion over
the LK trace, in the sense defined in \Cref{sec:maximal-traces}.
As such, the expression $\idiom{α_{\STraces}((σ_{i+1})_{i∈\overline{n-1}},κ)}$ has type
$\later \tSTraces$ (the $\later$ in the type of $(σ_{i+1})_{i∈\overline{n-1}}$
maps through $α_\STraces$ via the idiom brackets).
Likewise, $=$ on $\tSTraces$ is defined in the obvious structural way by guarded
recursion (as it would be if it was a finite, inductive type).

Our first goal is to establish a few auxiliary lemmas showing what kind of
properties of LK traces are preserved by $α_\States$ and in which way.

Let us warm up by defining a length function on traces:
\begin{definition}[Length of a trace]
  \label{defn:length}
  The \emph{length} $\len : \tSTraces \to ℕ_ω$ of a trace is defined by
  guarded recursion
  \[
    \len(τ) = \begin{cases}
      1 + \purelater \len \aplater τ^{\later} & τ = σ \cons τ^{\later} \\
      1 & \text{otherwise} \\
    \end{cases}
  \]
\end{definition}

\begin{lemma}[Preservation of length]
  \label{thm:abs-length}
  Let $(σ_i)_{i∈\overline{n}}$ be an arbitrary trace.
  Then $\len(α_\STraces((σ_i)_{i∈\overline{n}},\cont(σ_1))) = n$.
\end{lemma}
\begin{proof}
  This is quite simple to see and hence a good opportunity to familiarise
  ourselves with the concept of \emph{Löb induction}, the induction principle of
  guarded recursion.
  Löb induction arises simply from applying the guarded recursive fixpoint
  combinator to a proposition:
  \[
    \textsf{löb} = \fix : \forall P.\ (\later P \Longrightarrow P) \Longrightarrow P
  \]
  That is, we assume that our proposition holds \emph{later}, \eg
  \[
    IH ∈ (\later P \triangleq \later (
        \forall n ∈ ℕ_ω.\
        \forall (σ_i)_{i∈\overline{n}}.\
        \len(α_\STraces((σ_i)_{i∈\overline{n}},\cont(σ_1))) = n
      ))
  \]
  and use $IH$ to prove $P$.
  Let us assume $n$ and $(σ_i)_{i∈\overline{n}}$ are given, define
  $τ \triangleq α_\STraces((σ_i)_{i∈\overline{n}},\cont(σ_1))$ and proceed by case analysis
  over $n$:
  \begin{itemize}
    \item \textbf{Case $n=1$}: Then we have $j = 1$ and either $τ = \goodend{α_\States(σ_1)}$
      or $τ = \stuckend{α_\States(σ_1)}$, both of which map to $1$ under
      $\len$.
    \item \textbf{Case $n>1$}: Then $n = 1+m$ and $m ∈ \later ℕ_ω$ and the
      first case of $α_\States$ applies, hence $τ = σ \cons τ^{\later}$ for some
      $σ∈\States, τ^{\later}∈\later \tSTraces$.
      Now we apply the inductive hypothesis, as follows:
      Let $(σ_{i+1})_{i∈\overline{m}} ∈ \later \STraces$ be the guarded
      tail of the LK trace $(σ_i)_{i∈\overline{n}}$.
      Then we can apply $IH \aplater m \aplater (σ_{i+1})_{i∈\overline{m}}$ and
      get a proof for $\later (\len(τ^{\later}) = m)$.
      Now we can prove
      \[
        n = 1 + m = 1 + \len(τ^{\later}) = \len(τ).
      \]
  \end{itemize}
\end{proof}

\begin{lemma}[Preservation of components]
  \label{thm:abs-states}
  Let $(σ_i)_{i∈\overline{n}}$ be a trace and let $τ = α_\STraces((σ_i)_{i∈\overline{n}},\cont(σ_1))$.
  Then for all $j∈\overline{n}$, $τ_j = α_\States(σ_j)$
  (where $τ_j$ denotes the $j$th state in $τ$).
\end{lemma}
\begin{proof}
  With \Cref{thm:abs-length} it is enough to regard the finite prefix of the
  trace $(σ_i)_{i∈\overline{j}}$, for which the proposition is easily shown by
  induction on $j$.
\end{proof}

\begin{lemma}[Preservation of characteristic]
  \label{thm:abs-max-trace}
  Let $(σ_i)_{i∈\overline{n}}$ be a maximal trace.
  Then $α_\STraces((σ_i)_{i∈\overline{n}}, cont(σ_1))$ is ...
  \begin{itemize}
    \item ... infinite if and only if $(σ_i)_{i∈\overline{n}})$ is diverging
    \item ... ending with $\goodend{\wild}$ if and only if $(σ_i)_{i∈\overline{n}}$ is balanced
    \item ... ending with $\stuckend{\wild}$ if and only if $(σ_i)_{i∈\overline{n}}$ is stuck
  \end{itemize}
\end{lemma}
\begin{proof}
  The first point follows by a similar inductive argument as in \Cref{thm:abs-length}.

  In the other cases, we may assume that $n$ is finite.
  If $(σ_i)_{i∈\overline{n}}$ is balanced, then $σ_n$ is a return state with
  continuation $\cont(σ_1)$, so its control expression is a value.
  Then $α_\STraces$ will conclude with $\goodend{\wild}$.
  Conversely, if the trace ended with $\goodend{\wild}$, then $\cont(σ_n) = \cont(σ_1)$
  and $\ctrl(σ_n)$ is a value, so $(σ_i)_{i∈\overline{n}}$ forms a
  balanced trace.
  The stuck case is similar.
\end{proof}

The previous lemma is interesting as it allows us to apply the classifying
terminology of interior traces to a $τ$ that is an abstraction of a
\emph{maximal} LK trace.
For such a maximal $τ$ we will say that it is balanced when it ends with
$\goodend{\wild}$, stuck if ending in $\stuckend{\wild}$ and diverging if
infinite.

With increased clarity, we go on to prove the correctness predicate:

\begin{theorem}[Correctness of $\semst{\wild}$]
  \label{thm:semst-correct}
  $\mathcal{C}$ from \Cref{fig:semst-correctness} holds.
  That is, whenever $(σ_i)_{i∈\overline{n}}$ is a maximal LK trace with source
  state $(\pe,ρ,μ,κ)$, we have
  $α_{\STraces}((σ_i)_{i∈\overline{n}},κ) = \semst{\pe}_{α_\Environments(ρ)}(α_\Heaps(μ))$.
\end{theorem}
\begin{proof}
By Löb induction, with $IH ∈ \later C$ as the hypothesis.

We will say that an LK state $σ$ is stuck if there is no applicable rule in the
transition system (\ie, the singleton LK trace $σ$ is maximal and stuck).

Now let $(σ_i)_{i∈\overline{n}}$ be a maximal LK trace with source state
$σ_1=(\pe,ρ,μ,κ)$ and let $τ = \semst{\pe}_{α_\Environments(ρ)}(α_\Heaps(μ))$.
Then the goal is to show $α_{\STraces}((σ_i)_{i∈\overline{n}},κ) = τ$.
We do so by cases over $\pe$, abbreviating $\tm \triangleq α_\Heaps(μ), \tr
\triangleq α_\Environments(ρ)$:
\begin{itemize}
  \item \textbf{Case $\px$}:
    Let us assume first that $σ_1$ is stuck. Then $\px \not∈ ρ$ (because
    $\LookupT$ is the only transition that could apply) and hence $\px \not∈
    \tr$ either; hence $τ = \stuckend{(\px, \tm)}$ and the goal follows from
    \Cref{thm:abs-max-trace}.

    Otherwise, $σ_2 \triangleq (\pe', ρ', μ, \UpdateF(\pa) \pushF κ), σ_1 \smallstep σ_2$
    via $\LookupT$, and $ρ(\px) = \pa, μ(\pa) = (ρ', \pe')$.
    The equality between the head of $τ$ and $α_\States(σ_1)$ follows as in the
    stuck case.
    To show that the tails equate, it suffices to show that they equate \emph{later}.

    Let us abbreviate $\tr' \triangleq α_\Environments(ρ')$.
    Then we can infer that $\tm(\pa) = \idiom{\semst{\pe'}_{\tr'}}$, as well as
    \[
    \tr(\px)(\tm) = \semst{\pe'}_{\tr'}(\tm) \betastep \fn{((\lbl,v),μ)}{\idiom{\goodend{((\lbl,v),μ[\pa ↦ \ret(\lbl,v)])}}}
    \]
    from the definition of $α_\Environments$.

    Let us define $τ^\later \triangleq \idiom{\semst{\pe'}_{\tr'}(\tm)}$ and
    apply the induction hypothesis $IH$ to the maximal trace starting at $σ_2$.
    This yields an equality
    \[
      IH \aplater (σ_{i+1})_{i∈\overline{m}} ∈ \idiom{α_\STraces((σ_{i+1})_{i∈\overline{m}},\UpdateF(\pa) \pushF κ) = τ^{\later}}
    \]
    When $τ^{\later}$ is infinite, we are done. Similarly, if $τ^{\later}$ ends
    in $\stuckend{\wild}$ then $\betastep$ will return $τ^{\later}$, indicating
    by \Cref{thm:abs-length} and \Cref{thm:abs-max-trace} that
    $(σ_{i+1})_{i∈\overline{n-1}}$ is stuck and hence $(σ_i)_{i∈\overline{n}}$
    is, too.

    Otherwise $τ^{\later}$ ends with $\goodend{\tilde{σ}_m}$ and by
    \Cref{thm:abs-max-trace} $(σ_{i+1})_{i∈\overline{m}}$ is balanced; hence
    $\cont(σ_m) = \UpdateF(\pa) \pushF κ$ and $\ctrl(σ_m)$ is a value.
    So $σ_m = (\pv,ρ_m,μ_m,\UpdateF(\pa) \pushF κ)$ and the
    $\UpdateT$ transition fires, reaching $(\pv,ρ_m,μ_m[\pa ↦ (ρ_m, \pv)],κ)$
    and this must be the target state $σ_n$, because it remains a return state
    and has continuation $κ$, so $(σ_i)_{i∈\overline{n}}$ is balanced.
    Likewise, $\tilde{σ}_m \triangleq α_\States(σ_m) = ((\lbl,v),\tm_m)$ is the
    state that $τ^{\later}$ ends in and is a return state, so $\betastep$ calls
    its second argument which makes another step to the target state of $τ$,
    updating the heap to
    \[
      \tilde{σ}_n \triangleq ((\lbl,v),\tm_m[\pa ↦ \ret(\lbl,v)]) = ((\lbl,v),\tm_m[\pa ↦ \semst{\pv}_{α_\Environments(ρ_m)}]) = α_\States(σ_n),
    \]
    and this equality concludes the proof.

  \item \textbf{Case $\pe~\px$}:
    The cases where $τ$ gets stuck or diverges before finishing evaluation of
    $\pe$ are similar to the variable case.

    So let us focus on the situation when $τ^{\later} \triangleq
    \idiom{\semst{\pe}_{\tr'}(\tm)}$ returns and let $σ_m$ be LK state at the
    end of the finite maximal trace $(σ_{i+1})_{i∈\overline{m-1}}$ through $\pe$
    starting in stack $\ApplyF(\pa) \pushF κ$.
    Since it is maximal, any transition $σ_m \smallstep σ_{m+1}$ must leave
    the stack $\ApplyF(\pa) \pushF κ$, necessarily by an $\AppET$ transition.
    That in turn means that the value in $\ctrl(σ_m)$ must be a lambda
    $\Lam{\py}{\pe'}$, hence $τ^{\later}$ ends in $\goodend{\tilde{σ}_m}$,
    where
    $\tilde{σ}_m \triangleq (\lbl, \FunV(\fn{d^\later}{\idiom{\semst{\pe'}_{\tr_m[\py ↦ d^\later]}}}), \tm_m) = σ_\States(σ_m)$,
    assuming that $\lbl$ is the label of the lambda and $\tr_m, \tm_m$ correspond
    to $ρ_m,μ_m$ of $σ_m$ as usual.

    Now let $(σ_{i+m})_{i∈\overline{k}}$ be the maximal trace starting at
    $σ_{m+1}=(\pe',ρ_m[\py↦\pa], μ_m,κ)$.
    We can apply the induction hypothesis to this LK trace and
    $τ_2^{\later} \triangleq \idiom{\semst{\pe'}_{\tr_m}(\tm_m[\py↦\deref(\pa))}$
    to get the equality
    $\idiom{α_\STraces((σ_{i+m})_{i∈\overline{k}},κ) = τ_2^{\later}}$.
    From this and our earlier equalities, we get
    $α_\STraces((σ_i)_{i∈\overline{n}},κ) = τ$, concluding the proof.

  \item \textbf{Case $\Case{\pe_s}{\Sel[r]}$}:
    Similar to the application and lookup case.

  \item \textbf{Cases $\Lam{\px}{\pe}$, $K~\many{\px}$}:
    The length of both traces is $n = 1$ and the goal follows by simple calculation.

  \item \textbf{Case $\Let{\px}{\pe_1}{\pe_2}$}:
    The equality on the source states holds as in the other cases.
    Let $σ_1 = (\Let{\px}{\pe_1}{\pe_2},ρ_1,μ_1,κ)$.
    Then $σ_2 = (\pe_2, ρ_2, μ_2,κ)$ by $\BindT$, where $ρ_2 = ρ_1[\px↦\pa], μ_2
    = μ_1[\pa↦(ρ_2,\pe_1)]$.
    Since the stack does not grow, maximality from the tail $(σ_{i+1})_{i∈\overline{n-1}}$
    transfers to $(σ_{i})_{i∈\overline{n}}$.
    Straightforward application of the induction hypothesis to
    $(σ_{i+1})_{i∈\overline{n-1}}$ yields the equality for the tail (after a bit
    of calculation for the updated environment and heap), which concludes the
    proof.
\end{itemize}
\end{proof}

\Cref{thm:semst-correct} and \Cref{thm:abs-max-trace} are the key to proving a
strong version of adequacy for $\semst{\wild}$, where $σ$ is defined to be a
\emph{final} state if $\ctrl(σ)$ is a value and $\cont(σ) = \StopF$.

\begin{theorem}[Adequacy of $\semst{\wild}$]
  \label{thm:semst-adequate}
  Let $τ = \semst{\pe}_{[]}([])$.
  \begin{itemize}
    \item
      $τ$ ends with $\goodend{\wild}$ (is balanced) iff there exists a final
      state $σ$ such that $\inj(\pe) \smallstep^* σ$.
    \item
      $τ$ ends with $\stuckend{\wild}$ (is stuck) iff there exists a non-final
      state $σ$ such that $\inj(\pe) \smallstep^* σ$ and there exists no $σ'$
      such that $σ \smallstep σ'$.
    \item
      $τ$ is infinite (is diverging) iff for all $σ$ with $\inj(\pe)
      \smallstep^* σ$ there exists $σ'$ with $σ \smallstep σ'$.
  \end{itemize}
\end{theorem}
\begin{proof}
  There exists a maximal trace $(σ_i)_{i∈\overline{n}}$ starting
  from $σ_1 = \inj(\pe)$, and by \Cref{thm:semst-correct} we have
  $α_\STraces((σ_i)_{i∈\overline{n}},\StopF) = τ$.
  \begin{itemize}
    \item[$\Rightarrow$]
      \begin{itemize}
        \item
          If $(σ_i)_{i∈\overline{n}}$ is balanced, its target state $σ_n$
          is a return state that must also have the empty continuation, hence it
          is a final state.
        \item
          If $(σ_i)_{i∈\overline{n}}$ is stuck, it is finite and maximal, but not balanced, so its
          target state $σ_n$ cannot be a return state;
          otherwise maximality implies $σ_n$ has an (initial) empty continuation
          and the trace would be balanced. On the other hand, the only returning
          transitions apply to return states, so maximality implies there is no
          $σ'$ such that $σ \smallstep σ'$ whatsoever.
        \item
          If $(σ_i)_{i∈\overline{n}}$ is diverging, $n=ω$ and for every $σ$ with
          $\inj(\pe) \smallstep^* σ$ there exists an $i$ such that $σ = σ_i$ by
          determinism.
      \end{itemize}

    \item[$\Leftarrow$]
      \begin{itemize}
        \item
          If $σ_n$ is a final state, it has $\cont(σ) = \cont(\inj(\pe)) = []$,
          so the trace is balanced.
        \item
          If $σ$ is not a final state, $τ'$ is not balanced. Since there is no
          $σ'$ such that $σ \smallstep^* σ'$, it is still maximal; hence it must
          be stuck.
        \item
          Suppose that $n∈ℕ_ω$ was finite.
          Then, if for every choice of $σ$ there exists $σ'$ such that $σ
          \smallstep σ'$, then there must be $σ_{n+1}$ with $σ_n \smallstep
          σ_{n+1}$, violating maximality of the trace.
          Hence it must be infinite.
          It is also interior, because every stack extends the empty stack,
          hence it is diverging.
      \end{itemize}
  \end{itemize}
\end{proof}

\subsection{Discussion}

We can already give perspective on two of the goals we set ourselves in
\Cref{sec:problem}:

As the domain $\StateD$ of our semantics $\semst{\wild}$ is one defined by
guarded recursion, the approximation order between elements of the domain is
discrete and all elements are total.
$\semst{\wild}$ is formulated entirely within this internal language and as
such, looping programs are denoted by total elements as well,
fullfilling Goal 3.

From a trace generated by $\semevt{\wild}$ we can recover (on an ass-needed
basis) fine-grained operational detail such as the transition rules taken, so
any such trace-based semantics satisfies Goal 2.
