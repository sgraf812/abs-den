\section{Abstract Interpretation}
\label{sec:abstractions}

\subsection{Lazy Denotational Deadness}

Let us now finally try to reformulate semantic deadness in terms of
$\semevt{\wild}$ and $\equiv$:

\begin{definition}[Denotational deadness, lazily]
  \label{defn:deadness3}
  An address $\pa$ is \emph{dead} in a denotation $d$ if and only if,
  for all $μ_1 \approx μ_2$ such that $\pa$ is dead in $\rng(μ_i)$,
  $\dom(μ_1) ∪ \{\pa\} ⊦ d$ and $d_1,d_2$, we have
  \[
    \dom(μ_1) ⊦ d(μ_1[\pa↦d_1]) \sim d(μ_2[\pa↦d_2]).
  \]
  A variable $\px$ is \emph{dead} in an expression $\pe$ if and only if
  any $\pa$ is dead in $\semevt{\pe}_{ρ[\px↦\pa]}$ for any $ρ$ such
  that $\pa \not∈ \rng(ρ)$.
  Otherwise, $\px$ is \emph{live}.
\end{definition}

\begin{lemma}[Deadness implies irrelevance]
  If $\px$ is dead in $\pe$,
  then for all $ρ, \pe_1,\pe_2$,
  \[\semevt{\Let{\px}{\pe_1}{\pe}}_{ρ} \equiv \semevt{\Let{\px}{\pe_2}{\pe}}_{ρ}.\]
\end{lemma}
\begin{proof}
  Assume that $\pa$ is dead in $\semevt{\pe}_{ρ[\px↦\pa]}$ for any
  $ρ$ such that $\pa \not∈ \rng(ρ)$.
  To show that
  \[
    \semevt{\Let{\px}{\pe_1}{\pe}}_ρ \equiv \semevt{\Let{\px}{\pe_1}{\pe}}_ρ,
  \]
  we assume that $μ_1 \approx μ_2$ for arbitrary $μ_1,μ_2$ (satisfying
  well-addressedness constraints) and show that
  \[
    \dom(μ_1) ⊦ \semevt{\Let{\px}{\pe_1}{\pe}}_{ρ}(μ_1) \sim \semevt{\Let{\px}{\pe_2}{\pe}}_{ρ}(μ_2)
  \]
  We unfold the $\mathbf{let}$ case of $\semevt{\wild}$ and show
  \[
    \dom(μ_1) ⊦ \semevt{\pe}_{ρ[\px↦\pa]}(μ_1[\pa↦d_1]) \sim \semevt{\pe}_{ρ[\px↦\pa]}(μ_2[\pa↦d_2])
  \]
  For arbitrary $d_1,d_2$ (which we may set to
  $d_i \triangleq \memo(\pa,\semevt{\pe_i}_{ρ[\px↦\pa]})$).
  But $\pa \not∈ \rng(ρ)$ due to \Cref{thm:well-addressedness},
  so $\pa$ is dead in $\semevt{\pe}_{ρ[\px↦\pa]}$ per assumption.
  Hence we can show the goal, applying to $μ_1 \approx μ_2$.
\end{proof}

So if $x$ is dead in $\pe_2$, we can justify the following rewrite by
irrelevance:
\[
  \Let{x}{\pe_1}{\pe_2} \equiv \Let{x}{\mathit{panic}}{\pe_2}
\]
A syntactic \emph{occurrence analysis} could subsequently figure out whether the
binding for $x$ can be dropped without introducing scoping errors, a feat
that becomes far simpler once huge expressions $\pe_1$ are turned into small
$\mathit{panic}$s.

We can now prove \Cref{thm:semusg-correct-live} in terms of this new
characterisation of deadness by induction:

\begin{theorem}[$\semusg{\wild}$ is a correct deadness analysis]
  \label{thm:semusg-correct-live-3}
  Let $\pe$ be an expression, $\px$ a variable and $\tr$ a usage environment.
  If $\tr(\px) \not⊑ \semusg{\pe}_{\tr}$
  then $\px$ is dead in $\pe$.
\end{theorem}
\begin{proof}
  By induction over $\pe$.
  The full proof can be found in \Cref{prf:semusg-correct-live-3}.
\end{proof}

\subsection{Discussion}

The main proof of \Cref{thm:semusg-correct-live-3} is hardly longer than
\Cref{thm:semusg-correct-live}, but we have to admit that we needed to prove
quite a few metatheoretic properties to get there, so we declare only partial
victory on Goal 1 from \Cref{sec:problem}.
For obvious reasons, it seems preferable to stick to a simpler call-by-name
semantics without a heap if the property in question (\eg, deadness) can be
understood there as well.

Still, with \Cref{defn:deadness3} we were at least able to break
down the proof into manageable intermediate steps.
That is a huge step forward compared to the operational deadness definition of
\Cref{defn:deadness2} where we weren't even able to come up with a suitable
correctness relation.

In hindsight, we could trace back the intermediate steps to come up with at
least one proof strategy with \Cref{defn:deadness2}:
The structural induction principle is an important enabling factor and
the focus on maximal traces in \Cref{fig:semvan-correctness} suggests that
we should likely strive for a correctness relation characterising a property of
maximal traces.
This was not obvious to us when we first set out to do the proof; the gap was
too large to see how to get to the other side due to the structural mismatch.
A nice consequence of successfully avoiding structural mismatch, which we set
out to in Goal 4.

\subsection{Improvement}

Proving that dead bindings can be soundly rewritten is a nice litmus test
for the semantics.
But does it really make the program faster, or at least not slower?

We can affirm that indirectly:
A diverging program $\mathit{loop}$ takes more steps than a stuck program
$\mathit{panic}$, hence the former runs ``slower'' than the latter.
The stuck and the diverging program are not semantically equivalent,
but $\Let{x}{\mathit{panic}}{\pe}$ is semantically equivalent to
$\Let{x}{\mathit{loop}}{\pe}$ when $x$ is dead in $\pe$.
Since $(\betastep)$ runs sub-programs to completion, we would observe
execution of ${\mathit{panic}}$ or ${\mathit{loop}}$, which is the only
way in which we could have made the program slower or faster.
Since there is no semantic difference, the performance of the program must be
unaffected.

This argument is quite vague.
In order to put it on firm ground, we define an \emph{improvement relation}
$(\faster)$ in the style of \citet{MoranSands:99} in \Cref{fig:improv}.

\begin{figure}
\[\begin{array}{c}
 \ruleform{ A ⊦_n τ_1 \lesssim τ_2 \qquad μ_1 \lessapprox μ_2 \qquad d_1 \faster d_2 }
 \\
 \\[-0.5em]
 \inferrule*[right=\implrcons]
    {\later (A ⊦_n τ_1 \lesssim τ_2)}
    {A ⊦_{n} \wild \cons τ_1 \lesssim \wild \cons τ_2}
 \quad
 \inferrule*[right=\imprcons]
    {A ⊦_{n+1} τ_1 \lesssim τ_2}
    {A ⊦_{n} τ_1 \lesssim \wild \cons τ_2}
 \quad
 \inferrule*[right=\implcons]
    {A ⊦_{n} τ_1 \lesssim τ_2}
    {A ⊦_{n+1} \wild \cons τ_1 \lesssim τ_2}
 \\
 \\[-0.5em]
 \inferrule*[right=\impstuck]
    {\quad}
    {A ⊦_{0} \stuckend{} \lesssim \stuckend{}}
 \quad
 \inferrule*[right=\impcon]
    {\many{A ⊦_{n} μ_1(\pa_1) \lesssim μ_2(\pa_2)})}
    {A ⊦_{\Sigma \{\many{n}\}} \goodend{\ConV(K, \many{\pa_1}), μ_1} \lesssim \goodend{\ConV(K, \many{\pa_2}), μ_2}}
 \\
 \\[-0.5em]
 \inferrule*[right=\impfun]
    {\forall \pa.\ \pa ∈ A ⟹  A ⊦_{n} f_1(\pa)(μ_1) \lesssim f_2(\pa)(μ_2)}
    {A ⊦_{n} \goodend{\FunV(f_1), μ_1} \lesssim \goodend{\FunV(f_2), μ_2}}
 \\
 \\[-0.5em]
 \inferrule*[right=\impheap]
    {\dom(μ_1) = \dom(μ_2) \quad \forall \pa.\ \later(\dom(μ_1) ⊦_{0} μ_1(\pa)(μ_1) \lesssim μ_2(\pa)(μ_2))}
    {μ_1 \lessapprox μ_2}
 \\
 \\[-0.5em]
 \inferrule*[right=\impdenot]
    {\forall μ_1,μ_2.\ μ_1 \lessapprox μ_2 \wedge  \dom(μ_1) ⊦ d_1,d_2 ⟹  \dom(μ_1) ⊦_{0} d_1(μ_1) \lesssim d_2(μ_2)}
    {d_1 \faster d_2}
\end{array}\]
\caption{Improvement relation}
  \label{fig:improv}
\end{figure}

Structurally, $(\faster)$ is very similar to $(\equiv)$; the main differences are in
the rules for $(\cons)$ and the resulting tracking of \emph{skew credits} $n∈ℕ$,
\eg, we count the applications of $\imprcons$ to spend them on $\implcons$ or
when a value is further scrutinised.
Naturally, it is easier to prove $A ⊦_n τ_1 \lesssim τ_2$ the more credits we
have at our expense and thus the larger $n$ is.

We write $d_1 \lockstep d_2$ when $d_1 \faster d_2$ and $d_2 \faster d_1$, in
which case both denotations operate in lockstep.
Already it is the case that $d_1 \faster d_2$ implies $d_1 \equiv d_2$,
so $(\faster)$ corresponds to the strong notion of improvement in
\citet{MoranSands:99}.
The weaker notion can be recovered by defining $\imprcons$ and $\implcons$ by
coinduction, thus accepting skew credits in $ℕ_ω$ instead of $ℕ$.

We conjecture that $(\faster)$ is a sub-relation of the strong contextual
improvement relation of \citet{MoranSands:99}, just as $(\equiv)$ is finer than
contextual equivalence.

We could now once again refine our notion of deadness, using lockstep
simulation.
It is then easy to see that $\semusg{\wild}$ is correct \wrt to this stronger
notion of deadness, because we can in large parts reuse the proof for
\Cref{thm:semusg-correct-live-3}.

%\begin{definition}[Denotational deadness, improving]
%  \label{defn:deadness4}
%  An address $\pa$ is \emph{dead} in a denotation $d$ if and only if,
%  for all $μ_1 \lessapprox\!\gtrapprox μ_2$ such that $\pa$ is dead in $\rng(μ_i)$,
%  $\dom(μ_1) ∪ \{\pa\} ⊦ d$ and $d_1,d_2$, we have
%  \[
%    \dom(μ_1) ⊦_0 d(μ_1[\pa↦d_1]) \lesssim\!\gtrsim d(μ_2[\pa↦d_2]).
%  \]
%  A variable $\px$ is \emph{dead} in an expression $\pe$ if and only if
%  any $\pa$ is dead in $\semevt{\pe}_{ρ[\px↦\pa]}$ for any $ρ$ such
%  that $\pa \not∈ \rng(ρ)$.
%  Otherwise, $\px$ is \emph{live}.
%\end{definition}
%
%And we will now assume that we have proven $\semusg{\wild}$ correct \wrt to this
%new notion of deadness:
%\begin{theorem}[$\semusg{\wild}$ is an improving deadness analysis]
%  \label{thm:semusg-correct-live-4}
%  Let $\pe$ be an expression, $\px$ a variable and $\tr$ a usage environment.
%  If $\tr(\px) \not⊑ \semusg{\pe}_{\tr}$
%  then $\px$ is dead in $\pe$.
%\end{theorem}
%
%The proof is much the same as \Cref{thm:semusg-correct-live-3}, because
%intuitively, any derivation of $A ⊦ τ_1 \sim τ_2$ can be rewritten to never use
%$\eqlcons$ and $\eqrcons$.
%Such a derivation can be directly transformed into a proof for
%$A ⊦_0 τ_1 \lesssim τ_2$, as we will never need $\implcons$ and $\imprcons$
%and skew credits remain at $0$.

\subsection{Evaluation Cardinality}

Since our new semantics is able to express evaluation cardinality and thunk
update, we can try to add a new $\mathbf{let1}$ construct to our language that
opts out of memoisation:
\[
 \begin{array}{rcl}
  ε ∈ \Events   & ::= & ... \mid \BindOE(\px,\pa↦d) \\
  \\[-0.5em]
  \semevt{\Letn{\px}{\pe_1}{\pe_2}}_ρ(μ) & = &
    \begin{letarray}
      \text{let} & ρ' = ρ[\px ↦ \pa] \quad \text{where $\pa \not∈ \dom(μ)$} \\
                 & d_1^\later = \semevt{\pe_1}_{ρ'} \\
      \text{in}  & \BindOE(\px,\pa↦d_1^\later) \cons \semevt{\pe_2}_{ρ'}(μ[\pa ↦ \highlight{d_1^\later}])
    \end{letarray} \\
 \end{array}
\]
Any program in which we switch from memoised $\mathbf{let}$ to $\mathbf{let1}$
is semantically equivalent after we adjust the definition of lazy heaps
accordingly.
This is a simple consequence of the fact that $\memo(\pa,d) \equiv d$
and compositionality.

However, omitting thunk memoisation has measurable effect on performance
if the same variable is evaluated repeatedly!
We should rather show that whenever $x$ is \emph{evaluated at most
once}, it is an improvement to rewrite $\Let{x}{\pe_1}{\pe_2}$ to
$\Letn{x}{\pe_1}{\pe_2}$.

We can sharpen this statement by making use of \emph{tick algebra}
\citep{MoranSands:99}.
For that, we need to add a notion of ticks to our language, a routine extension:
\[
 \begin{array}{rcl}
  ε ∈ \Events   & ::= & ... \mid \TickE \\
  \\[-0.5em]
  \semevt{\tick \pe}_ρ(μ) & = & \TickE \cons \semevt{\pe}_{ρ}(μ) \\
 \end{array}
\]
Now, whenever $x$ is ``evaluated at most once'', we
have $\semevt{\Let{x}{\pe_1}{\pe_2}}_ρ \lockstep
      \semevt{\Letn{x}{\tick\pe_1}{\pe_2}}_ρ$.
What remains before we can formalise this statement is a precise notion of
evaluation cardinality, one that works in arbitrary contexts.

Intuitively, we need a function $\mathit{count}_\pa : \Traces \to ℕ_ω$ that counts
$\LookupE(\pa)$ actions at a particular address $\pa$ over the course of a
head-normal form reduction.
Then, ``$\pa$ is evaluated at most once'' roughly corresponds to
$\mathit{count}_\pa(\semevt{\pE[\pe_2]}_{[\px↦\pa]}([\pa↦\semevt{\pe_1}_{[\px↦\pa]}])) \leq 1$
in arbitrary contexts such that $\pE$ does not capture $\px$ nor preoccupies $\pa$.

This sketch has two flaws:
The first is that the proposition and thus $\mathit{count}$ needs to know the
address it should count, so we were forced to unfold the definition of
$\semevt{\Let{\px}{\pe_1}{\pe_2}}_ρ(μ)$ without knowing $μ$, leading to new side
conditions begging for an intricate definition, such as ``$\pE$ preoccupies
$\pa$''.
The second flaw is that $\pe_1$ can't have any free variables besides $\px$ this
way, so it is not a faithful model of $\mathbf{let}$-binding and perhaps too
weak to prove lockstep bisimilarity.

Both flaws are a result of the need to escape and re-enter the syntactic (or,
perhaps \emph{static}) realm of $\pE$ and $\pe_2$ to name the semantic (or
\emph{dynamic}) address which the proposition needs to refer to.

One solution to this problem is to extend the semantics function to evaluation
contexts, with functionality
$\semevt{\pE} : ((\Var \to \Addresses) \to \EventD) \to ((\Var \to \Addresses) \to \EventD)$
such that $\semevt{\pE[\pe]}_ρ = \semevt{\pE}_ρ(\semevt{\pe})$.
This equation has a solution because of compositionality
and would allow for a faithful model of $\mathbf{let}$-binding in the hole of
the context.
A closed definition can be found in \Cref{fig:semevt-context}.

Now it is possible to define usage cardinality
\begin{definition}[Usage cardinality]
  \label{defn:usg-card}
  Let $d$ be a trace and $\pa$ be an address.
  $d$ evaluates $\pa$ \emph{at most $u$ times} if and only if,
  for all $μ$ such that $\pa$ is dead in $μ$,
  \[
    \ctx_\LookTraces(\usg_\Traces(d(μ)))(\pa) ⊑ u.
  \]
  \\
  An expression $\pe$ evaluates $\px$ \emph{at most $u$ times} if and only if,
  for $\pa \not∈ \rng(ρ)$, $\semevt{\pe}_{ρ[\px↦\pa]}$ evaluates
  $\pa$ at most $u$ times.
\end{definition}


The second option is the one we pursue in this work, because we believe it
yields interesting perspective:
Rather than to let syntactic evaluation contexts dictate how $\pe_2$ might be
evaluated to produce (essentially first-order) traces that we count addresses
in, we lift the counting of addresses through the whole domain, including
function values.
The resulting \emph{usage abstraction} $\usg_\Traces : \Traces \to \LookTraces$
is the most precise usage analysis possible and is induced componentwise by the
event abstraction
\[
  \usg_{\Events}(ε) = \begin{cases}
      [\pa↦1] & ε = \LookupT(\pa) \\
      \constfn{0} & \text{otherwise}
    \end{cases}
\]
as defined in \Cref{fig:usg-abs}.
The resulting $\LookTraces$ trace can then be folded by $\ctx_\LookTraces$ into
an $\Addresses \to \Usg$ mapping.
Intuitively, $\ctx_\LookTraces$ runs the $\LookD$ in all possible evaluation
contexts, returning the least upper bound of all resulting traces.

We can now define usage cardinality (\eg, an estimate for upper bound on
evalution cardinality) in terms of these two functions:
\begin{definition}[Usage cardinality]
  \label{defn:usg-card}
  Let $d$ be a trace and $\pa$ be an address.
  $d$ evaluates $\pa$ \emph{at most $u$ times} if and only if,
  for all $μ$ such that $\pa$ is dead in $μ$,
  \[
    \ctx_\LookTraces(\usg_\Traces(d(μ)))(\pa) ⊑ u.
  \]
  \\
  An expression $\pe$ evaluates $\px$ \emph{at most $u$ times} if and only if,
  for $\pa \not∈ \rng(ρ)$, $\semevt{\pe}_{ρ[\px↦\pa]}$ evaluates
  $\pa$ at most $u$ times.
\end{definition}

Happily and unlike \Cref{defn:deadness3}, this definition does
not need to relate executions of different heaps, thus it is
a simple \emph{trace property} rather than a \emph{program
property}~\citep{Cousot:21} (also called
\emph{hyperproperty} by~\citet{ClarksonSchneider:10}).

It is also a useful property, because it justifies elision of thunk updates:
\begin{theorem}[Update elision]
  \label{thm:usg-by-name}
  Let $\Let{\px}{\pe_1}{\pe_2}$ be an expression such that $\pe_2$ evaluates $\px$
  at most once and $\px$ is dead in $\pe_1$.
  Then
    $\semevt{\Let{\px}{\pe_1}{\pe_2}}_ρ \lockstep
     \semevt{\Letn{\px}{\tick\pe_1}{\pe_2}}_ρ$.
\end{theorem}
\begin{proof}
  Unless explicitly stated otherwise, we will always apply the improvement
  judgments in a symmetrical manner.
  That is, whenever we have to prove $a ⊑ b$, the proof should also hold for
  $b ⊑ a$ (where $(⊑)$ is either of $(\faster),(\lessapprox),(\lesssim)$).

  Assume that $\pe_2$ evaluates $\px$ at most once.
  We prove $(\lockstep)$ by rule $\impdenot$.
  After unfolding the definitions of $\semevt{\wild}$ for $\mathbf{let}$ and
  $\mathbf{let1}$, the goal is to show
  \[
    \dom(μ_i) ⊦_0 \semevt{\pe_2}_{ρ[\px↦\pa]}(μ_1[\pa↦d_1]) \lesssim\!\gtrsim \semevt{\pe_2}_{ρ[\px↦\pa]}(μ_2[\pa↦d_2])
  \]
  where $\pa \not∈\dom(μ_i)$,
  $\dom(μ_i) ∪ \{\pa\} ⊦ \semevt{\pe_2}_{ρ[\px↦\pa]}$,
  $μ_1 \lessapprox\!\gtrapprox μ_2$, and $\pa$ is dead in both
  $d_1 \triangleq \memo(\pa,\semevt{\pe_1}_{ρ[\px↦\pa]})$ and
  $d_2 \triangleq \semevt{\tick\pe_1}_{ρ[\px↦\pa]}$. \\
  We also know that
  \[
    \ctx_\LookTraces(\usg_\Traces(\semevt{\pe_2}_{ρ[\px↦\pa]}(μ_i[\pa↦d_i])))(\pa) ⊑ 1.
  \]

  By induction on $\pe_2$.
  \begin{itemize}
    \item \textbf{Case $\pe_2 = \pe~\py$}:
      Since $\pe_2$ evaluates $\px$ at most once, either $\pe$
      By rule $\impfun$ it suffices to show that, for any $\pa' ∈ \dom(μ_i)$,
      \[
        \dom(μ_i) ⊦_0 \semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']}(μ_1[\pa↦d_1]) \lesssim\!\gtrsim \semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']}(μ_2[\pa↦d_2]).
      \]

      From $\tr(\px) \not⊑ \semusg{\pe}_{\tr} + ω*\tr(\py)$ we can see that
      $\tr(\px) \not⊑ \semusg{\pe'}_{\tr}$ and $\tr(\px) \not⊑ \tr(\py)$ by
      monotonicity of $+$ and $*$.
      If $\px=\py$ then the latter inequality leads to a contradiction.
      Otherwise, $\px$ must be dead in $\pe'$, hence both cases of
      $\semscott{\pe'~\py}$ evaluate equally, differing only in
      the environment. It remains to be shown that
      $ρ[\px↦d_1](\py) = ρ[\px↦d_2](\py)$, and that is easy to see since
      $\px \not= \py$.

    \item \textbf{Case $\pe_2 = \Lam{\py}{\pe}$}:
      By rule $\impfun$ it suffices to show that, for any $\pa' ∈ \dom(μ_i)$,
      \[
        \dom(μ_i) ⊦_0 \semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']}(μ_1[\pa↦d_1]) \lesssim\!\gtrsim \semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']}(μ_2[\pa↦d_2]).
      \]
      If $\px = \py$, $\pa$ is dead in
      $\semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']} = \semevt{\pe}_{ρ[\py↦\pa']}$, thus
      showing the goal.

      Otherwise, $\px \not= \py$ and $\pa \not∈ \rng(ρ[\py↦\pa'])$, so if we can
      apply the induction hypothesis to $\pe$, we are done.
      For that, we need to prove that $\pe$ evaluates $\px$ at most once.
      We know that
      \[\begin{array}{rcl}
        1 & ⊒ & \ctx_\LookTraces(\usg_\Traces(\semevt{\pe_2}_{ρ[\px↦\pa]}(μ_i[\pa↦d_i])))(\pa) \\
          & ⊒ & ω*\ctx_\LookTraces(\usg_\Traces(\semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']}(μ_i[\pa↦d_i])))(\pa) \\
          & ⊒ & \ctx_\LookTraces(\usg_\Traces(\semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']}(μ_i[\pa↦d_i])))(\pa) \\
      \end{array}\]
      where the second inequality follows from $μ ∈ \usg_\Heaps(\usg^{⊣}_\Heaps(μ))$.
      Thus we can apply the induction hypothesis.

    \item \textbf{Case $\pe_2 = \py$}:
      If $\px \not= \py$ then $\pa$ is dead in $μ_i(ρ(\py))$ and the goal follows.

      If $\px=\py$, the goal reduces to
      \[
        \dom(μ_i) ⊦_0 \memo(\pa,\semevt{\pe_1}_{ρ[\px↦\pa]})(μ_1[\pa↦d_1]) \lesssim\!\gtrsim \semevt{\tick\pe_1}_{ρ[\px↦\pa]}(μ_2[\pa↦d_2])
      \]
      Since the tick makes up for the additional step that heap update incurs
      later on, it suffices to show that
      \[
        \dom(μ_i) ⊦_0 \semevt{\pe_1}_{ρ[\px↦\pa]}(μ_1[\pa↦d_1]) \lesssim\!\gtrsim \semevt{\pe_1}_{ρ[\px↦\pa]}(μ_2[\pa↦d_2])
      \]
      and that the updated heap does not make a difference.

      Since $\pa$ is dead in $d_i$ and thus in $d \triangleq \semevt{\pe_1}_{ρ[\px↦\pa]}$,
      we have
      \[
        \dom(μ_i) ⊦_0 d(μ_1[\pa↦d_1]) \lesssim\!\gtrsim d(μ_1[\pa↦d_2]) \lesssim\!\gtrsim d(μ_2[\pa↦d_2])
      \]
      where the latter equality follows from
      $μ_1[\pa↦d_2] \lessapprox\!\gtrapprox μ_2[\pa↦d_2]$ and reflexivity.

      For the elision of the heap update, consider the situation
      $\bigstep{d}{μ_i[\pa↦d_i]}{\FunV(f_i)}{μ_i'}$.
      For $μ_1'$, we make another step to $μ_1'[\pa↦\memo(\pa,\ret(\FunV(f_1)))]$,
      so we have to prove that
      \[
        \dom(μ_i) ⊦_0 f_1(\pa')(μ_1'[\pa↦\memo(\pa,\ret(\FunV(f_1)))]) \lesssim\!\gtrsim f_2(\pa')(μ_2')
      \]
      for all $\pa' ∈ \dom(μ_i)$.

      Now, $\pa$ is dead in $μ_i[\pa↦d_i]$, so
      $\ctx_\LookTraces(\usg_\Traces(\semevt{\px}_ρ[\px↦\pa](μ_i[\pa↦d_i])))(\pa)⊑1$.
      But we already emitted a $\LookupE(\pa)$ event,
      and because $1 + u = 1$ implies $u = 0$, we must have
      $\ctx_\LookTraces(\usg_\Traces(d_i(μ_i[\pa↦d_i])))(\pa) = 0$.
      That implies
      $\ctx_\LookTraces(\usg_\Traces(\goodend{\FunV(f_1),μ_1'[\pa↦\memo(\pa,\ret(\FunV(f_1)))]}))(\pa) = 0$.
      and
      $\ctx_\LookTraces(\usg_\Traces(\goodend{\FunV(f_2),μ_2'}))(\pa) = 0$.
      By unfolding both $\ctx_\LookTraces$ and $\usg_\Traces$ and exploiting
      that $μ ∈ \usg_\Heaps(\usg^{⊣}_\Heaps(μ))$, we see that
      \[
        \ctx_\LookTraces(\usg_\Traces(f_1(\pa')(μ_1'[\pa↦\memo(\pa,\ret(\FunV(f_1)))]))) = 0
      \]
      for any $\pa' ∈ \dom(μ_i)$ and likewise for $f_2(\pa')(μ_2')$.
      Thus, $\pa$ is dead in $f_1(\pa')(μ_1'[\pa↦\memo(\pa,\ret(\FunV(f_1)))])$
      and we may rewrite back to $μ_1'$ for which we already know
      \[
        \dom(μ_i) ⊦_0 f_1(\pa')(μ_1') \lesssim\!\gtrsim f_2(\pa')(μ_2')
      \]
      Thus proving the goal.

    \item \textbf{Case $\pe = \Let{\py}{\pe_1}{\pe_2}$}:
      We have to show that
      \[
        \semscott{\pe_2}_{ρ[\px↦d_1][\py↦d'_1]} = \semscott{\pe_2}_{ρ[\px↦d_2][\py↦d'_2]}
      \]
      where $d'_i$ satisfy $d'_i = \semscott{\pe_1}_{ρ[\px↦d_i][\py↦d'_i]}$.
      The case $\px = \py$ is simple to see, because $ρ[\px↦d_i](\px)$ is never
      looked at.
      So we assume $\px \not= \py$ and see that $\tr(\px) = \tr'(\px)$, where
      $\tr' = \operatorname{fix}(\fn{\tr'}{\tr ⊔ [\py ↦ \semusg{\pe_1}_{\tr'}]})$.

      We know that
      \[
        \tr'(\px) = \tr(\px) \not⊑ \semusg{\pe}_{\tr} = \semusg{\pe_2}_{\tr'}
      \]
      So by the induction hypothesis, $\px$ is dead in $\pe_2$.

%      Now consider the predicate $P(\tr) = \tr(\px) ⊑ \semusg{\pe_1}_{\tr}$.
%      We must prove it admissable to see that it holds (by fixpoint induction)
%      for $\tr'$. That is clearly the case because it is a composition of
%      continuous functions ($\tr, \semusg{\pe_1}$) and admissable predicates
%      ($⊑$).
%
%      SG: I think we don't need to prove that P above is admissable because
%      we never try to prove it through fixpoint induction; we simply apply LEM.

      We proceed by cases over $\tr(\px) = \tr'(\px) ⊑ \semusg{\pe_1}_{\tr'}$.
      \begin{itemize}
        \item \textbf{Case $\tr'(\px) ⊑ \semusg{\pe_1}_{\tr'}$}: Then
          $\tr'(\px) ⊑ \tr'(\py)$ and $\py$ is also dead in $\pe_2$ by the above
          inequality.
          Both deadness facts together allow us to rewrite
          \[
            \semscott{\pe_2}_{ρ[\px↦d_1][\py↦d'_1]} = \semscott{\pe_2}_{ρ[\px↦d_1][\py↦d'_2]} = \semscott{\pe_2}_{ρ[\px↦d_2][\py↦d'_2]}
          \]
          as requested.
        \item \textbf{Case $\tr'(\px) \not⊑ \semusg{\pe_1}_{\tr'}$}:
          Then $\px$ is dead in $\pe_1$ and $d'_1 = d'_2$. The goal follows
          from the fact that $\px$ is dead in $\pe_2$.
      \end{itemize}
  \end{itemize}


\end{proof}


It is also a useful property, because it justifies elision of thunk updates:
\begin{theorem}[Update elision]
  \label{thm:usg-by-name}
  Let $\Let{\px}{\pe_1}{\pe_2}$ be an expression and $\tr$ a usage environment
  such that $ω*\tr(\px) \not⊑ \semusg{\Let{\px}{\pe_1}{\pe_2}}_{\tr}$.
  Then
    $\semevt{\Let{\px}{\pe_1}{\pe_2}}_ρ \lockstep
     \semevt{\Letn{\px}{\tick\pe_1}{\pe_2}}_ρ$.
\end{theorem}
\begin{proof}
  Unless explicitly stated otherwise, we will always apply the improvement
  judgments in a symmetrical manner.
  That is, whenever we have to prove $a ⊑ b$, the proof should also hold for
  $b ⊑ a$ (where $(⊑)$ is either of $(\faster),(\lessapprox),(\lesssim)$).

  Assume that $ω*\tr(\px) \not⊑ \semusg{\Let{\px}{\pe_1}{\pe_2}}_{\tr}$ for some $\tr$, so
  $ω*\tr_1(\px) \not⊑ \semusg{\pe_2}_{\tr_1}$ where
  $\tr_1 \triangleq \operatorname{fix}(\fn{\tr_1}{\tr ⊔ [\px ↦ [\px↦1]+\semusg{\pe_1}_{\tr_1}]})$.

  Consider the case that $\px$ is not dead in $\pe_1$.
  Then $\tr_1(\px) = ω = ω*\tr_1(\px) \not⊑ \semusg{\pe_2}_{\tr_1}$, so $\px$
  would be dead in $\pe_2$ and the goal follows from deadness.
  So we assume that $\px$ is dead in $\pe_1$.

  We prove $(\lockstep)$ by rule $\impdenot$.
  After unfolding the definitions of $\semevt{\wild}$ for $\mathbf{let}$ and
  $\mathbf{let1}$, the goal is to show
  \[
    \dom(μ_i) ⊦_0 \semevt{\pe_2}_{ρ[\px↦\pa]}(μ_1[\pa↦d_1]) \lesssim\!\gtrsim \semevt{\pe_2}_{ρ[\px↦\pa]}(μ_2[\pa↦d_2])
  \]
  where $\pa \not∈\dom(μ_i)$,
  $\dom(μ_i) ∪ \{\pa\} ⊦ \semevt{\pe_2}_{ρ[\px↦\pa]}$,
  $μ_1 \lessapprox\!\gtrapprox μ_2$.
  Clearly,
  \[
    \dom(μ_i) ⊦_0 \semevt{\pe_2}_{ρ[\px↦\pa]}(μ_1[\pa↦d_2]) \lesssim\!\gtrsim \semevt{\pe_2}_{ρ[\px↦\pa]}(μ_2[\pa↦d_2])
  \]
  holds by reflexivity because $μ_1[\pa↦d_2] \lessapprox\!\gtrapprox μ_2[\pa↦d_2]$, so the goal becomes
  \[
    \dom(μ_i) ⊦_0 τ_1 \lesssim\!\gtrsim τ_2,
  \]
  abbreviating $τ_i \triangleq \semevt{\pe_2}_{ρ[\px↦\pa]}(μ_1[\pa↦d_i])$.

  It suffices to show that $\len(τ_1) = \len(τ_2)$ and that
  whenever there is $\pa',μ_i'$ such that $\pa$ is dead in $μ_i'(\pa')$ and
  $τ_i = ... \cons \goodend{\FunV(f_i),μ_i'}$,
  $\dom(μ_i) ⊦_0 f_1(\pa')(μ_1') \lesssim\!\gtrsim f_2(\pa')(μ_2')$.

  Since any $\pa$ is dead in $μ_1[\pa↦d_i](\pa')$ for any $\pa' ∈ \dom(μ_i)$,
  this is enough to apply $\impfun$ and the goal follows.

%  Since $\px$ is dead in $\pe_1$, $\pa$ is dead in both
%  $d_1 \triangleq \memo(\pa,\semevt{\pe_1}_{ρ[\px↦\pa]})$ and
%  $d_2 \triangleq \semevt{\tick\pe_1}_{ρ[\px↦\pa]}$.

  By induction on $\pe_2$.
  We strengthen the induction hypothesis by requiring that $\pa \not∈ \rng(ρ)$.
  \sg{Perhaps we can get rid of this? No I don't think so. For usage abstraction
  we might want ``evaluates $\pa$ at most once'' as the invariant, moving much
  of the $\px=\py$ case to the let case.}
  \begin{itemize}
    \item \textbf{Case $\pe_2 = \py$}:
      If $\px \not= \py$ then $ρ(\py) \not= \pa$ and the goal follows
      from $μ_1 \lessapprox\!\gtrapprox μ_2$.

      If $\px=\py$, we have
      $τ_1 = \memo(\pa,\semevt{\pe_1}_{ρ[\px↦\pa]})(μ_1[\pa↦d_1])$,
      $τ_2 = \semevt{\tick\pe_1}_{ρ[\px↦\pa]}(μ_1[\pa↦d_2])$.
      Since the tick makes up for the additional step that heap update incurs
      later on it is easy to see that $\len(τ_1) = \len(τ_2)$.

      Hence we assume that there is $\pa',μ_i'$ such that $\pa$ is dead in
      $μ_i'(\pa')$ and $τ_i = ... \cons \goodend{\FunV(f_i),μ_i'}$ and show
      \[
        \dom(μ_i) ⊦_0 f_1(\pa')(μ_1') \lesssim\!\gtrsim f_2(\pa')(μ_2')
      \]
      and that the updated heap does not make a difference.

      Since $\pa$ is dead in $d \triangleq \semevt{\pe_1}_{ρ[\px↦\pa]}$ because
      $\px$ is dead in $\pe_1$, we have
      \[
        \dom(μ_i) ⊦_0 d(μ_1[\pa↦d_1]) \lesssim\!\gtrsim d(μ_1[\pa↦d_2])
      \]
      NEED THIS

      For the elision of the heap update, consider the situation
      $\bigstep{d}{μ_1[\pa↦d_i]}{\FunV(f_i)}{μ_i'}$.
      For $μ_1'$, we make another step to $μ_1'[\pa↦\memo(\pa,\ret(\FunV(f_1)))]$,
      so we have to prove that
      \[
        \dom(μ_i) ⊦_0 f_1(\pa')(μ_1'[\pa↦\memo(\pa,\ret(\FunV(f_1)))]) \lesssim\!\gtrsim f_2(\pa')(μ_2')
      \]
      for all $\pa' ∈ \dom(μ_i)$.

      Now, $\pa$ is dead in $d$, hence in $d_i$

      By unfolding both $\ctx_\LookTraces$ and $\usg_\Traces$ and exploiting
      that $μ ∈ \usg_\Heaps(\usg^{⊣}_\Heaps(μ))$, we see that
      \[
        \ctx_\LookTraces(\usg_\Traces(f_1(\pa')(μ_1'[\pa↦\memo(\pa,\ret(\FunV(f_1)))]))) = 0
      \]
      for any $\pa' ∈ \dom(μ_i)$ and likewise for $f_2(\pa')(μ_2')$.
      Thus, $\pa$ is dead in $f_1(\pa')(μ_1'[\pa↦\memo(\pa,\ret(\FunV(f_1)))])$
      and we may rewrite back to $μ_1'$ for which we already know
      \[
        \dom(μ_i) ⊦_0 f_1(\pa')(μ_1') \lesssim\!\gtrsim f_2(\pa')(μ_2')
      \]
      Thus proving the goal.

    \item \textbf{Case $\pe_2 = \Let{\py}{\pe_1'}{\pe_2'}$}:
      We assume that $\px \not= \py$ (otherwise $\pa$ would be dead) and have to show that
      \[
        \dom(μ_i) ⊦_0 \semevt{\pe_2'}_{ρ'[\py↦\pa']}(μ_1'[\pa'↦d_1']) \lesssim\!\gtrsim \semevt{\pe_2'}_{ρ'[\py↦\pa']}(μ_2'[\pa'↦d_1'])
      \]
      where $ρ' \triangleq ρ[\px↦\pa]$, $μ_i' \triangleq μ_i[\pa↦d_1]$,
      $d'_1 \triangleq \semevt{\pe_1'}_{ρ[\px↦\pa][\py↦\pa']}$.
      From $\px \not= \py$ we see that $\tr_1(\px) = \tr_2(\px)$, where
      $\tr_2 \triangleq \operatorname{fix}(\fn{\tr_2}{\tr_1 ⊔ [\py ↦ [\py↦1]+\semusg{\pe_1'}_{\tr_2}]})$.
      Hence we know that
      \[
        ω*\tr_2(\px) = ω*\tr_1(\px) \not⊑ \semusg{\pe_2}_{\tr_1} = \semusg{\pe_2'}_{\tr_2}
      \]

%      So by the induction hypothesis,
%      \[
%        \dom(μ_i) ∪ \{ \pa' \} ⊦_0 \semevt{\pe_2'}_{ρ'[\py↦\pa']}(μ_1'[\pa'↦d_1']) \lesssim\!\gtrsim \semevt{\pe_2'}_{ρ'[\py↦\pa']}(μ_2'[\pa'↦d_1'])
%      \]

%      Now consider the predicate $P(\tr) = \tr(\px) ⊑ \semusg{\pe_1}_{\tr}$.
%      We must prove it admissable to see that it holds (by fixpoint induction)
%      for $\tr'$. That is clearly the case because it is a composition of
%      continuous functions ($\tr, \semusg{\pe_1}$) and admissable predicates
%      ($⊑$).
%
%      SG: I think we don't need to prove that P above is admissable because
%      we never try to prove it through fixpoint induction; we simply apply LEM.

      We proceed by cases over $\tr_1(\px) = \tr_2(\px) ⊑ \semusg{\pe_1}_{\tr_2}$.
      \begin{itemize}
        \item \textbf{Case $\tr_2(\px) \not⊑ \semusg{\pe_1}_{\tr_2}$}:
          Then $\px$ is dead in $\pe_1$ and $d'_1$ and we can apply the
          induction hypothesis, yielding
          \[
            \dom(μ_i) ∪ \{ \pa' \} ⊦_0 \semevt{\pe_2'}_{ρ'[\py↦\pa']}(μ_1'[\pa'↦d_1']) \lesssim\!\gtrsim \semevt{\pe_2'}_{ρ'[\py↦\pa']}(μ_2'[\pa'↦d_1'])
          \]
          which can be weakened to address domain $\dom(μ_i)$.
        \item \textbf{Case $ω*\tr_2(\px) ⊑ \semusg{\pe_1}_{\tr_2}$}: Then
          $ω*\tr_2(\px) ⊑ \tr_2(\py) \not⊑ \semusg{\pe_2'}_{\tr_2}$ and hence
          $\py$ is dead in $\pe'$, which allows us to rewrite its bindings in
          $μ_i'$ with something that is dead in $\pa$.
          That again makes it possible to apply the induction hypothesis,
          showing the goal.
        \item \textbf{Case $\tr_2(\px) ⊑ \semusg{\pe_1}_{\tr_2}$}: Then
          $\tr_2(\px) ⊑ \tr_2(\py)$ and hence $ω*\tr_2(\py) \not⊑
          \semusg{\pe_2}_{\tr_2}$.
          is also evaluated at most once in
          $\pe_2$ by the above
          inequality.
          Both deadness facts together allow us to rewrite
          \[
            \semscott{\pe_2}_{ρ[\px↦d_1][\py↦d'_1]} = \semscott{\pe_2}_{ρ[\px↦d_1][\py↦d'_2]} = \semscott{\pe_2}_{ρ[\px↦d_2][\py↦d'_2]}
          \]
          as requested.
      \end{itemize}

    \item \textbf{Case $\pe_2 = \Lam{\py}{\pe}$}:
      By rule $\impfun$ it suffices to show that, for any $\pa' ∈ \dom(μ_i)$,
      \[
        \dom(μ_i) ⊦_0 \semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']}(μ_1[\pa↦d_1]) \lesssim\!\gtrsim \semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']}(μ_2[\pa↦d_2]).
      \]
      If $\px = \py$, $\pa$ is dead in
      $\semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']} = \semevt{\pe}_{ρ[\py↦\pa']}$, thus
      showing the goal.

      Otherwise, $\px \not= \py$ and $\pa \not∈ \rng(ρ[\py↦\pa'])$, so if we can
      apply the induction hypothesis to $\pe$, we are done.
      For that, we need to prove that $\pe$ evaluates $\px$ at most once.
      We know that
      \[\begin{array}{rcl}
        1 & ⊒ & \ctx_\LookTraces(\usg_\Traces(\semevt{\pe_2}_{ρ[\px↦\pa]}(μ_i[\pa↦d_i])))(\pa) \\
          & ⊒ & ω*\ctx_\LookTraces(\usg_\Traces(\semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']}(μ_i[\pa↦d_i])))(\pa) \\
          & ⊒ & \ctx_\LookTraces(\usg_\Traces(\semevt{\pe}_{ρ[\px↦\pa][\py↦\pa']}(μ_i[\pa↦d_i])))(\pa) \\
      \end{array}\]
      where the second inequality follows from $μ ∈ \usg_\Heaps(\usg^{⊣}_\Heaps(μ))$.
      Thus we can apply the induction hypothesis.
    \item \textbf{Case $\pe_2 = \pe~\py$}:
      From $ω*\tr_1(\px) \not⊑ \semusg{\pe}_{\tr_1} + ω*\tr_1(\py)$ we can see that
      $ω*\tr_1(\px) \not⊑ \semusg{\pe}_{\tr_1}$ and $\tr_1(\px) \not⊑ \tr_1(\py)$ by
      monotonicity of $+$ and $*$.
      If $\px=\py$ then the latter inequality leads to a contradiction,
      so $\px \not= \py$ and $ρ(\py) ∈ \dom(μ_i)$.

      Since $ω*\tr_1(\px) \not⊑ \semusg{\pe}_{\tr_1}$, we can apply the induction
      hypothesis to $\pe$, so we have
      \[
        \dom(μ_i) ⊦_0 \semevt{\pe}_{ρ[\px↦\pa]}(μ_1[\pa↦d_1]) \lesssim\!\gtrsim \semevt{\pe_2}_{ρ[\px↦\pa]}(μ_2[\pa↦d_2])
      \]
      The interesting case is again when $\betastep{\semevt{\pe}_{ρ[\px↦\pa]}}{μ_i[\pa↦d_i]}{\FunV(f_i)}{μ_i'}$.
      In that case, we have
      \[
        \dom(μ_i) ⊦_0 f_1(\pa')(μ_1') \lesssim\!\gtrsim f_2(\pa')(μ_2')
      \]
      for any $\pa' ∈ \dom(μ_i)$.
      But $ρ(\py)$ is just such an address and hence we show the goal.

    \item \textbf{Case $\pe = \Let{\py}{\pe_1}{\pe_2}$}:
      We have to show that
      \[
        \semscott{\pe_2}_{ρ[\px↦d_1][\py↦d'_1]} = \semscott{\pe_2}_{ρ[\px↦d_2][\py↦d'_2]}
      \]
      where $d'_i$ satisfy $d'_i = \semscott{\pe_1}_{ρ[\px↦d_i][\py↦d'_i]}$.
      The case $\px = \py$ is simple to see, because $ρ[\px↦d_i](\px)$ is never
      looked at.
      So we assume $\px \not= \py$ and see that $\tr(\px) = \tr'(\px)$, where
      $\tr' = \operatorname{fix}(\fn{\tr'}{\tr ⊔ [\py ↦ \semusg{\pe_1}_{\tr'}]})$.

      We know that
      \[
        \tr'(\px) = \tr(\px) \not⊑ \semusg{\pe}_{\tr} = \semusg{\pe_2}_{\tr'}
      \]
      So by the induction hypothesis, $\px$ is dead in $\pe_2$.

%      Now consider the predicate $P(\tr) = \tr(\px) ⊑ \semusg{\pe_1}_{\tr}$.
%      We must prove it admissable to see that it holds (by fixpoint induction)
%      for $\tr'$. That is clearly the case because it is a composition of
%      continuous functions ($\tr, \semusg{\pe_1}$) and admissable predicates
%      ($⊑$).
%
%      SG: I think we don't need to prove that P above is admissable because
%      we never try to prove it through fixpoint induction; we simply apply LEM.

      We proceed by cases over $\tr(\px) = \tr'(\px) ⊑ \semusg{\pe_1}_{\tr'}$.
      \begin{itemize}
        \item \textbf{Case $\tr'(\px) ⊑ \semusg{\pe_1}_{\tr'}$}: Then
          $\tr'(\px) ⊑ \tr'(\py)$ and $\py$ is also dead in $\pe_2$ by the above
          inequality.
          Both deadness facts together allow us to rewrite
          \[
            \semscott{\pe_2}_{ρ[\px↦d_1][\py↦d'_1]} = \semscott{\pe_2}_{ρ[\px↦d_1][\py↦d'_2]} = \semscott{\pe_2}_{ρ[\px↦d_2][\py↦d'_2]}
          \]
          as requested.
        \item \textbf{Case $\tr'(\px) \not⊑ \semusg{\pe_1}_{\tr'}$}:
          Then $\px$ is dead in $\pe_1$ and $d'_1 = d'_2$. The goal follows
          from the fact that $\px$ is dead in $\pe_2$.
      \end{itemize}
  \end{itemize}


\end{proof}

We will now prove that $\semusg{\wild}$ is a correct usage analysis
in two steps:
First, we will show that it is in fact an abstract interpretation
of the usage abstraction.
Subsequently, we will show that the notion of usage cardinality
can be used to


We will define

The use of the term ``abstraction'' is justifiable by the following lemma:

% Nope, for the following we need preservation of (arbitrary) joins
%\begin{lemma}[Monotone functions have upper adjoints]
%  Let $α : C \to A$ be a monotone function between partial orders $(C,\leq)$ and $(A,⊑)$.
%  Then $γ : A \to C, γ(a) = \bigvee \{ c \mid α(c) ⊑ a \}$ is a monotone function as well
%  and $γ$ is upper adjoint to $α$.
%\end{lemma}
%\begin{proof}
%  For any $a,c$, let $α(c) ⊑ a$.
%  Then $c ∈ \{ c \mid α(c) ⊑ a \}$ and hence $c \leq γ(a)$.
%  Conversely, let $c \leq γ(a)$.
%  Then, by monotonicity, $α(c) ⊑ α(γ(a)) = α(\bigvee \{ c \mid α(c) ⊑ a \})$.
%\end{proof}

\begin{lemma}[Pointwise abstraction, after \citet{Cousot:21}]
  Let $f : C \to A$ be a function.
  Then $f^* : A \to \poset{C}, f^*(C) = \Lub \{ f(c) \mid c ∈ C \}$
  and $f^⊣ : A \to \poset{C}, f^⊣(a) = \bigcup \{ C \mid f^*(C) ⊑ a \}$
  form a Galois connection between partial orders
  $(A,⊑) \galois{f^*}{f^⊣}(\poset{C},⊆)$.
\end{lemma}
\begin{proof}
  For any $a,C$, let $f^*(C) ⊑ a$.
  Then $C ∈ \{ C \mid f^*(C) ⊑ a \}$ and hence $C ⊆ f^⊣(a)$.
  Conversely, let $C ⊆ f^⊣(a) = \bigcup \{ C \mid f^*(C) ⊑ a \} = \bigcup \{ C \mid \forall c∈C.\ f(c) ⊑ a \} = \{ c \mid f(c) ⊑ a \}$.
  Then, by monotonicity of $f^*$, $f^*(C) ⊑ \Lub \{ f(c) \mid f(c) ⊑ a \}$.
  But $a$ is an upper bound of $\{ f(c) \mid f(c) ⊑ a \}$, so it can't be below the least upper bound.
\end{proof}

And $\usg_\EventD$ is exactly such a pointwise abstraction.
We will apply $\usg_\EventD^*$ to the \emph{collecting semantics}
$\semcoll{\pe}_ρ \triangleq \{\semevt{\pe}_ρ\}$, but
$\usg_\EventD^*(\{\semevt{\pe}_ρ\}) = \usg_\EventD(\semevt{\pe}_ρ)$, so
$\usg_\EventD^*$ is barely worth talking about.


we define
would be to compute one to fuse $\usg$ with
$\semevt{\pE[\pe]}_ρ$ to arrive at definition that is similar to


$\semevt{\pe_1}_{ρ[\px↦\deref(\pa)]}(μ[\pa↦\semevt{\pe_2}_ρ])$

\begin{definition}
  \label{defn:card}
  Let $d$ be a trace $\pa$ be an address.
  Then $\usg_d(d)$ is the \emph{evaluation cardinality abstraction} of $\pa$ in $d$.
\end{definition}

\begin{figure}
\[\begin{array}{c}
 \arraycolsep=3pt
 \begin{array}{rclcl}
  μ & ∈ & \Heaps^{\Look} & =   & \Addresses \pfun \later\Domain{\Look} \\
  d & ∈ & \Domain{\Look} & =   & \Heaps^{\Look} \to \LookTraces \\
  u & ∈ & \Usg & =   & \{ 0 ⊏ 1 ⊏ ω \} ⊂ ℕ_ω \\
  τ & ∈ & \LookTraces & =   & (l ∈ \Addresses \to \Usg) \lcons \someend{v,μ} \\
  v & ∈ & \Values{\Look} & =   & \FunV(f ∈ \Addresses \to \Domain{\Look}) \\
 \end{array} \\
 \\[-0.5em]
 \begin{array}{lcl}
  \multicolumn{3}{c}{ \ruleform{ \usg_{\Events} : \Events \to (\Addresses \to \Usg)} } \\
  \\[-0.5em]
  \usg_{\Events}(ε) & = & \begin{cases}
      [\pa↦1] & ε = \LookupT(\pa) \\
      \constfn{0} & \text{otherwise}
    \end{cases} \\
  l_1 +_1 (l_2 \lcons \someend{\tilde{v},\tm}) & = & (l_1+l_2) \lcons \someend{\tilde{v},\tm} \\
  \usg_{\Traces}(ε \cons τ) & = & \usg_{\Events}(ε) +_1 \usg_{\Traces}(τ) \\
  \usg_{\Traces}(\goodend{\FunV(f),μ}) & = & \constfn{0} \lcons \someend{\usg_{\EventV}(\FunV(f)), \usg_\Heaps(μ)} \\
  \usg_{\Traces}(\stuckend{}) & = & \constfn{0} \lcons \someend{\bot_{\Values{\UsgD}}, (\constfn{\bot_\EventD}) \circ μ} \\
  \usg_{\Heaps}(μ) & = & \usg_\EventD \circ μ \\
  \usg^{⊣}_{\Heaps}(\tm) & = & \bigcup \{ μ \mid \usg_{\Heaps}(μ) ⊑ \tm \} \\
  \usg_{\EventD}(d) & = & \usg_\Traces \circ d \circ \usg^{⊣}_{\Heaps} \\
  \usg_{\EventV}(\FunV(f)) & = & \FunV(\usg_{\EventD} \circ f) \\
  \\[-0.5em]
  \multicolumn{3}{c}{ \ruleform{ \byname : ((\Var \to \LookD) \to_m \LookD) \to_m ((\Var \to \LookD) \to_m \LookD) } } \\
  \\[-0.5em]
  \byname(\mathcal{S})(ρ)(μ) & = & \mathcal{S}(\fn{\px}{\fn{μ'}{ρ(\px)(μ)}})(μ) \\
  \\[-0.5em]
  \multicolumn{3}{c}{ \ruleform{ \ctx : \LookTraces \to_m \Addresses \to \Usg } } \\
  \\[-0.5em]
  \ctx_\LookTraces(\pE,ρ,l \lcons \someend{\tv,\tm}) & = & l + \begin{cases}
    \ctx_\LookTraces(\pE',ρ,\tilde{f}(ρ(\px))(\tm)) & \pE = \pE'~\px, \tv = \FunV(\tilde{f}) \\
    \ctx_\LookTraces(\pE',ρ,\someend{\tv,\tm}) & \pE = \Let{\px}{\pe}{\pE'}, \tv = \FunV(\tilde{f}) \\
    \ctx_\LookTraces(\pE',ρ,\someend{\tv,\tm}) + \ctx_\LookTraces(\pE_2,ρ,\tilde{f}(ρ(\px))(\tm[\pa↦)) & \pE = \Let{\px}{\pE_1}{\pE_2[\px]}, \tv = \FunV(\tilde{f}) \\
    0 & \text{otherwise} \\
  \end{cases} \\
  \\[-0.5em]
  \multicolumn{3}{c}{ \ruleform{ α : \Traces \to \UsgD } } \\
  \\[-0.5em]
  α(τ) & = & fst(intra(usg_\Traces(blub(τ)(\fn{\px}{[\px↦1]}))(τ))) \\
 \end{array}
\end{array}\]
\caption{Usage abstraction}
\label{fig:usg-abs}
\end{figure}
