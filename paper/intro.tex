\section{Introduction}
\label{sec:introduction}

To an implementor of a programming language, it is often useful to employ a
\emph{static program analysis} to automatically infer facts about a program such
as ``this program is well-typed'', ``this higher-order function is always called
with argument $\Lam{x}{x+1}$'' or ``this program never evaluates $x$''.

If the implementation language is a functional one, then usually such static
analyses are formulated as a function defined by \emph{structural recursion} on
the input term.
For example, given an application expression $(\pe_1~\pe_2)$,
the property ``$(\pe_1~\pe_2)$ never evaluates its free variable $x$'' can be
\emph{conservatively approximated} (here: It's OK to say ``No'' more often) by
the property ``$\pe_1$ never evaluates $x$ and $\pe_2$ never evaluates
$x$''.

It is quite convenient to formulate such a \emph{deadness analysis}%
\footnote{\citet{Cousot:21} calls it a \emph{potential liveness analysis}}
structurally:
(1) Structural recursion gives an immediate proof of termination and can
    further be exploited in other inductive proofs.
(2)~A structurally-defined function $f$ is often \emph{compositional}, meaning that
    the result of $f\denot{\pe_1~\pe_2}$ is a function of $f\denot{\pe_1}$ and
    $f\denot{\pe_2}$, but not of the structure of either $\pe_1$ or $\pe_2$.
    Compositionality makes it easy for humans to understand and reason about the
    function, as well as allows to abstract away program syntax in the first
    place.

\subsection{Compositional Analyses Abstract Denotational Semantics}

For static analyses, especially more complicated ones, it is good practice to
provide a proof of correctness.
If the correctness statement can be expressed in terms of a \emph{denotational
semantics}~\citep{ScottStrachey:71}, then the recursion structure of analysis
function and semantics function line up nicely.
As a result, the proof of correctness can be conducted by simple induction
over the expression. Abstract interpretation~\citep{Cousot:21} then provides
a neat framework to derive static analyses that are proven correct by simple
equational reasoning.

%\subsection{Domain Theory is leaky and too abstract}
%Alas, there are several shortcomings to traditional denotational semantics:
%\begin{itemize}
%  \item Program behaviors are denoted by elements of an algebraic domain.
%        Crucially, such algebraic domains allow embedding of functions
%        operating on algebraic domain elements~\citep{ScottStrachey:71}.
%        However, this embedding is restricted to the subset of
%        \emph{continuous} functions%
%        \footnote{Continuous functions in turn form a superset of all
%        \emph{computable} functions.}.
%
%        As a result, coming up with one's own denotational semantics requires a
%        proof of continuity of all involved functions that is often hand-waved
%        over when the semantics is ``sufficiently standard''.
%        In other cases, continuity is proven for a number of combinators and
%        their composition, and then the semantics is formulated in terms of this
%        meta language of combinators, adversely affecting the presentation of the
%        semantics.
%  \item Traditional domain theory proved non-compositional~\citep{WrightFelleisen:94},
%        in that language features such as exceptions, state and nondeterminism
%        require individual, complicated adjustments where it is far from clear
%        how to combine these adjustments in a way that the combined semantics'
%        functions are still continuous.
%  \item There have been denotational semantics for call-by-name and
%        call-by-value, but none for call-by-need. That is a symptom of the fact
%        that traditional domain theory eschews any account of operational
%        detail, such as evaluation cardinality.
%\end{itemize}
%
%The third point is important in the context of quantitative type
%systems~\citep{Atkey:18} and optimising compilers for call-by-need languages such
%as the Glasgow Haskell Compiler.
%The first two points have been noted by \citet{WrightFelleisen:94}, establishing
%operational semantics as the Gold Standard to this day.
%The past twenty years have proven that the methodology scales to
%big and complex type systems, building on techniques such as
%\emph{step-indexing}~\citep{AppelMcAllester:01,DreyerAhmedBirkedal:11}.

\subsection{Operational Semantics is Detailed and Systematically Scalable}

Alas, the existing denotational semantics for lambda calculus are insufficiently
expressive to model operational detail such as \emph{evaluation cardinality},
\eg, ``How often does $\pe$ evaluate its free variable $x$?'', because they lack
the concept of ``evaluating a variable''.
Thus, a static analysis that cares about evaluation cardinality (we will give
an example in \Cref{sec:problem}) cannot be proven correct \wrt traditional
denotational semantics.
A related issue is that up to this day, there are denotational semantics for
call-by-value and call-by-name but none for call-by-need, because memoisation is
not a concept that is observable in traditional denotational semantics.

Ultimately, traditional denotational semantics fell out of fashion due to
scaling issues and \citet{WrightFelleisen:94} established operational semantics
as the Gold Standard semantics for correctness proofs to this day.
The past thirty years have proven that the methodology scales to
big and complex type systems, building on techniques such as
\emph{step-indexing}~\citep{AppelMcAllester:01,DreyerAhmedBirkedal:11}.
However, transition systems do not easily admit a compositional definition as a
function of the input expression.%
\footnote{While~\citet{Cousot:02} has derived trace-based fixpoint
semantics from an arbitrary transition system, the resulting function is not
structurally-recursive in the expression.}
In giving in to operational semantics, semanticists have chosen predictable
step-wise reasoning over elegant equational reasoning backed by
compositionality.

%In preservation proofs of type systems, step-wise reasoning necessitates
%substitution lemmas to cope with the non-structural recursion during variable
%lookup and beta reduction, an inconvenience that is readily accepted when the
%alternative would be to tame domain theory.

\subsection{Static Analysis by Abstraction of Operational Semantics}

As a result, we are stuck with a large amount of literature and implementations
on \emph{compositional} program analyses such as in \citet{cardinality-ext}
that have to be proven correct \wrt a transition system.
Compared to when a denotational semantics is available, this \emph{structural
mismatch} necessitates the invention of ad-hoc, complicated correctness
relations that must proven to be preserved during transitions.

When there is no semantics that structurally matches our analysis, we could
try to rearrange our analysis.
That is the idea of \emph{Abstracting Abstract Machines}~(AAM)~\citep{aam} which
abandons compositional analysis in favour of a convenient proof by abstract
interpretation of the transition semantics.
The resulting static analysis is no longer defined as a function that recurses
over the input expression, but rather as an iterative fixpoint procedure that
approximates the set of possible states in the transition system that reach a
given sub-expression.
However, such a definition is hard to reconcile with existing battle-proven and
compositional static analyses in compilers such as the Glasgow Haskell Compiler
due to the structural mismatch.
It would be preferable to verify these implementations, too.

%It is not so simple in lattice-based compiler analyses, because recursive
%$\mathbf{let}$ bindings invite fixpoint iteration. If you think about
%``well-annotatedness'' of a machine configuration according to an analysis as a
%type system, the corresponding ``preservation lemma'' needs to relate fixpoints
%before and after \emph{every} kind of machine transition!
%This necessitates a dreadful application of fixpoint induction, unfolding
%the whole analysis function body before and after each step and thus culminating
%in beaurocratic nightmare.
%Of course, the definition of ``well-annotatedness'' needs to encompass whole
%machine configurations, including the (mutually recursive, in call-by-need)
%stack and heap, see the proofs in~\citep{cardinality-ext} for a taste. It is
%hard to raise confidence in such a proof without full mechanisation.
%A denotational semantics would arguably simplify the proof, unfortunately one
%allowing to observe evaluation cardinality of call-by-need is lacking to this
%day.

\subsection{Summary of Contributions}

Our ambitious goal is to resolve the aforementioned tensions around operational
detail and structural mismatch via the following contributions:
\begin{itemize}
  \item In \Cref{sec:problem}, we explicate the lack of operational detail in
    denotational semantics and the structural mismatch problem \wrt operational
    semantics by the example of \emph{usage analysis}, a generalisation of
    deadness analysis.
  \item In \Cref{sec:stateful}, we give a compositional semantics
    for call-by-need lambda calculus that generates an abstraction of
    potentially infinite small-step traces. Unlike traditional formulations
    of denotational semantics, our semantics is defined by \emph{guarded
    recursion}~\citep{gdtt} and thus total as a mathematical function.
    Our semantics is distinct from similar ones for call-by-name or
    call-by-value and allows to observe evaluation cardinality as needed.
    We believe that our semantics is the first with the aforementioned two
    qualities and prove it adequate \wrt a standard operational semantics.
  \item The semantics in \Cref{sec:stateful} is one generating \emph{stateful}
    traces.
    This is in line with the standard operational approach in which
    self-contained states are the objects of interest.
    Borrowing ideas from the \emph{maximal trace semantics} of
    \citet{Cousot:21}, we define an equivalent, but more convenient
    \emph{stateless} semantics in \Cref{sec:stateless} and will see how to
    recover state from program history as needed.
  \item We employ the stateless semantics as a collecting semantics and derive
    the usage analysis of \Cref{sec:problem} by \emph{calculational design}~\citep{Cousot:21}.
    Similar derivations will be considered for Control Flow Analysis~\citep{Shivers:91}.
    \sg{Hopefully :)}
    % Urgh, not yet:
    %  Since call-by-need lambda calculus is the simplest language that features
    %  both function calls and state, it is possible for the first time to prove
    %  correct the ``functional approach'' by
  \item Talk about prototype in Haskell? Formalisation in Agda?
  \item Related Work \Cref{sec:related-work}
\end{itemize}

