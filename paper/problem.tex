\section{Problem Statement}
\label{sec:problem}

%By way of the poster child example of a compositional definition of \emph{usage
%analysis}, we showcase how the operational detail available in traditional
%denotational semantics is too coarse to substantiate a correctness criterion,
%although the \emph{proof} of (a weaker notion of) correctness is simple and direct.
%While operational semantics observe sufficient detail to formulate a correctness
%criterion, it is quite complicated to come up with a suitable inductive
%hypothesis for the correctness proof.

\subsection{Usage Analysis and Deadness, Intuitively}
\label{sec:usage-intuition}

\begin{figure}
\begin{minipage}{\textwidth}
\[\begin{array}{c}
 \arraycolsep=3pt
 \begin{array}{rrclcl}
  \text{Scott Domain}      &  d & ∈ & \ScottD & =   & [\ScottD \to_c \ScottD]_\bot \\
  \text{Usage cardinality} &  u & ∈ & \Card & =   & \{ 0 ⊏ 1 ⊏ ω \} ⊂ ℕ_ω \\
  \text{Usage Domain}      &  d & ∈ & \UsgD & =   & \Var \to \Card \\
 \end{array} \quad
 \begin{array}{rcl}
   (ρ_1 ⊔ ρ_2)(\px) & = & ρ_1(\px) ⊔ ρ_2(\px) \\
   (ρ_1 + ρ_2)(\px) & = & ρ_1(\px) + ρ_2(\px) \\
   (u * ρ_1)(\px)   & = & u * ρ_1(\px) \\
 \end{array}
 \\[-0.5em]
\end{array}\]
\subcaption{Syntax of semantic domains}
  \label{fig:dom-syntax}
\newcommand{\scalefactordenot}{0.92}
\scalebox{\scalefactordenot}{%
\begin{minipage}{0.49\textwidth}
\arraycolsep=0pt
\[\begin{array}{rcl}
  \multicolumn{3}{c}{ \ruleform{ \semscott{\wild} \colon \Exp → (\Var \to \ScottD) → \ScottD } } \\
  \\[-0.5em]
  \semscott{\px}_ρ & {}={} & ρ(\px) \\
  \semscott{\Lam{\px}{\pe}}_ρ & {}={} & \fn{d}{\semscott{\pe}_{ρ[\px ↦ d]}} \\
  \semscott{\pe~\px}_ρ & {}={} & \begin{cases}
     f(ρ(x)) & \text{if $\semscott{\pe} = f$}  \\
     \bot   & \text{otherwise}  \\
   \end{cases} \\
  \semscott{\Letsmall{\px}{\pe_1}{\pe_2}}_ρ & {}={} &
    \begin{letarray}
      \text{letrec}~ρ'. & ρ' = ρ \mathord{⊔} [\px \mathord{↦} d_1] \\
                        & d_1 = \semscott{\pe_1}_{ρ'} \\
      \text{in}         & \semscott{\pe_2}_{ρ'}
    \end{letarray} \\
\end{array}\]
\subcaption{\relscale{\fpeval{1/\scalefactordenot}} Denotational semantics after Scott}
  \label{fig:denotational}
\end{minipage}%
\quad
\begin{minipage}{0.56\textwidth}
\arraycolsep=0pt
\[\begin{array}{rcl}
  \multicolumn{3}{c}{ \ruleform{ \semusg{\wild} \colon \Exp → (\Var → \UsgD) → \UsgD } } \\
  \\[-0.5em]
  \semusg{\px}_ρ & {}={} & ρ(\px) \\
  \semusg{\Lam{\px}{\pe}}_ρ & {}={} & ω*\semusg{\pe}_{ρ[\px ↦ \bot]} \\
  \semusg{\pe~\px}_ρ & {}={} & \semusg{\pe} + ω*ρ(\px)
    \phantom{\begin{cases}
       f(ρ(x)) & \text{if $\semscott{\pe} = f$}  \\
       \bot   & \text{otherwise}  \\
     \end{cases}} \\
  \semusg{\Letsmall{\px}{\pe_1}{\pe_2}}_ρ& {}={} & \begin{letarray}
      \text{letrec}~ρ'. & ρ' = ρ \mathord{⊔} [\px \mathord{↦} d_1] \\
                        & d_1 = [\px\mathord{↦}1] \mathord{+} \semusg{\pe_1}_{ρ'} \\
      \text{in}         & \semusg{\pe_2}_{ρ'}
    \end{letarray}
\end{array}\]
\subcaption{\relscale{\fpeval{1/\scalefactordenot}} Naïve usage analysis}
  \label{fig:usage}
\end{minipage}
}
\end{minipage}
  \label{fig:intro}
\caption{Connecting usage analysis to denotational semantics}
\end{figure}

Let us begin by defining the object language of this work, a labelled lambda
calculus with recursive let bindings and algebraic data types:
\[
\arraycolsep=3pt
\begin{array}{rrclcrrclcl}
  \text{Variables}    & \px, \py & ∈ & \Var        &     & \quad \text{Constructors} &        K & ∈ & \Con        &     & \text{with arity $α_K ∈ ℕ$} \\
  \text{Labels}       &     \lbl & ∈ & \Labels     &     & \quad \text{Values}       &      \pv & ∈ & \Val        & ::= & \highlight{\Lam{\px}{\pe}} \mid K~\many{\px}^{α_K} \\
  \text{Expressions}  &      \pe & ∈ & \Exp        & ::= & \multicolumn{6}{l}{\highlight{\slbl \px \mid \slbl \pv \mid \slbl \pe~\px \mid \slbl \Let{\px}{\pe_1}{\pe_2}} \mid \slbl \Case{\pe}{\SelArity}}
\end{array}
\]
The form is reminiscent of \citet{Launchbury:93} and \citet{Sestoft:97} because
it is factored into \emph{A-normal form}, that is, the arguments of applications
are restricted to be variables, so the difference between call-by-name and
call-by-value manifests purely in the semantics of $\mathbf{let}$.
In this section, only the highlighted parts are relevant for brevity; we will
discuss semantics of labels and data types in \Cref{sec:stateful}.
From hereon throughout, we assume that all labels and bound program variables
are distinct.

We give a standard call-by-name denotational semantics $\semscott{\wild}$ in
\Cref{fig:denotational} \citep{ScottStrachey:71}, assigning meaning to our
syntax by means of the infamous Scott domain $\ScottD$ defined in
\Cref{fig:dom-syntax}.%
\footnote{As usual, the notation $[X \to_c X]_\bot$ is meant to indicate the
topology of Scott-continuous endofunctions on $X$ together with a distinct least
element $\bot$.
Then the Scott domain $\ScottD$ is the solution to the emerging domain equation.}
Squinting a bit, we find that $\semscott{\wild}$ looks quite similar to
the function to its right in \Cref{fig:usage}, depicting a \emph{usage
analysis} $\semusg{\wild}$, a static analysis for estimating an upper bound on
\emph{evaluation cardinality}, \eg, how often a variable is evaluated.

Such upper bounds on evaluation cardinality are represented by a $u ∈ \Card$,
and for a given expression $\pe$, an element $d ∈ \UsgD$ can denote how many
times $\pe$ evaluates its free variables.
Any number of uses beyond $1$, such as $2$ for $x$ in $(x+x)$, will be collapsed to
$d(x) = ω$, which denotes the set of any possible number of uses and is thus the
top element of the total order $\Card$.
For open expressions, we will need a way to describe the denotations of its
free variables with a \emph{usage environment} $\tr ∈ \Var \to \UsgD$.
Note that we will occassionally adorn with \textasciitilde{} to disambiguate
elements of the analysis domain from the semantic domain.
Given a usage environment $\tr$, $\tr(x)(y)$ is supposed to model an upper bound
on how often the expression bound to $x$ evaluates $y$.

We say that $x$ is \emph{potentially live} in an element $d ∈ \UsgD$ whenever
$\bot = 0 ⊏ d(x)$ (where $\bot$ denotes the least element of a partial order
such as $\Card$ that is inferred from context).
Let us now call
\[
  \tr_Δ(\px) \triangleq \fn{\py}{\ternary{\px = \py}{1}{0}}
\]
the ``diagonal'' usage environment, assigning each free variable $\px$ a unique
meaning in terms of a denotation that evaluates $\px$ once and nothing else.
Then we will say that $x$ is potentially live in $\pe$ whenever it is
potentially live in $d \triangleq \semusg{\pe}_{\tr_Δ}$.
Likewise, when $d(x) = 0$ we say that $x$ is \emph{dead} in $d$/$\pe$, \eg,
\emph{never evaluated}.
In this way, $\semusg{\wild}$ can be used to infer facts of the form ``$\pe$
never evaluates $x$'' from the introduction.

Note that the usage analysis is naïve in its treatment of function application:
It assumes that that every function deeply evaluates its argument.
Whenever $y$ is assumed to be live in $x$ (which is encoded as $\tr(x) ⊑
\tr(y)$), the analysis will report that $(f~y)$ is live in $x$, regardless of
whether $f$ evaluates its argument.
In turn, the analysis assumes in the lambda case that liveness of the argument
has been accounted for at the call site, hence the lambda-bound variable $\px$
is not live in any variable and denoted by $\bot$ in $\tr$ (according to the
pointwise ordering, $\forall \px.\ \bot_{\UsgD}(\px) = \bot_{\Card} = 0$).

\subsection{Usage Analysis Infers Denotational Deadness}

The requirement (in the sense of informal specification) on an assertion
such as ``$x$ is dead'' in a program like $\Let{x}{\pe_1}{\pe_2}$ is that we
may rewrite to $\Let{x}{panic}{\pe_2}$ and perhaps even to $\pe_2$ without
observing any change in semantics. Doing so reduces code size and heap
allocation.

This can be made formal in the following definition of deadness in terms of
$\semscott{\wild}$:

\begin{definition}[Deadness]
  \label{defn:deadness}
  A variable $\px$ is \emph{dead} in an expression $\pe$ if and only
  if, for all $ρ ∈ \Var \to \ScottD$ and $d_1, d_2 ∈ \ScottD$, we have
  $\semscott{\pe}_{ρ[\px↦d_1]} = \semscott{\pe}_{ρ[\px↦d_2]}$.
  Otherwise, $\px$ is \emph{live}.
\end{definition}

Indeed, if we know that $x$ is dead, then the following equation justifies our
rewrite above: $\semscott{\Let{x}{\pe_1}{\pe_2}}_ρ = \semscott{\pe_2}_{ρ[x↦d]} =
\semscott{\pe_2}_ρ$ (for all $ρ$ and the suitable $d$).
So our definition of deadness is not only simple to grasp, but also simple to
exploit.

We can now try to prove our usage analysis correct as a liveness analysis in
terms of this notion of deadness. After a bit of trial and error, we could
arrive at the following theorem:

\begin{theorem}[$\semusg{\wild}$ is a correct deadness analysis]
  \label{thm:semusg-correct-live}
  Let $\pe$ be an expression, $\px$ a variable and $\tr$ a usage environment.
  If $\tr(\px) \not⊑ \semusg{\pe}_{\tr}$
  then $\px$ is dead in $\pe$.
\end{theorem}
\begin{proof}
  By induction over $\pe$. The full proof can be found in
  \Cref{prf:semusg-correct-live}.
\end{proof}

The proof capitalises on the similarities in structure by using induction on
the program expression, hence it is simple and direct, at just under a page of
accessible prose.

In practice, it is simpler to exploit the following lemma that instantiates
$\tr$ to $\tr_Δ$:

\begin{corollary}
  \label{thm:semusg-correct-live-simple}
  Let $\pe$ be an expression and $\px$ a variable.
  If $\semusg{\pe}_{\tr_Δ}(\px) = 0$
  then $\px$ is dead in $\pe$.
\end{corollary}
\begin{proof}
  From the assumption $0 = \semusg{\pe}_{\tr_Δ}(\px)$ we know that
  $\tr_Δ(\px)(\px) = 1 \not⊑ 0 = \semusg{\pe}_{\tr_Δ}(\px)$ and hence that
  $\tr_Δ(\px) \not⊑ \semusg{\pe}_{\tr_Δ}$.
  Now we can apply \Cref{thm:semusg-correct-live}.
\end{proof}

This corollary proves that our intuitive notion of potential liveness/deadness
from \Cref{sec:usage-intuition} lines up with the formal \Cref{defn:deadness}.

% It is surprising that the theorem does not need to relate $\tr_Δ$ to
% $ρ$; after all, $ρ(\py)$ (for $\py \not= \px$) might be bound to the
% \emph{meaning} of an expression that is potentially live in $\px$, such as
% $\semscott{\px}_{ρ'}$, and we have no way to observe the dependency on $\px$
% just through $ρ(\py)$.
% The key is to realise that our notion of deadness varies $ρ(\px)$ (the meaning
% of $\px$), but that does not vary $ρ(\py)$, because that only sees $ρ'(\px)$,
% so for all intents and purposes, the proof may assume that $ρ(\py)$ is dead in
% $\px$.
% The analysis, on the other hand, encodes transitive deadness relationships via
% $\tr(\px) ⊑ \tr(\py)$ in case $\px$ occurs in the RHS of a $\mathsf{let}$-bound
% $\py$ to encode that deadness of $\py$ is a necessary condition for deadness of
% $\px$, which requires generalisation of the inductive hypothesis.

\formgoal{1}{Give a semantics that makes correctness proofs similarly simple.}

This is a rather vague goal and should be seen as the overarching principle of
this work.
In support of this principle, we will formulate a few more concrete goals that
each require more context to make sense.

\subsection{Continuity and Divergence}

Nevermind our confidence in the ultimate correctness of $\semusg{\wild}$,
note that our notion of deadness has a blind spot \wrt diverging computations:
$\semscott{\wild}$ denotes any looping program such as
$\Let{\mathit{loop}}{\Lam{x}{\mathit{loop}~x}}{{\mathit{loop}~\mathit{loop}}}$ by $\bot$, the
same element that is meant to indicate partiality in the approximation order
of the domain (\eg, insufficiently specified input).
Hence any looping program is automatically dead in all its free variables, even
though any of them might influence which particular endless loop is taken.

This is not only a curiosity of $\semusg{\wild}$; it also applies to the original
control-flow analysis work~\citep[p. 23]{Shivers:91} where it is remedied
by the introduction of a \emph{non-standard semantic interpretation} that
assigns meaning to diverging programs where the denotational semantics only
says $\bot$.
The latter would actually denote the empty set of reached program labels,
neglecting that any part of the program before the loop was ever reached.
The non-standard semantic interpretation is far more reasonable, but credibility
of this approach solely rests on the structural similarity to the standard
denotational semantics.

Furthermore, as is often done, $\semscott{\wild}$ abuses $\bot$ as a collecting
pool for error cases.
This shows in the following example:
$x$ is dead in $(\Lam{y}{\Lam{z}{z}})~x$, but dropping the $\mathbf{let}$
binding in $\Let{x}{\pe_1}{(\Lam{y}{\Lam{z}{z}})~x}$
introduces a scoping error which is not observable under $\semscott{\wild}$.
We could take inspiration in the work of \citet{Milner:78}
and navigate around the issue by introducing a $\mathbf{wrong}$ denotation for
errors which is propagated strictly; then we would notice when we optimise a
looping program into one that has a scoping error.

We can try the same trick as \citeauthor{Milner:78} and assign diverging
programs a total domain element $\mathbf{div}$ distinct from all other elements.
Then when would we go from $\bot$ to $\mathbf{div}$ in the least fixed-point in
$\semscott{\Let{\wild}{\wild}{\wild}}$?
There is no way to introduce $\mathbf{div}$ unless we make it a partial element
that approximates every total element; but then we could have just chosen $\bot$
as the denotation to begin with.
Hence denoting diverging programs by a partial element $\bot$ or $\mathbf{div}$
is a fundamental phenomenon of traditional denotational semantics and brings
with it annoying pitfalls.
To see one, consider the predicate ``Denotation $d$ will get stuck and not
diverge''.
This predicate is not \emph{admissable}~\citep{Abramsky:94}, because an
admissable predicate that is at all satisfiable would need to be true for
the partial elements $d=\bot$ and $d=\mathbf{div}$.
A practical consequence is that such a predicate could not be proven about a
recursive let binding because that would need admissability to apply fixpoint
induction.

\formgoal{2}{Find a semantic domain in which diverging programs can be denoted
by a total element.}

\subsection{Operational Detail and Structural Mismatch}

Blind spots and annoyances notwithstanding, the denotational notion of deadness
above is quite reasonable and \Cref{thm:semusg-correct-live} is convincing.
But our usage analysis infers more detailed cardinality information;
for example, it can infer whether a binding is evaluated at most once.
This information can be useful to inline a binding that is not a value or
to omit update frames under call-by-need~\citep{cardinality-ext}.%
\footnote{A more useful application of the ``at most once'' cardinality is the
identification of \emph{one-shot} lambdas~\citep{cardinality-ext} --- functions which are
called at most once for every activation --- because it allows floating of heap
allocations from a hot code path into cold function bodies.
Simplicity prohibits $\semusg{\wild}$ from inferring such properties.}
Thus, our usage analysis should satisfy the following generalisation of
\Cref{thm:semusg-correct-live}:

\begin{theorem}[Correctness of $\semusg{\wild}$]
  \label{thm:semusg-correct-2}
  Let $\pe$ be an expression, $\px$ a variable and $\tr$ a usage environment.
  If $(u+1)*\tr(\px) \not⊑ \semusg{\pe}_{\tr}$
  then $\pe$ evaluates $\px$ at most $u$ times.
\end{theorem}

Again, we could simplify the condition to $\semusg{\pe}_{\tr_Δ}(\px) ⊑ u$ for
practical use and intuition.

Unfortunately, our denotational semantics does not allow us to express the
operational property ``$\pe$ evaluates $\px$ at most $u$ times'', so
this theorem cannot be proven correct.

% We should probably mvoe this RElated Work? Don't want to discuss it here
%The problem of observable cardinality also comes up in Quantitative Type
%Theory~\citep{Atkey:18}, where the solution is to give a categorical
%semantics that postulates observability of cardinality in a suitable
%\emph{$R$-Quantitative Category with Families} without giving a concrete
%model.

\formgoal{3}{Find a semantics that can observe operational detail such as
arbitrary evaluation cardinality.}

\subsection{Structural Mismatch}

\begin{figure}
\[\begin{array}{c}
 \begin{array}{rrclcl}
  \text{LK States}     & σ   & ∈ & \States        & =      & \Exp \times \Environments \times \Heaps \times \Continuations \\
  \text{Environments}  & ρ   & ∈ & \Environments  & =      & \Var \pfun \Addresses \\
  \text{Addresses}     & \pa & ∈ & \Addresses     & \simeq & ℕ \\
  \text{Heaps}         & μ   & ∈ & \Heaps         & =      & \Addresses \pfun \Environments \times \Exp \\
  \text{Continuations} & κ   & ∈ & \Continuations & ::=    & \StopF \mid \ApplyF(\pa) \pushF κ \mid \SelF(ρ,\SelArity) \pushF κ \mid \UpdateF(\pa) \pushF κ \\
 \end{array} \\
  \\[-0.5em]
\end{array}\]

\newcolumntype{L}{>{$}l<{$}} % math-mode version of "l" column type
\newcolumntype{R}{>{$}r<{$}} % math-mode version of "r" column type
\newcolumntype{C}{>{$}c<{$}} % math-mode version of "c" column type
\resizebox{\textwidth}{!}{%
\begin{tabular}{LR@{\hspace{0.4em}}C@{\hspace{0.4em}}LL}
\toprule
\text{Rule} & σ_1 & \smallstep & σ_2 & \text{where} \\
\midrule
\BindT & (\Let{\px}{\pe_1}{\pe_2},ρ,μ,κ) & \smallstep & (\pe_2,ρ',μ[\pa↦(ρ',\pe_1)], κ) & \pa \not∈ \dom(μ),\ ρ'\! = ρ[\px↦\pa] \\
\AppIT & (\pe~\px,ρ,μ,κ) & \smallstep & (\pe,ρ,μ,\ApplyF(\pa) \pushF κ) & \pa = ρ(\px) \\
\CaseIT & (\Case{\pe_s}{\Sel[r]},ρ,μ,κ) & \smallstep & (\pe_s,ρ,μ,\SelF(ρ,\Sel[r]) \pushF κ) & \\
\LookupT & (\px, ρ, μ, κ) & \smallstep & (\pe, ρ', μ, \UpdateF(\pa) \pushF κ) & \pa = ρ(\px),\ (ρ',\pe) = μ(\pa) \\
\AppET & (\Lam{\px}{\pe},ρ,μ, \ApplyF(\pa) \pushF κ) & \smallstep & (\pe,ρ[\px ↦ \pa],μ,κ) &  \\
\CaseET & (K'~\many{y},ρ,μ, \SelF(ρ',\Sel) \pushF κ) & \smallstep & (\pe_i,ρ'[\many{\px_i ↦ \pa}],μ,κ) & K_i = K',\ \many{\pa = ρ(\py)} \\
\UpdateT & (\pv, ρ, μ, \UpdateF(\pa) \pushF κ) & \smallstep & (\pv, ρ, μ[\pa ↦ (ρ,\pv)], κ) & \\
\bottomrule
\end{tabular}
} % resizebox
\caption{Lazy Krivine transition semantics $\smallstep$}
  \label{fig:lk-semantics}
\end{figure}

Let us try a different approach then and define a stronger notion of deadness
in terms of a small-step operational semantics such as the Mark II machine of
\citet{Sestoft:97} given in \Cref{fig:lk-semantics}, the semantic ground truth
for this work. (A close sibling for call-by-value would be a CESK machine
\citep{Felleisen:87} or a simpler derivative thereof.)
It is a Lazy Krivine (LK) machine implementing call-by-need, so for a meaningful
comparison to the call-by-name semantics $\semscott{\wild}$, we ignore rules
$\CaseIT, \CaseET, \UpdateT$ and the pushing of update frames in $\LookupT$ for
now to recover a call-by-name Krivine machine with explicit heap addresses.%
\footnote{Note that discarding update frames makes the heap entries immutable,
which makes the explicit heap unnecessary. Of course, for call-by-name we would
not need a heap to begin with, but the point is to get a glimpse at the effort
necessary for call-by-need.}

The configurations $σ$ in this transition system resemble abstract machine
states, consisting of a control expression $\pe$, an environment $ρ$ mapping
lexically-scoped variables to their current heap address, a heap $μ$ listing a
closure for each address, and a stack of continuation frames $κ$.

The notation $f ∈ A \pfun B$ used in the definition of $ρ$ and $μ$ denotes a
finite map from $A$ to $B$, a partial function where the domain $\dom(f)$ is
finite and $\rng(f)$ denotes its range.
The literal notation $[a_1↦b_1,...,a_n↦b_n]$ denotes a finite map with domain
$\{a_1,...,a_n\}$ that maps $a_i$ to $b_i$. Function update $f[a ↦ b]$
maps $a$ to $b$ and is otherwise equal to $f$.

The initial machine state for a closed expression $\pe$ is given by the
injection function $\inj(\pe) = (\pe,[],[],\StopF)$ and
the final machine states are of the form $(\pv,\wild,\wild,\StopF)$.
We bake into $σ∈\States$ the simplifying invariant of \emph{well-addressedness}:
Any address $\pa$ occuring in $ρ$, $κ$ or the range of $μ$ must be an element of
$\dom(μ)$.
It is easy to see that the transition system maintains this invariant and that
it is still possible to observe scoping errors which are thus confined to lookup
in $ρ$.

This machine allows us to observe variable lookups as $\LookupT$ transitions.
Unfortunately, we still suffer from immense proof complexity caused by the
\emph{structural mismatch} between transition semantics and compositional
analysis, as we shall see in due course.
Let us first try to define a notion of deadness that is similar to
\Cref{defn:deadness}, in terms of \emph{contextual equivalence} as in
\citep{MoranSands:99}:

\begin{definition}[Deadness, operationally]
  \label{defn:deadness2}
  Let $\pe$ be an expression and $\px$ a variable.
  $\px$ is \emph{dead} in $\pe$ if and only if
  for any evaluation context $(ρ,μ,κ)$ and expressions $\pe_1,\pe_2$
  (where $\px$ does not occur in the context)
  the sequences of transitions $(\Let{\px}{\pe_1}{\pe},ρ,μ,κ) \smallstep^*$
  and $(\Let{\px}{\pe_2}{\pe},ρ,μ,κ) \smallstep^*$ operate in lockstep.
  Otherwise, $\px$ is \emph{live}.
\end{definition}

This definition captures diverging behaviors correctly and straightforwardly
legitimises the transformation we want to perform, without any mention of
addresses. It is however unwieldy in a correctness proof due to its use of
bisimulation, so a bit of rejigging is in order:

\begin{lemma}[Without proof]
  $\px$ is dead in $\pe$ if and only if for any evaluation context $(ρ,μ,κ)$
  and $\pa \not∈ \dom(μ)$ there exists no sequence of transitions
  $(\pe,ρ[\px↦\pa],μ[\pa↦([],\Lam{z}{z})],κ) \smallstep^* (\py,ρ',μ',κ')$ such
  that $ρ'(\py) = \pa$.
\end{lemma}

This property is a bit easier to handle in a proof.
However, note that it is not compositional in $\pe$:
To see that, consider a variable occurrence $y$; is $x$ dead in $y$?
That depends on which expression $y$ is bound to in the heap, but our deadness
predicate does not make assumptions about free variables.
Consequently, it is impossible to prove that $\semusg{\pe}$ satisfies
\Cref{thm:semusg-correct-live} by direct structural induction on $\pe$ (in a way
that would be useful to the proof).

Instead, such proofs are often conducted by induction over the reflexive
transitive closure of the transition relation.
For that it is necessary to give an inductive hypothesis that considers
environments, stacks and heaps.
One way is to extend the analysis function $\semusg{\wild}$ to entire
configurations and then prove that if $σ_1 \smallstep σ_2$ we have $\semusg{σ_2}
⊑ F(\semusg{σ_1})$, where $F$ is the abstraction of the particular transition
rule taken and is often left implicit.
This is a daunting task, for multiple reasons:
First off, $\semusg{\wild}$ might be quite complicated in practice and extending
it to entire configurations multiplies this complexity.
Secondly, $\semusg{\wild}$ makes use of fixpoints in the let case,
so $\semusg{σ_2} ⊑ F(\semusg{σ_1})$ relates fixpoints that are ``out of sync'',
implying a need for fixpoint induction.

In call-by-need, there will be a fixpoint between the heap and stack due to
update frames acting like heap bindings whose right-hand side is under
evaluation (a point that is very apparent in the semantics of
\citet{Ariola:95}), so fixpoint induction needs to be applied \emph{at every
case of the proof}, diminishing confidence in correctness unless the proof is
fully mechanised.

For an analogy with type systems: What we just tried is like attempting a proof
of preservation by referencing the result of an inference algorithm rather than
the declarative type system. So what is often done instead is to define a declarative and
more permissive \emph{correctness relation} $C(σ)$ to prove preservation $C(σ_1)
\Longrightarrow C(σ_2)$ (\eg, that $C$ is \emph{logical} \wrt $\smallstep$).
$C$ is chosen such that
  (1) it is strong enough to imply the property of interest (deadness)
  (2) it is weak enough that it is implied by the analysis result for an initial state ($\tr(\px) \not⊑ \semusg{\pe}_{\tr}$).
Examples of this approach are the
``well-annotatedness'' relation in \citep[Lemma 4.3]{cardinality-ext} or
$\sim_V$ in \citep[Theorem 2.21]{Nielson:99}) and in fact the correctness
relations we give in \Cref{sec:stateful,sec:stateless}.
We found it quite hard to come up with a suitable ad-hoc correctness relation
for usage analysis, though, and postpone futher discussion to
\Cref{sec:abstractions}, where the full correctness relation in
\Cref{thm:semusg-correct-2} and its proof is derived by abstract
interpretation~\citep{Cousot:21}.
\sg{TODO}

Often, correctness proofs do not need the full operational detail of a
CESK-style machine, in which case a simpler machine definition leads to simpler
proof.
If the correctness statement does not need to keep track about which address
is an activation of which let-bound program variable, the distinction between
addresses and variables is unnecessary and the environment component vanishes.
The stack can often be reflected back into the premises of the judgment
rules, distinguishing \emph{instruction transitions} from \emph{search
transitions}, a distinction which is made explicit in a \emph{contextual
semantics}.
Applying both these transformations yields a CS machine~\citep{Felleisen:87}.
However for call-by-need, the evaluation context corresponding to an update
frame is neither obvious nor simple~\citep{Ariola:95}.
For pure call-by-value and call-by-name calculi, the heap becomes
immutable and variables can be substituted immediately for their right-hand
sides/arguments rather than delaying lookup to the variable case, abolishing the
need for the heap altogether and yielding a contextual semantics where
states are a simple expression.

These refactorings help in simplifying proofs:
Instead of defining a coinductive well-formedness predicate on the heap, we
prove a substitution lemma.
Instead of a well-formedness predicate for the stack, we appeal to the
well-formedness of the search transition rule.

We have just descended into a mire of complexity to appreciate the following
goal:

\formgoal{4}{Avoid structural mismatch between semantics and analysis.}

Goal 4 can be seen as a necessary condition for Goal 1:
Structural mismatch makes a simple proof impossible.
Since our analysis is compositional, we strive for a compositional semantics in
\Cref{sec:stateful,sec:stateless}.
An alternative to avoid structural mismatch is to follow Abstracting Abstract
Machines~\citep{aam}.
We will compare our approach to theirs in \Cref{sec:related-work}.

%\subsection{Abstracting Abstract Machines}
%
%Another way to work around the structural mismatch is to adopt the structure of
%the semantics in the analysis; this is done in the Abstracting Abstract Machines
%work \citep{aam}.
%The appeal is to piggy-back traditional and well-explored intraprocedural
%analysis techniques on the result of an interprocedural flow
%analysis~\citep{Shivers:91}.
