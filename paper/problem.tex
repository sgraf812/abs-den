\section{Problem Statement}
\label{sec:problem}

By way of the poster child example of a compositional definition of \emph{usage
analysis}, we showcase how the operational detail available in traditional
denotational semantics is too coarse to substantiate a correctness criterion,
although the proof of (a weaker notion of) correctness is simple and direct.
While operational semantics observe sufficient detail to formulate a correctness
criterion, it is quite complicated to come up with a suitable inductive
hypothesis for the correctness proof.

%\subsection{Notation}
%
%Collection of stuff to explain, for now:
%\begin{itemize}
%  \item $\triangleq$ for defining an object (defn eq), rather than $=$
%  \item $\text{letrec}$
%    The (meta-level, math) notation
%    \[
%    \text{letrec}~l.~\many{x = rhs_x} ~ l = rhs_{l} ~ \many{y = rhs_y}~\text{in}~body
%    \]
%    where $l$ might occur freely in any $rhs_{\wild}$ and $body$, is syntactic sugar for
%    \[
%    snd(\lfp(\fn{(l,\wild)}{\text{let}~\many{x = rhs_x} ~ \many{y = rhs_y}~\text{in}~(rhs_{l},body)}))
%    \]
%    Where $\lfp$ is the least fixpoint operator and $snd(a,b) = b$. Clearly, this
%    desugaring's use of $\lfp$ is well-defined for its use on elements of the
%    powerset lattice $\UsgD$.
%
%    But \citep{Shivers:91} uses the similar $\text{whererec}$ and gets by without
%    ever explaining it, so we might as well.
%\end{itemize}

\subsection{Usage Analysis and Deadness, Intuitively}

\begin{figure}
\begin{minipage}{\textwidth}
\[\begin{array}{c}
 \arraycolsep=3pt
 \begin{array}{rrclcrrclcl}
  \text{Variables}    & \px, \py & ∈ & \Var        &     & \quad \text{Constructors} &        K & ∈ & \Con        &     & \text{with arity $α_K ∈ ℕ$} \\
  \text{Labels}       &     \lbl & ∈ & \Labels     &     & \quad \text{Values}       &      \pv & ∈ & \Val        & ::= & \highlight{\Lam{\px}{\pe}} \mid K~\many{\px}^{α_K} \\
  \text{Expressions}  &      \pe & ∈ & \Exp        & ::= & \multicolumn{6}{l}{\highlight{\slbl \px \mid \slbl \pv \mid \slbl \pe~\px \mid \slbl \Let{\px}{\pe_1}{\pe_2}} \mid \slbl \Case{\pe}{\SelArity}} \\
  \\[-0.5em]
 \end{array} \\
 \\[-0.5em]
 \begin{array}{rrclcl}
  \text{Scott Domain}      &  d & ∈ & \ScottD & =   & [\ScottD \to_c \ScottD]_\bot \\
  \text{Usage cardinality} &  u & ∈ & \Card & =   & \{ 0 ⊏ 1 ⊏ ω \} ⊂ ℕ_ω \\
  \text{Usage Domain}      &  d & ∈ & \UsgD & =   & \Var \to \Card \\
 \end{array} \quad
 \begin{array}{rcl}
   (ρ_1 ⊔ ρ_2)(\px) & = & ρ_1(\px) ⊔ ρ_2(\px) \\
   (ρ_1 + ρ_2)(\px) & = & ρ_1(\px) + ρ_2(\px) \\
   (u * ρ_1)(\px)   & = & u * ρ_1(\px) \\
 \end{array}
 \\[-0.5em]
\end{array}\]
\subcaption{Syntax of expressions and semantic domains}
  \label{fig:syntax}
\newcommand{\scalefactordenot}{0.92}
\scalebox{\scalefactordenot}{%
\begin{minipage}{0.49\textwidth}
\arraycolsep=0pt
\[\begin{array}{rcl}
  \multicolumn{3}{c}{ \ruleform{ \semscott{\wild} \colon \Exp → (\Var \to \ScottD) → \ScottD } } \\
  \\[-0.5em]
  \semscott{\px}_ρ & {}={} & ρ(\px) \\
  \semscott{\Lam{\px}{\pe}}_ρ & {}={} & d ↦ \semscott{\pe}_{ρ[\px ↦ d]} \\
  \semscott{\pe~\px}_ρ & {}={} & \begin{cases}
     f(ρ(x)) & \text{if $\semscott{\pe} = f$}  \\
     \bot   & \text{otherwise}  \\
   \end{cases} \\
  \semscott{\Letsmall{\px}{\pe_1}{\pe_2}}_ρ & {}={} &
    \begin{letarray}
      \text{letrec}~ρ'. & ρ' = ρ \mathord{⊔} [\px \mathord{↦} d_1] \\
                        & d_1 = \semscott{\pe_1}_{ρ'} \\
      \text{in}         & \semscott{\pe_2}_{ρ'}
    \end{letarray} \\
\end{array}\]
\subcaption{\relscale{\fpeval{1/\scalefactordenot}} Denotational semantics after Scott}
  \label{fig:denotational}
\end{minipage}%
\quad
\begin{minipage}{0.56\textwidth}
\arraycolsep=0pt
\[\begin{array}{rcl}
  \multicolumn{3}{c}{ \ruleform{ \semusg{\wild} \colon \Exp → (\Var → \UsgD) → \UsgD } } \\
  \\[-0.5em]
  \semusg{\px}_ρ & {}={} & ρ(\px) \\
  \semusg{\Lam{\px}{\pe}}_ρ & {}={} & ω*\semusg{\pe}_{ρ[\px ↦ \bot]} \\
  \semusg{\pe~\px}_ρ & {}={} & \semusg{\pe} + ω*ρ(\px)
    \phantom{\begin{cases}
       f(ρ(x)) & \text{if $\semscott{\pe} = f$}  \\
       \bot   & \text{otherwise}  \\
     \end{cases}} \\
  \semusg{\Letsmall{\px}{\pe_1}{\pe_2}}_ρ& {}={} & \begin{letarray}
      \text{letrec}~ρ'. & ρ' = ρ \mathord{⊔} [\px \mathord{↦} d_1] \\
                        & d_1 = [\px\mathord{↦}1] \mathord{+} \semscott{\pe_1}_{ρ'} \\
      \text{in}         & \semusg{\pe_2}_{ρ'}
    \end{letarray}
\end{array}\]
\subcaption{\relscale{\fpeval{1/\scalefactordenot}} Naïve usage analysis}
  \label{fig:usage}
\end{minipage}
}
\end{minipage}
  \label{fig:intro}
\caption{Connecting usage analysis to denotational semantics}
\end{figure}

\Cref{fig:syntax} defines the labelled syntax of a lambda calculus with
recursive let bindings and algebraic data types, reminiscent of
\citet{Sestoft:97}. The calculus is factored into \emph{administrative normal
form}, that is, the arguments of applications are restricted to be variables, so
the difference between call-by-name and call-by-value manifests purely in the
semantics of $\mathbf{let}$.
In this section, only the highlighted parts are relevant; we will ignore labels
and data types for brevity.

We give a standard call-by-name denotational semantics $\semscott{\wild}$ in
\Cref{fig:denotational} \citep{ScottStrachey:71}, assigning meaning to our
syntax by means of the infamous Scott domain $\ScottD$.
Squinting a bit, we find that it looks quite similar to the function
to its right in \Cref{fig:usage}, depicting a \emph{usage analysis}
$\semusg{\wild}$, a static analysis for estimating an upper bound on how often
a variable is evaluated. The given analysis is naïve in that its treatment of
function application assumes that every function deeply evaluates its argument.

Assuming that all program variables are distinct (a silent assumption from
here on throughout), the result of $\semusg{\wild}$ is an element $d ∈ \UsgD$,
an environment that maps to each variable an upper bound on its \emph{evaluation
cardinality}, that is, how often the variable is evaluated over the cause of any
of its activations.
Whenever $0 ⊏ d(x)$, we say that it is \emph{potentially live} in $d$ and
extend this meaning to a program $\pe$ whenever $\semusg{\pe} = d$.
Likewise, when $d(x) = 0$ we say that $x$ is \emph{dead} in $d$ and the programs
$d$ denotes, \eg, \emph{never evaluated}. In this way, $\semusg{\wild}$ can
be used to infer facts of the form ``$\pe$ never evaluates $x$'' from the
introduction.

\subsection{Denotational Deadness, Continuity and Divergence}

The \emph{requirement} (in the sense of informal specification) on an assertion
such as ``$x$ is dead'' in a program like $\Let{x}{\pe_1}{\pe_2}$ is that we
may rewrite to $\Let{x}{panic}{\pe_2}$ and perhaps even to $\pe_2$ without
observing any change in semantics. Doing so reduces code size and heap
allocation.

This can be made formal in the following definition of deadness in terms of
$\semscott{\wild}$:

\begin{definition}[Deadness]
  \label{defn:deadness}
  A variable $\px$ is \emph{dead} in an expression $\pe$ if and only
  if, for all $ρ ∈ \Var \to \ScottD$ and $d_1, d_2 ∈ \ScottD$, we have
  $\semscott{\pe}_{ρ[\px↦d_1]} = \semscott{\pe}_{ρ[\px↦d_2]}$.
  Otherwise, $\px$ is \emph{live}.
\end{definition}

Indeed, if we know that $x$ is dead, then the following equation justifies our
rewrite above: $\semscott{\Let{x}{\pe_1}{\pe_2}}_ρ = \semscott{\pe_2}_{ρ[x↦d]} =
\semscott{\pe_2}_ρ$ (for all $ρ$ and the suitable $d$).
So our definition of deadness is not only simple to grasp, but also simple to
exploit.

We can now try to prove our usage analysis correct as a liveness analysis in
terms of this notion of deadness. After a bit of trial and error, we could
arrive at the following theorem:

\begin{theorem}[$\semusg{\wild}$ is a correct potential liveness analysis]
  \label{thm:semusg-correct-live}
  Let $\pe$ be an expression and $\px$ a variable.
  Then $\px$ is dead in $\pe$ whenever
  there exists $\tr ∈ \Var \to \UsgD$ such that
  $\tr(\px) \not⊑ \semusg{\pe}_{\tr}$.
\end{theorem}
\begin{proof}
  By induction over $\pe$. The full proof can be found in
  \Cref{prf:semusg-correct-1}.
\end{proof}

Let us stop and reflect about this theorem for a bit.
Deadness is witnessed by a particular $\tr$ and it helps to think of this
witness as the ``diagonal'' $\tr(\px) \triangleq \fn{\py}{\ternary{\px =
\py}{1}{0}}$, because then the intuitive notion of deadness applies.%
\footnote{In fact, it can be proven that if \emph{any} $\tr$ exists, then the
diagonal is also a witness.}

It is surprising that the theorem does not relate $\tr$ with $ρ$; after all,
$ρ(\py)$ (for $\py \not= \px$) might be bound to the \emph{meaning} of an
expression that is potentially live in $\px$, such as $\semscott{\px}_{ρ'}$, and
we have no way to observe the dependency on $\px$ just through $ρ(\py)$.
The key is to realise that our notion of deadness varies $ρ(\px)$ (the meaning
of $\px$), but that does not vary $ρ(\py)$, because that only sees $ρ'(\px)$,
so for all intents and purposes, the proof may assume that $ρ(\py)$ is dead in
$\px$.
The analysis, on the other hand, encodes transitive deadness relationships via
$\tr(\px) ⊑ \tr(\py)$ in case $\px$ occurs in the RHS of a $\mathsf{let}$-bound
$\py$ to encode that deadness of $\py$ is a necessary condition for deadness of
$\px$.

The proof capitalises on the similarities in structure by using induction on the
program expression, hence it is simple and direct, at just under a page of
accessible prose. Often, such a proof needs to strengthen the induction
hypothesis for the application case, or prove admissability of a predicate to
apply fixpoint induction in the let case, but for deadness and our very simple
analysis we do not need to be so crafty.

Nevermind our confidence in the ultimate correctness of $\semusg{\wild}$,
note that our notion of deadness has a blind spot \wrt diverging computations:
A looping program is automatically dead in all its free variables, even though
any of them might influence which particular endless loop is taken.

This is not a curiosity of $\semusg{\wild}$; it also applies to the original
control-flow analysis work~\citep[p. 23]{Shivers:91} where it is remedied
by the introduction of a \emph{non-standard semantic interpretation} that
assigns meaning to diverging programs where the denotational semantics only
says $\bot$. Credibility of this approach solely rests on the structural
similarity to the standard denotational semantics.

So the issue is not with $\semusg{\wild}$ but with traditional denotational
semantics because it (necessarily) assigns $\bot$ to any diverging computation.
Furthermore, as is often done, $\semscott{\wild}$ abuses $\bot$ as a collecting
pool for error cases.
This shows in the following example:
$x$ is dead in $(\Lam{y}{\Lam{z}{z}})~x$, but rewriting
$\Let{x}{\pe_1}{(\Lam{y}{\Lam{z}{z}})~x}$ to $(\Lam{y}{\Lam{z}{z}})~x$
introduces a scoping error, a change that is not observable under
$\semscott{\wild}$.
We could take inspiration in the work of \citet{Milner:78}
and navigate around the issue by introducing a $\mathbf{wrong}$ denotation for
errors which is propagated strictly; then we would notice when we optimise a
looping program into one that has a scoping error (the only kind of stuckness
that our calculus admits without data types).

However, $\bot$ is still there as the denotation of diverging computations;
hence a predicate such as ``Denotation $d$ will get stuck and not diverge'' is
not an admissable one, because an admissable predicate would be true for $\bot$.

\subsection{Evaluation Cardinality and Call-by-need}
Blind spots notwithstanding, the notion of deadness above is quite reasonable.
But our usage analysis infers more detailed cardinality information; for
example, it can infer whether a binding is evaluated at most once.
This information can be useful under call-by-need to omit pushing of update
frames~\citep{cardinality-ext}.%
\footnote{A more useful application of the ``at most once'' cardinality is the
notion of a \emph{one-shot} lambda~\citep{cardinality-ext}, a function which is
called at most once for every activation, because it allows floating of heap
allocations from a hot code path into cold function bodies.
Simplicity prohibits $\semusg{\wild}$ from inferring such properties.}
Thus, our usage analysis should satisfy the following generalisation of
\Cref{thm:semusg-correct-live}:

\begin{theorem}[Correctness of $\semusg{\wild}$]
  \label{thm:semusg-correct-2}
  Let $\pe$ be an expression and $\px$ a variable.
  Then $\pe$ evaluates $\px$ at most $u$ times whenever
  there exists $\tr ∈ \Var \to \UsgD$ such that
  $(u+1)*\tr(\px) \not⊑ \semusg{\pe}_{\tr}$.
\end{theorem}

Unfortunately, our denotational semantics does not allow us to express the
operational property ``$\pe$ evaluates $\px$ at most $u$ times'', so
this theorem cannot be proven correct.

% We should probably mvoe this RElated Work? Don't want to discuss it here
%The problem of observable cardinality also comes up in Quantitative Type
%Theory~\citep{Atkey:18}, where the solution is to give a categorical
%semantics that postulates observability of cardinality in a suitable
%\emph{$R$-Quantitative Category with Families} without giving a concrete
%model.

\begin{figure}
\[\begin{array}{c}
 \begin{array}{rrclcl}
  \text{LK States}     & σ   & ∈ & \States        & =      & \Controls \times \Environments \times \Heaps \times \Continuations \\
  \text{Controls}      & \pc & ∈ & \Controls      & =      & \Exp \\
  \text{Environments}  & ρ   & ∈ & \Environments  & =      & \Var \pfun \Addresses \\
  \text{Addresses}     & \pa & ∈ & \Addresses     & \simeq & ℕ \\
  \text{Heaps}         & μ   & ∈ & \Heaps         & =      & \Addresses \pfun \Environments \times \Exp \\
  \text{Continuations} & κ   & ∈ & \Continuations & ::=    & \StopF \mid \ApplyF(\pa) \pushF κ \mid \SelF(ρ,\SelArity) \pushF κ \mid \UpdateF(\pa) \pushF κ \\
 \end{array} \\
  \\[-0.5em]
\end{array}\]

\newcolumntype{L}{>{$}l<{$}} % math-mode version of "l" column type
\newcolumntype{R}{>{$}r<{$}} % math-mode version of "r" column type
\newcolumntype{C}{>{$}c<{$}} % math-mode version of "c" column type
\resizebox{\textwidth}{!}{%
\begin{tabular}{LR@{\hspace{0.4em}}C@{\hspace{0.4em}}LL}
\toprule
\text{Rule} & σ_1 & \smallstep & σ_2 & \text{where} \\
\midrule
\BindT & (\Let{\px}{\pe_1}{\pe_2},ρ,μ,κ) & \smallstep & (\pe_2,ρ',μ[\pa↦(ρ',\pe_1)], κ) & \pa \not∈ \dom(μ),\ ρ'\! = ρ[\px↦\pa] \\
\AppIT & (\pe~\px,ρ,μ,κ) & \smallstep & (\pe,ρ,μ,\ApplyF(\pa) \pushF κ) & \pa = ρ(\px) \\
\CaseIT & (\Case{\pe}{\Sel},ρ,μ,κ) & \smallstep & (\pe,ρ,μ,\SelF(ρ,\Sel) \pushF κ) & \\
\LookupT & (\px, ρ, μ, κ) & \smallstep & (\pe, ρ', μ, \UpdateF(\pa) \pushF κ) & \pa = ρ(\px),\ (ρ',\pe) = μ(\pa) \\
\AppET & (\Lam{\px}{\pe},ρ,μ, \ApplyF(\pa) \pushF κ) & \smallstep & (\pe,ρ[\px ↦ \pa],μ,κ) &  \\
\CaseET & (K'~\many{y},ρ,μ, \SelF(ρ',\Sel) \pushF κ) & \smallstep & (\pe_i,ρ'[\many{\px_i ↦ \pa}],μ,κ) & K_i = K',\ \many{\pa = ρ(\py)} \\
\UpdateT & (\pv, ρ, μ, \UpdateF(\pa) \pushF κ) & \smallstep & (\pv, ρ, μ[\pa ↦ (ρ,\pv)], κ) & \\
\bottomrule
\end{tabular}
} % resizebox
\caption{Lazy Krivine transition semantics $\smallstep$}
  \label{fig:lk-semantics}
\end{figure}

Let us try a different approach then and define a stronger notion of deadness
in terms of a small-step operational semantics such as the Mark II machine of
\citet{Sestoft:97} given in \Cref{fig:lk-semantics}, the semantic ground truth
for this work. (A close sibling for call-by-value would be a CESK machine
\citep{Felleisen:87} or a simpler derivative thereof.) It is a variant of
the Lazy Krivine (LK) machine implementing call-by-need, so for a meaningful
comparison to $\semscott{\wild}$, we ignore rules $\CaseIT, \CaseET, \UpdateT$
and the pushing of update frames in $\LookupT$ for now to recover a call-by-name
Krivine machine with explicit heap addresses.%
\footnote{Note that discarding update frames makes the heap entries immutable,
which makes the explicit heap unnecessary. Of course, for call-by-name we would
not need a heap to begin with, but the point is to get a glimpse at the effort
necessary for call-by-need.}

The configurations $σ$ in this transition system resemble abstract machine
states, consisting of control expression $\pe$, an environment $ρ$ mapping
lexically-scoped variables to their current heap address, a heap $μ$ listing a
closure for each address, and a stack of continuation frames $κ$.

The notation $f ∈ A \pfun B$ used in the definition of $ρ$ and $μ$ denotes a
finite map from $A$ to $B$, a partial function where the domain $\dom(f)$ is
finite and $\rng(f)$ denotes its range.
The literal notation $[a_1↦b_1,...,a_n↦b_n]$ denotes a finite map with domain
$\{a_1,...,a_n\}$ that maps $a_i$ to $b_i$. Function update $f[a ↦ b]$
maps $a$ to $b$ and is otherwise equal to $f$.

The initial machine state for a closed expression $\pe$ is given by the
injection function $inj(\pe) = (\pe,[],[],\StopF)$ and
the final machine states are of the form $(\pv,\wild,\wild,\StopF)$.
We bake into $σ$ the simplifying invariant of \emph{well-addressedness}: Any
address $\pa$ occuring in $ρ$, $κ$ or the range of $μ$ must be an element of
$\dom(μ)$. It is easy to see that the transition system maintains this invariant
and that it is still possible to observe scoping errors which are thus confined
to lookup in $ρ$.

Now we are able to define a notion of ``strong deadness'':

\begin{definition}[Deadness, Mark II]
  \label{defn:deadness2}
  Let $\pe$ be an expression and $\px$ a variable.
  $\px$ is \emph{dead} in $\pe$ if and only if
  for any evaluation context $(ρ,μ,κ)$ and expressions $\pe_1,\pe_2$
  (where $\px$ does not occur in the context)
  the sequences of transitions $(\Let{\px}{\pe_1}{\pe},ρ,μ,κ) \smallstep^*$
  and $(\Let{\px}{\pe_2}{\pe},ρ,μ,κ) \smallstep^*$ operate in lockstep.
  Otherwise, $\px$ is \emph{live}.
\end{definition}

This definition captures diverging behaviors correctly and straightforwardly
legitimises the transformation we want to perform, without any mention of
addresses. It is however unwieldy in a correctness proof due to its use of
bisimulation, so a bit of rejigging is in order:

\begin{lemma}[Without proof]
  $\px$ is dead in $\pe$ if and only if for any evaluation context $(ρ,μ,κ)$
  and $\pa \not∈ \dom(μ)$ there exists no sequence of transitions
  $(\pe,ρ[\px↦\pa],μ[\pa↦([],\Lam{z}{z})],κ) \smallstep^* (\py,ρ',μ',κ')$ such
  that $ρ'(\py) = \pa$.
\end{lemma}

This property is a bit easier to handle in a proof.
Unfortunately, it is still not compositional in $\pe$: Consider a variable
occurrence $y$; is $x$ dead in $y$? That depends on which expression $y$ is
bound to in the heap, but our deadness predicate has no notion of making
assumptions about free variables.
Consequently, it is impossible to prove that $\semusg{\pe}$ satisfies
\Cref{thm:semusg-correct-live} by direct structural induction on $\pe$ (in a way
that would be useful to the proof).

Instead, such proofs are often conducted by induction over the reflexive
transitive closure of the transition relation.
For that it is necessary to give an inductive hypothesis that considers
environments, stacks and heaps.
One way is to extend the analysis function $\semusg{\wild}$ to entire
configurations and then prove that if $σ_1 \smallstep σ_2$ we have $\semusg{σ_2}
⊑ F(\semusg{σ_1})$, where $F$ is the abstraction of the particular transition
rule taken and is often left implicit.
This is a daunting task, for multiple reasons:
First off, $\semusg{\wild}$ might be quite complicated in practice and extending
it to entire configurations multiplies this complexity.
Secondly, $\semusg{\wild}$ makes use of fixpoints in the let case and
undoubtedly needs some more fixpoints in its extension to the heap,
so $\semusg{σ_2} ⊑ F(\semusg{σ_1})$ relates fixpoints that are ``out of sync'',
implying a need for fixpoint induction for every transition that touches
the heap.

In call-by-need, there will be a fixpoint between the heap and stack due to
update frames acting like heap bindings whose right-hand side is under
evaluation (a point that is very apparent in the contextual semantics of
\citet{Ariola:95}), so fixpoint induction needs to be applied \emph{at every
case of the proof}, diminishing confidence in correctness unless the proof is
fully mechanised.

For an analogy with type systems: What we just tried is like attempting a proof
of preservation by referencing the result of an inference algorithm rather than
the declarative type system. So what is often done instead is to define a declarative and
more permissive \emph{correctness relation} $C(σ)$ to prove preservation $C(σ_1)
\Longrightarrow C(σ_2)$ (\eg, that $C$ is \emph{logical} \wrt $\smallstep$).
$C$ is chosen such that
  (1) it is strong enough to imply the property of interest (deadness)
  (2) it is weak enough that it is implied by the analysis result for an initial state ($\tr(\px) \not⊑ \semusg{\pe}_{\tr}$).

Examples of this approach are the
``well-annotatedness'' relation in \citep[Lemma 4.3]{cardinality-ext} or
$\sim_V$ in \citep[Theorem 2.21]{Nielson:99}).
We found it quite hard to come up with a suitable ad-hoc correctness relation
and postpone futher discussion to \Cref{sec:abstractions}, where the full
correctness relation in \Cref{thm:semusg-correct-2} and its proof is derived by
abstract interpretation~\citep{Cousot:21}.

Often, correctness proofs do not need to keep track about which address
is an activation of which let-bound program variable, in which case the
distinction between addresses and variables is unnecessary and the
environment component vanishes.
The stack can often be reflected back into the premises of the judgment
rules, so that the system distinguishes \emph{instruction transitions}
from \emph{search transitions}, a distinction which is made explicit in a
\emph{contextual semantics}.
Applying both these translations yields a CS machine~\citep{Felleisen:87}.
For call-by-need, the evaluation context corresponding to an update frame
is neither obvious nor simple~\citep{Ariola:95}.
For effect-free call-by-value and call-by-name calculi, the heap becomes
immutable and variables can be substituted immediately for their right-hand
sides/arguments rather than delaying lookup to the variable case, abolishing the
need for the heap altogether and yielding a contextual semantics where
states are a simple expression.

These refactorings are with the ultimate goal of simplifying proofs:
Instead of defining an coinductive well-formedness predicate on the heap, we
prove a substitution lemma.
Instead of a well-formedness predicate for the stack, we appeal to the
well-formedness of the search transition rule.

\subsection{Abstracting Abstract Machines}

Another way to work around the structure gap is to adopt the structure of the
semantics in the analysis; this is done in the Abstracting Abstract
Machines work \citep{aam}.
To our knowledge, its exclusive application seems to be control-flow analysis
\citep{Shivers:91}, so that the analyses and optimisations that follow do not
need to reason about arbitrary function call structure and can apply traditional
intraprocedural analysis techniques that are well-explored in the imperative
world.
Unfortunately, control-flow information is often invalidated during compiler
passes and we would expect re-running or interleaving the analysis after or
during each pass to be quite costly.
