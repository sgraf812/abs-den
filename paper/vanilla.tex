\section{A Denotational Semantics for Call-by-need}
\label{sec:stateful}

\subsection{Labelled Syntax}

Recall the syntax definition of our object language in
\Cref{sec:usage-intuition} in the style of \citet{Launchbury:93} and
\citet{Sestoft:97}.
Any (sub-)expression has a unique \emph{label} (think of it as the AST node's
pointer identity) that we usually omit. For example, a correct labelling of
$\Let{x}{f~y}{f~x}$ would be
\[
  (\slbln{1} \Let{x}{(\slbln{2} (\slbln{3} f)~y)}{(\slbln{4} (\slbln{5} f)~x)}).
\]
Labels are there so that we do not conflate the (otherwise structurally equal)
sub-terms $(\slbln{3} f)$ and $(\slbln{5} f)$ as equivalent. This is an important
distinction for, \eg, control-flow analysis. Since labels introduce excessive
clutter, we will omit them unless they are distinctively important. If anything,
labels make it so that everything ``works as expected''.

\subsection{Transition System}

\Cref{fig:lk-semantics} gave an operational semantics in terms of
a small-step transition system closest to the lazy Krivine machine
\citep{AgerDanvyMidtgaard:04} for Launchbury's language as presented
in \citet{Sestoft:97}.
It is worth having a second look at the workings of our Gold Standard.

When the control expression $\ctrl(σ)$ of a state $σ$ is a value $\pv$, we
call $σ$ a \emph{return} state and say that the continuation $\cont(σ)$ drives
evaluation.
Otherwise, $σ$ is an \emph{evaluation} state and $\ctrl(σ)$ drives evaluation.
The entries in the heap $μ$ are \emph{closures} of the form $(ρ,e)$, where the
environment $ρ$ closes over the expression $e$.
Finally, the $\cont(σ)$ lists actions to be taken in a return state, such as
applying the result to an argument address or updating a heap entry with its
value.

Heap entries are introduced via $\BindT$ transitions under a \emph{fresh} address
$\pa \not∈ \dom(μ)$ that we call an \emph{activation} of the let-bound variable
$\px$. The lexical activation of every variable in scope is maintained
in $ρ$. The $\AppIT$ rule pushes an \emph{application frame} with the address of
the argument variable onto the stack, while the rule $\LookupT$ pushes an
\emph{update frame} with the address of the variable the heap entry of which is
accessed. When a return state is reached, the original heap entry is overwritten
with the value in the control.

Let us conclude with an example trace in this transition system, evaluating
$\pe \triangleq \Let{i}{\Lam{x}{x}}{i~i}$ to completion:
\[\begin{array}{c}
  \arraycolsep2pt
  \begin{array}{clclclcl}
             & (\pe, [], [], \StopF)         & \smallstep & (i~i, ρ_1, μ, \StopF)
             & \smallstep & (i, ρ_1, μ, κ_1) & \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_2)
             \\
  \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_1)     & \smallstep & (x, ρ_2, μ, \StopF) & \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_3)
             & \smallstep & (\Lam{x}{x}, ρ_1, μ, \StopF) \\
  \end{array} \\
  \\[-0.5em]
  \quad \text{where} \quad \begin{array}{lll}
  ρ_1 = [i ↦ \pa_1] & ρ_2 = [i ↦ \pa_1, x ↦ \pa_1] & μ = [\pa_1 ↦ (ρ_1,\Lam{x}{x})] \\
  κ_1 = \ApplyF(\pa_1) \pushF \StopF & κ_2 = \UpdateF(\pa_1) \pushF κ_1 & κ_3 = \UpdateF(\pa_1) \pushF \StopF
  \end{array}
\end{array}\]

\subsection{Domain Theory}
\label{sec:domain-theory}

The challenge that domain theory sets out to solve is that the ``inductive
datatype''
\[
  D ::= \FunV(f ∈ D \to D) \mid \bot
\]
is ill-defined:
The usual interpretation of such a declaration as the least fixed-point of
the implied set-valued functional
$F(X) \triangleq \{ f \mid ∀a∈X.\ ∃b∈X.\ f(a) = b \} ∪ \{ \bot \}$
does not exist.

To see that, suppose $μF$ was that set.
Then there exists an injection (``data constructor'') $\FunV$ from $μF \to μF =
μF^{μF}$ into $μF$.
We can see that $\{\bot, (\fn{\wild}{\bot}) \} \subseteq μF$, so there are at
least two elements in $μF$.
Then to accomodate $μF^{μF}$, $μF$ must be at least as large as $2^{μF}$, the
set of two-valued functions on $μF$.
But this latter set is one-to-one with $\poset{μF}$ and it is a known result by
Cantor that the $\poset{μF}$ has greater cardinality than $μF$, in contradiction
to the existence of the injection $\FunV$.

Domain theory, on the other hand, interprets the implied recursion equation
in terms of topology and continuous functions, where the fixed-point exists
when restricted to \emph{algebraic domains}.
At the same time, algebraic domains are expressive enough to encode any
computable function as a continuous function.

\subsection{Guarded Domain Theory}

As we have discussed in \Cref{sec:continuity}, there are a few strings attached
to working with continuity and partiality in the context of denotational
semantics.

The key to getting rid of partiality and thus denoting infinite computations
with total elements is to avoid working with algebraic domains altogether and
instead work in a total type theory with \emph{guarded recursive types}, such
as Guarded Dependent Type Theory (GDTT)~\citep{gdtt} or Ticked Cubical Type
Theory~\citep{tctt}.%
\footnote{Of course, in reality we are just using GDTT as a meta
language~\citep{Moggi:07} with a known domain-theoretic model in terms
of the topos of trees~\citep{gdtt}.
This meta language is sufficiently expressive as a logic to
express proofs, though, justifying the view that we are extending ``math''
with the ability to conveniently reason about computable functions on infinite
data without needing to think about topology and approximation directly.}
The fundamental innovation of these theories is the integration of the
``later'' modality $\later$ which allows to define coinductive data types
with negative recursive occurrences such in our ``data type'' $D$ from
\Cref{sec:domain-theory}, as first realised by \citet{Nakano:00}.

GDTT walks a fine line:
The theory guarantees that all well-typed functions (naturally) correspond
to continuous functions in the underlying model, while it also allows for
embedding of a sufficiently expressive restriction to give meaning to $D$.

Whereas previous theories of coinduction require syntactic productivity
checks~\citep{Coquand:94}, requiring tiresome constraints on the form of guarded
recursive functions, the appeal of GDTT is that productivity is instead proven
semantically, in the type system.

The way that GDTT achieves this is roughly as follows: The type $\later T$
represents data of type $T$ that will become available after a finite amount
of computation, such as unrolling one layer of a fixpoint definition.
It comes with a general fixpoint combinator $\fix : \forall A.\ (\later A \to
A) \to A$ that can be used to define both coinductive \emph{types} (via guarded
recursive functions on the universe of types~\citep{BirkedalMogelbergEjlers:13})
as well as guarded recursive \emph{terms} inhabiting said types.
The classic example is that of coinductive streams:
\[
  Str = ℕ \times \later Str \qquad ones = \fix (r : \later Str).\ (1,r),
\]
where $ones : Str$ is the constant stream of $1$.
In particular, $Str$ is the fixpoint of a locally contractive functor $F(X) =
ℕ \times \later X$.
According to \citet{BirkedalMogelbergEjlers:13}, any type expression in simply
typed lambda calculus defines a locally contractive functor as long as any
occurrence of $X$ is under a $\later$, so we take that as the well-formedness
criterion of coinductive types in this work.
The most exciting consequence is that
$D ::= \FunV(f ∈ \later D \to D) \mid \bot$ (where $\bot$ is interpreted as a
plain nullary data constructor rather than as the least element of some partial
order) is a sound coinductive encoding of the data type in
\Cref{sec:domain-theory}.

As a type constructor, $\later$ is an applicative
functor~\citep{McBridePaterson:08} via functions
\[
  \purelater : \forall A.\ A \to \later A \qquad \wild \aplater \wild : \forall A,B.\ \later (A \to B) \to \later A \to \later B,
\]
allowing us to apply a familiar framework of reasoning around $\later$.
In order not to obscure our work with pointless symbol pushing
in, \eg, \Cref{fig:semvan}, we will often omit the idiom
brackets~\citep{McBridePaterson:08} $\idiom{\wild}$
to indicate where the $\later$ ``effects'' happen.
Rest assured, they are still there in the Guarded Cubical Agda development in
the Supplement.

\sg{The Guarded Cubical Agda prototype type-checks and is available at
\url{https://github.com/sgraf812/comp-trace/blob/main/agda}}

\begin{figure}
\[\begin{array}{c}
 \begin{array}{rrclclrrclcl}
 \end{array} \\
 \begin{array}{rrclclrrcrclcl}
  \text{Environment}  & ρ   & ∈ & \Environments  & =      & \Var \pfun \Addresses
  &
  \text{Heap}         & μ   & ∈ & \Heaps         & =      & \Addresses \pfun \later\VanD
  \\
  \\[-0.5em]
  \text{Trace} & τ      & ∈          & \VTraces & ::= & \goodend{v,μ} \mid \stuckend \mid \laterC~τ^{\later}
  &
  \multicolumn{3}{r}{\text{Delayed trace}} & τ^{\later} & ∈ & \later\VTraces &   &
  \\
  \text{Domain} & d & ∈ & \VanD & = & \Heaps \to \VTraces
  &
  \multicolumn{3}{r}{\text{Delayed element}} & d^{\later} & ∈ & \later\VanD &   &
  \\
  \\[-0.5em]
 \end{array} \\
 \begin{array}{rrclcl}
  \text{Value} & v & ∈ & \VanV & ::= & \FunV(f ∈ (\Addresses \to \VanD)) \mid \ConV(K,\many{\pa}^{α_K}) \\
 \end{array} \\
  \\[-0.5em]
\end{array}\]
\[\begin{array}{c}
 \begin{array}{rcl}
  \multicolumn{3}{c}{ \ruleform{
    \begin{array}{c}
      (\betastep) : \VanD \to (\VanV \pfun \VanD) \to \VanD \quad \ret : \VanV \to \VanD \quad \apply : \VanD \times \Addresses \to \VanD \\
      \memo : \Addresses \times \VanD \to \VanD \quad \select : \VanD \times ((K:\Con) \times \pa^{α_K} \pfun \VanD) \to \VanD \\
    \end{array}
  }} \\
  \\[-0.5em]
  (d \betastep f)(μ) & = & \begin{cases}
      \laterC^n~f(v,μ')  & \text{$d(μ) = \laterC^n~\goodend{v,μ'}$ and $(v,μ') ∈ \dom(f)$} \\
      \laterC^n~\stuckend  & \text{$d(μ) = \laterC^n~\goodend{v,μ'}$ and $(v,μ') \not∈ \dom(f)$} \\
      d(μ) & \text{otherwise} \\
    \end{cases} \\
  \\[-0.5em]
  \ret(v)(μ) & = & \goodend{v,μ} \\
  \apply(d,\pa) & = & d \betastep \fn{(\FunV(f))}{f(\pa)} \\
  \select(d,\alts) & = & d \betastep \fn{(\ConV(K_s,\many{\pa}))}{\alts(K_s, \many{\pa})} \quad \text{where } (K_s, \many{\pa}) ∈ \dom(\alts) \\
  \memo(\pa,d) & = & d \betastep \fn{v}{(\fn{μ}{\laterC~\goodend{v,μ[\pa ↦ \memo(\pa,\ret(v))]}})} \\
 \end{array} \\
 \\[-0.5em]
 \begin{array}{rcl}
  \multicolumn{3}{c}{ \ruleform{ \semvan{\wild} \colon \Exp → (\Var \pfun \Addresses) → \VanD } } \\
  \\[-0.5em]
  \semvan{\px}_ρ & = & \begin{cases}
    \laterC~μ(ρ(\px))(μ) & \px ∈ \dom(ρ) \\
    \stuckend & \text{otherwise}
    \end{cases} \\
  \\[-0.5em]
  \semvan{\Lam{\px}{\pe}}_ρ & = & \ret(\FunV(\fn{\pa}{\laterC~\semvan{\pe}_{ρ[\px↦\pa]}})) \\
  \\[-0.5em]
  \semvan{\pe~\px}_ρ(μ) & = & \begin{cases}
      \laterC~\apply(\semvan{\pe}_ρ(μ),\pa) & \px ∈ \dom(ρ) \\
      \stuckend & \text{otherwise} \\
    \end{cases} \\
  \\[-0.5em]
  \semvan{\Let{\px}{\pe_1}{\pe_2}}_ρ(μ) & = & \begin{letarray}
    \text{let} & ρ' = ρ[\px↦\pa] \quad \text{where $\pa \not∈ \dom(μ)$} \\
    \text{in}  & \laterC~\semvan{\pe_2}_{ρ'}(μ[\pa ↦ \memo(\pa,\semvan{\pe_1}_{ρ'})]) \\
  \end{letarray} \\
  \\[-0.5em]
  \semvan{K~\many{\px}}_ρ & = & \ret(\ConV(K,\many{ρ(\px)})) \\
  \\[-0.5em]
  \semvan{\Case{\pe_s}{\Sel[r]}}_ρ(μ) & = &
    \begin{letarray}
      \text{let} & \alts = \fn{(K_i,\many{\pa})}{\laterC~\semevt{\pe_{r_i}}_{ρ[\many{\px_i↦\pa}]}} \\
      \text{in} & \laterC~\select(\semevt{\pe_s}_ρ, \alts)  \\
    \end{letarray}
 \end{array}
  \\[-0.5em]
\end{array}\]
\caption{Call-by-need Denotational Semantics $\semvan{-}$}
  \label{fig:semvan}
\end{figure}

\subsection{Definition}

\Cref{fig:semvan} finally gives the definition for $\semvan{\wild}$, a function
defined by structural recursion on an input expression $\pe$. Given a free
variable environment $ρ$, $\semvan{\pe}_ρ$ assigns $\pe$ a denotation $d$ in
terms of the semantic domain $\VanD$ of stateful call-by-need trace functions.
If such a trace function is supplied the heap $μ$ just before $\pe$ takes
control, then $d(μ)$ is a trace $τ$ starting at $\pe$ in that heap $μ$.
As with $(\smallstep)$, the job of the environment $ρ$ is to assign meaning to
free variables of $\pe$ via address tokens $\pa$ bound in the heap.
If evaluation of $\pe$ terminates, then $τ$ will be a finite list of $\laterC$
wrappers ending with $\goodend{v,μ'}$ for some return semantic value $v$ and
heap $μ'$.
Otherwise, it might be finite but stuck ($\stuckend$), or diverge without
ever leaving $\pe$, in which case $τ$ will be an infinite layering of $\laterC$s.

One can think of $\laterC$ (read as ``later'' or ``delayed'') as introducing
a finite portion of latency into the trace -- an atomic computation step of a
trace.
It makes crucial use of $\later$ to achieve that and naturally encode divergence
in a infinite sequence of productive steps.

Compared to the LK transition semantics, the most striking difference is that
the returned trace does not contain any intermediate information such as an
environment or control stack component.
The entire state is internal to the definition of $\semvan{\wild}$:
The stack in particular is implicitly encoded in call structure while the
environment follows lexical structure.
As we have seen in \Cref{sec:problem} at the example of $\semscott{\wild}$,
this reflection of machine state into ``math'' bears great potential for program
analysis, one we will exploit in \Cref{sec:abstractions}.
We will see that for every LK transition, the trace will have one $\laterC$
step.

The second difference is that the heap $μ$ does not map to syntactic closures
but to delayed semantic values $\later \VanD$, offering further abstraction
possibilities compared to the rigid and indirect syntactic domain.

The choice to have environments map to addresses naturally leads to function
values $\FunV(f)$ that take said addresses as parameter rather than a
(necessarily guarded) $\VanD$ as in $\semscott{\wild}$.%
\footnote{An earlier version of this paper had
$\Environments = \Var \pfun \VanD$ instead, where every entry would simply look
up a particular address in the heap.
Though it felt more ``semantic'', it was ultimately more taxing than useful,
because many later proofs will have to pose additional preconditions on $ρ$.}
Crucially, this allows the embedding of function values $\FunV(f)$ in the
lambda case $\semvan{\Lam{\px}{\pe}}$, enabling a compositional definition of the
application case $\semvan{\pe~\px}$, just as in $\semscott{\wild}$.

It is worth noting that without guarded recursive types, the definition of
$\VanD$ would not be well-founded because of the negative cycle arising through
$\VanD \to \Heaps \to \VanD$ (\cf \Cref{sec:domain-theory}).
Interpreted as a traditional algebraic domain, we would now have to do a lot of
complicated justification.
However, the valiant use of a guarded recursive type $\later \VanD$ in the
definition of heaps breaks that cycle, thus the definition is well-founded.

All definitions of semantics in this work have been type-checked using Guarded
Cubical Agda and are available in the Supplement.
Hence we leave out the necessary $\purelater$, $\aplater$ and $\idiom{\wild}$
combinators in the presentation to avoid distraction from the payload.

Let us now understand $\semvan{\wild}$ by way of evaluating the example program
from earlier, $\pe \triangleq \Let{i}{\Lam{x}{x}}{i~i}$:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[mymatrixenv,anchor=center]
      \matrix [mymatrix] (m)
      {
        1 & \laterC & \hspace{3.7em} & \hspace{4.2em} & \hspace{3.9em} & \hspace{2.5em} \\
        2 & \laterC & & & & \\
        3 & \laterC & & & & \\
        4 & \laterC & & & & \\
        5 & \laterC & & & & \\
        6 & \laterC & & & & \\
        7 & \laterC & & & & \\
        8 & \goodend{\FunV(f), μ} & & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{8}{$\semvan{\pe}_{[]}$}
      \myleftbrace{4}{1}{2}{$\BindT$}
      \myleftbrace{4}{2}{8}{$\semvan{i~i}_{ρ_1}$}
      \myleftbrace{5}{2}{3}{$\AppIT$}
      \myleftbrace{5}{3}{5}{$\semvan{i}_{ρ_1}$}
      \myleftbrace{5}{5}{6}{$\AppET$}
      \myleftbrace{5}{6}{8}{$\semvan{x}_{ρ_2}$}
      \myleftbrace{6}{3}{4}{$\LookupT$}
      \myleftbrace{6}{4}{5}{$\UpdateT$}
      \myleftbrace{6}{6}{7}{$\LookupT$}
      \myleftbrace{6}{7}{8}{$\UpdateT$}
  \end{tikzpicture}
  $}} &
  \!\!\!\!\text{where}  \begin{array}{ll}
  ρ_1 = [i ↦ \pa_1] & \\
  ρ_2 = ρ_1[x ↦ \pa_1] &  \\
  μ = [\pa_1 ↦ \memo(\pa_1,\semvan{\Lam{x}{x}}_{ρ_1})] & \\
  f = \pa \mapsto \semvan{\px}_{ρ_1[\px↦\pa]}
  \end{array}
\end{array}\]
The annotations to the right of the trace can be understood as denoting the
``call graph'' of $\semvan{\pe}_{[]}$, with the corresponding LK transitions
as leaves.
Evaluation begins at timestamp 1 with a $\BindT$ transition to timestamp 2,
which $\semvan{\pe}_{[]}$ acknowledges by emitting a $\laterC$.
A fresh address $\pa_1$ is allocated for variable $i$ and the heap is extended
with $\memo(\pa,\semvan{\Lam{x}{x}}_{ρ_1})$.
It is interesting to realise that this process does not involve a fixpoint
despite the recursive semantics of $\mathbf{let}$.
Of course, the self-application in $\semvan{\px}$ does the job just as well, as
we will see in due course.

Evaluation recurses into the body $\semvan{i~i}_{ρ_1}$, yielding another
$\AppIT$ transition (corresponding to a bland $\laterC$) into $\semvan{i}_{ρ_1}$.
Note that the target state $\semvan{i}_{ρ_1}$ will later be fed (via
$\betastep$) into the anonymous function in $\apply$.
This scheme is quite common: Continuation items of the transition semantics
(``data'') are reflected into the call stack of the trace semantics (``code'').
The reverse process an be recognised as defunctionalisation~\citep{Reynolds:72}.

$\semvan{i}_{ρ_1}$ guides the trace through a heap lookup:
After emitting a $\laterC$ corresponding to the $\LookupT$ transition,
$μ$ is dereferenced at $ρ(i)$ where we find $\memo(\pa,\semvan{\Lam{x}{x}}_{ρ_1})$.
This heap entry is ``self-applied'' to $μ$, effectively ``tying the knot''.
The memoisation action will run $\semvan{\Lam{x}{x}}_{ρ_1}$ to completeness
through $(\betastep)$ on heap $μ$ at timestamp 4.
Since that is already a value, $(\betastep)$ calls its second argument with
$\goodend{\FunV(f),μ}$ and we witness for the first time a reduction operation,
making an $\UpdateT$ transition to update $μ(\pa)$.
Note that this update has no effect on the heap $μ$ because
$\ret(\FunV(f))$ is precisely the same as $\semvan{\Lam{x}{x}}_{ρ_1}$.

After the heap update, we leave $\semvan{i}$ in timestamp 5,
where $\betastep$ yields to the anonymous function in $\apply$ (from the earlier
call to $\semvan{i~i}_{ρ_1}$), yielding another $\AppET$ reduction and giving
control to $f(ρ_1(i)) = \semvan{x}_{ρ_1[x ↦ ρ_1(i)]}$.
Since $x$ is an alias for $i$, steps 6 to 8 just repeat the same same heap
update sequence we observed in steps 3 to 5, concluding the example.

It is useful to review another example involving an observable heap
update. The following trace begins right before the heap update occurs in
$\Let{i}{(\Lam{y}{\Lam{x}{x}})~i}{i~i}$, that is, after reaching the value
in $\semvan{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1}$.
We will indicate the heap before a transition takes place by
writing it before $\laterC$:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[baseline={-0.5ex},mymatrixenv]
      \matrix [mymatrix] (m)
      {
        1 & (μ_1)~\laterC & \hspace{4em} & \hspace{4em} & \hspace{2.5em} \\
        2 & (μ_2)~\laterC & & & \\
        3 & (μ_2)~\laterC & & & \\
        4 & (μ_2)~\laterC & & & \\
        5 & \goodend{\FunV(f), μ_2} & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{5}{$\semvan{i~i}_{ρ_1}$}
      \myleftbrace{4}{1}{2}{$\semvan{i}_{ρ_1}$}
      \myleftbrace{4}{2}{3}{$\AppET$}
      \myleftbrace{4}{3}{5}{$\semvan{x}_{ρ_3}$}
      \myleftbrace{5}{1}{2}{$\UpdateT$}
      \myleftbrace{5}{3}{4}{$\LookupT$}
      \myleftbrace{5}{4}{5}{$\UpdateT$}
    \end{tikzpicture}
  $}} &
  \!\!\!\text{where} \begin{array}{l}
  ρ_1 = [i ↦ \pa_1] \\
  ρ_2 = [i ↦ \pa_1, y ↦ \pa_1] \\
  ρ_3 = [i ↦ \pa_1, y ↦ \pa_1, x ↦ \pa_1] \\
  μ_1 = [\pa_1 ↦ \memo(\pa_1,\semvan{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1})] \\
  μ_2 = [\pa_1 ↦ \memo(\pa_1,\semvan{\Lam{x}{x}}_{ρ_2})] \\
  f = \fn{d}{\semvan{\px}_{ρ_2[\px↦d]}} \\
  \end{array} \\
\end{array}\]
Note that both the denotation in the heap $μ_1$ \emph{and} its environment are updated
in timestamp 2, and that the new denotation is immediately visible on the next heap
lookup in timestamp 3, so that $\semvan{\Lam{x}{x}}_{ρ_2}$ takes control rather than
$\semvan{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1}$, just as the transition system requires.

The handling of data types and case expressions is routine (if a bit
syntactically heavy) and not so different to denotational semantics in
call-by-name or call-by-value.
It is a useful inclusion because it allows us to observe type errors other than
scoping errors, as well as enable more interesting examples.
Let us consider evaluation of the closed expression
$\pe \triangleq \Let{x}{\ttrue}{\ttrue~x}$
(where $\ttrue$ is one of two nullary data constructors of the data type $\bool
::= \ttrue \mid \ffalse$).
$\semvan{\wild}$ makes it is easy to observe that the trace gets stuck:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[baseline={-0.5ex},mymatrixenv]
      \matrix [mymatrix] (m)
      {
        1 & (\pe, []) \cons {} & \hspace{4em} & \hspace{5em} & \hspace{2.5em} \\
        2 & (\ttrue~x, μ) \cons {} & & & \\
        3 & \stuckend & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{3}{$\semvan{\pe}_{[]}$}
      \myleftbrace{4}{1}{2}{$\BindT$}
      \myleftbrace{4}{2}{3}{$\semvan{\ttrue~x}_{ρ}$}
      \myleftbrace{5}{2}{3}{$\AppIT$}
    \end{tikzpicture}
  $}} &
  \!\!\!\text{where} \begin{array}{l}
  ρ = [x ↦ \pa_1] \\
  μ = [\pa_1 ↦ \semvan{\ttrue}_ρ] \\
  \end{array} \\
\end{array}\]
Crucially, $\betastep$ is equipped to propagate $\stuckend$ up the call
stack (through potential $\UpdateT$ transitions, in particular), similar to
\citeauthor{Milner:78}'s $\mathbf{wrong}$.

Diverging traces hold no new surprises, other than they are observably different
to stuck traces.

\subsection{Maximal LK Traces}
\label{sec:maximal-traces}

It turns out that the traces $\semvan{\pe}$ generates correspond to
\emph{maximal} traces in the LK transition system.
Let us make precise what that means.

A transition system is characterised by the set of \emph{traces} it generates.
An \emph{LK trace} is a trace in $(\smallstep)$, \eg, a non-empty and
potentially infinite sequence of LK states $(σ_i)_{i∈\overline{n}}$
(where $\overline{n} = \{ m ∈ ℕ_+ \mid m ≤ n \}$ when $n∈ℕ$, $\overline{ω} = ℕ$),
such that $σ_i \smallstep σ_{i+1}$ for $i,(i+1)∈\overline{n}$.

The \emph{source} state $σ_0$ exists for finite and infinite traces, while the
\emph{target} state $σ_n$ is only defined when $n \not= ω$ is finite.

For proofs, we will often regard $(σ_i)_{i∈\overline{n}}$ as an object of type
$\STraces \triangleq ∃n∈ℕ_ω.\ \overline{n} \to \States$, where $ℕ_ω$ is defined by guarded recursion
as $ℕ_ω = \{\mathit{Z}\} + \later ℕ_ω$.
The constructor for the right sum alternative is written $\mathit{succ}$.
Now $ℕ_ω$ contains all natural numbers (where $n$ is encoded as
$(\mathit{succ})^{n}(\mathit{Z})$) and the transfinite limit ordinal
$ω = \mathit{succ}(\mathit{succ}(...))$.
We will write $1+m$ to denote $\mathit{succ}(m)$ (a different kind of $+$ than
in the recursive equation for $ℕ_ω$), just as we are used to from $ℕ$.
Hence, when $(σ_i)_{i∈\overline{n}} ∈ \STraces$ is an LK trace and $n > 0$, then
$(σ_{i+1})_{i∈\overline{n-1}} ∈ \later \STraces$ is the guarded tail of the
trace with an associated induction principle.

An important kind of trace is one that never leaves the evaluation context of
its source state:

\begin{definition}[Deep, interior and balanced traces]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is
  \emph{$κ$-deep} if every intermediate continuation
  $κ_i = \cont(σ_i)$ extends $κ$ (so $κ_i = κ$ or $κ_i = ... \pushF κ$,
  abbreviated $κ_i = ...κ$).

  A trace $(σ_i)_{i∈\overline{n}}$ is called \emph{interior} if it is
  $\cont(σ_0)$-deep.
  Furthermore, an interior trace $(σ_i)_{i∈\overline{n}}$ is
  \emph{balanced}~\citep{Sestoft:97} if the target state exists and is a return
  state with continuation $κ_1$.

  We notate $κ$-deep, interior and balanced traces as
  $\deep{κ}{(σ_i)_{i∈\overline{n}}}$, $\interior{(σ_i)_{i∈\overline{n}}}$ and
  $\balanced{(σ_i)_{i∈\overline{n}}}$, respectively.
\end{definition}

\begin{example}
  Let $ρ=[x↦\pa_1],μ=[\pa_1↦([], \Lam{y}{y})]$ and $κ$ an arbitrary
  continuation. The trace
  \[
     (x, ρ, μ, κ) \smallstep (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, κ)
  \]
  is interior and balanced. Its prefixes are interior but not balanced.
  The trace suffix
  \[
     (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, κ)
  \]
  is neither interior nor balanced.
\end{example}

We will say that the transition rules $\LookupT$, $\AppIT$, $\CaseIT$ and $\BindT$
are interior, because the lifting into a trace is, whereas the returning
transitions $\UpdateT$, $\AppET$ and $\CaseET$ are not.

A balanced trace starting at a focus expression $\pe$ and ending with $\pv$
loosely corresponds to a derivation of $\pe \Downarrow \pv$ in a natural
big-step semantics~\citep{Sestoft:97} or a non-$⊥$ result in a denotational
semantics.

It is when a derivation in a natural semantics does not exist that a small-step
semantics shows finesse, in that it differentiates two different kinds of
\emph{maximally interior} (or, just \emph{maximal}) traces:

\begin{definition}[Maximal trace]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is \emph{maximal} if and only if it is
  interior and there is no $σ_{n+1}$ such that $(σ_i)_{i∈\overline{n+1}}$ is
  interior.
  More formally (and without a negative occurrence of ``interior''),
  \[
    \maxtrace{(σ_i)_{i∈\overline{n}}} \triangleq \interior{(σ_i)_{i∈\overline{n}}} \wedge (\not\exists σ_{n+1}.\ σ_n \smallstep σ_{n+1} \wedge \cont(σ_{n+1}) = ...\cont(σ_0))
  \]
  We notate maximal traces as $\maxtrace{(σ_i)_{i∈\overline{n}}}$.
\end{definition}

We call infinite and interior traces \emph{diverging}.
A maximally finite, but unbalanced trace is called \emph{stuck}.
Note that usually stuckness is associated with a state of a transition
system rather than a trace.
That is not possible in our framework; the following example clarifies.

\begin{example}[Stuck and diverging traces]
Consider the interior trace
\[
             (\ttrue~x, [x↦\pa_1], [\pa_1↦...], κ)
  \smallstep (\ttrue, [x↦\pa_1], [\pa_1↦...], \ApplyF(\pa_1) \pushF κ)
\]
It is stuck, but its singleton suffix is balanced.
An example for a diverging trace where $ρ=[x↦\pa_1]$ and $μ=[\pa_1↦(ρ,x)]$ is
\[
  (\Let{x}{x}{x}, [], [], κ) \smallstep (x, ρ, μ, κ) \smallstep (x, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep ...
\]
\end{example}

A maximal trace that is not balanced either diverges or is stuck:

\begin{lemma}[Characterisation of maximal traces]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is maximal if and only if it is balanced,
  diverging or stuck.
\end{lemma}
\begin{proof}
  $\Rightarrow$: Let $(σ_i)_{i∈\overline{n}}$ be maximal.
  If $n=ω$ is infinite, then it is diverging due to interiority, and if
  $(σ_i)_{i∈\overline{n}}$ is stuck, the goal follows immediately.
  So we assume that $(σ_i)_{i∈\overline{n}}$ is maximal, finite and not stuck,
  so it must be balanced by the definition of stuckness.

  $\Leftarrow$: Both balanced and stuck traces are maximal.
  A diverging trace $(σ_i)_{i∈\overline{n}}$ is interior and infinite,
  hence $n=ω$.
  Indeed $(σ_i)_{i∈\overline{ω}}$ is maximal, because the expression $σ_ω$
  is undefined and hence does not exist.
\end{proof}

Interiority guarantees that the particular initial stack $κ$ of a maximal trace
is irrelevant to execution, so maximal traces that differ only in the initial
stack are bisimilar.

One class of maximal traces is of particular interest:
The maximal trace starting in $\inj(\pe)$!
Whether it is inifinite, stuck or balanced is the defining operational
characteristic of $\pe$.
If we can show that $\semvan{\pe}$ distinguishes these behaviors of $\pe$, we
have proven it an adequate replacement for the LK transition system.

\subsection{Adequacy}

\Cref{fig:semvan-correctness} shows the correctness predicate $\mathcal{C}$ in
our endeavour to prove $\semvan{\wild}$ adequate.
It builds on the framework of maximal LK traces established in the last section;
specifically it encodes that an \emph{abstraction} of every maximal LK trace can be
recovered by running $\semvan{\wild}$ starting from the abstraction of an initial
state.

\begin{figure}
\[\begin{array}{rcl}
  α_\Heaps([\many{\pa ↦ (ρ,\pe)}]) & = & [\many{\pa ↦ \memo(\pa,\semvan{\pe}_{ρ})}] \\
  α_\VanV(\Lam{\px}{\pe},ρ,μ,κ) & = & \goodend{\FunV(\fn{\pa}{\laterC~\semvan{\pe}_{ρ[\px↦\pa]}}),α_\Heaps(μ)} \\
  α_\VanV(K~\overline{\px},ρ,μ,κ) & = & \goodend{\ConV(K,\overline{ρ(\pa)}),α_\Heaps(μ)} \\
  α_{\STraces}((σ_i)_{i∈\overline{n}},κ) & = & \begin{cases}
    \laterC~\idiom{α_{\STraces}((σ_{i+1})_{i∈\overline{n-1}},κ)} & n > 0 \\
    α_\VanV(σ_0) & \ctrl(σ_0) \text{ value } \wedge \cont(σ_0) = κ \\
    \stuckend & \text{otherwise} \\
  \end{cases} \\
  \mathcal{C}((σ_i)_{i∈\overline{n}}) & = & \maxtrace{(σ_i)_{i∈\overline{n}}} \Longrightarrow ∀((\pe,ρ,μ,κ) = σ_0).\ α_{\STraces}((σ_i)_{i∈\overline{n}},κ) = \semvan{\pe}_{ρ}(α_\Heaps(μ)) \\
\end{array}\]
\caption{Correctness predicate for $\semvan{\wild}$}
  \label{fig:semvan-correctness}
\end{figure}

The family of abstraction functions makes precise the intuitive connection
between the semantic objects in $\semvan{\wild}$ and the syntactic objects in
the transition system.

We will sometimes need to disambiguate the clashing definitions from
\Cref{sec:stateful} and \Cref{sec:problem}.
We do so by adorning semantic objects with a tilde, so $\tm \triangleq
α_\Heaps(μ)$ denotes a semantic heap which in this instance is
defined to be the abstraction of a syntactic heap $μ$.

Note first that $α_\STraces$ is defined by guarded recursion over
the LK trace, in the sense defined in \Cref{sec:maximal-traces}.
As such, the expression $\idiom{α_{\STraces}((σ_{i+1})_{i∈\overline{n-1}},κ)}$ has type
$\later \VTraces$ (the $\later$ in the type of $(σ_{i+1})_{i∈\overline{n-1}}$
maps through $α_\STraces$ via the idiom brackets).
Likewise, $=$ on $\VTraces$ is defined in the obvious structural way by guarded
recursion (as it would be if it was a finite, inductive type).

Our first goal is to establish a few auxiliary lemmas showing what kind of
properties of LK traces are preserved by $α_\STraces$ and in which way.

Let us warm up by defining a length function on traces:
\begin{definition}[Length of a trace]
  \label{defn:length}
  The \emph{length} $\len : \VTraces \to ℕ_ω$ of a trace is defined by
  guarded recursion
  \[
    \len(τ) = \begin{cases}
      1 + \purelater \len \aplater τ^{\later} & τ = \laterC~τ^{\later} \\
      0 & \text{otherwise} \\
    \end{cases}
  \]
\end{definition}

\begin{lemma}[Preservation of length]
  \label{thm:abs-length}
  Let $(σ_i)_{i∈\overline{n}}$ be an arbitrary trace.
  Then $\len(α_\STraces((σ_i)_{i∈\overline{n}},\cont(σ_0))) = n$.
\end{lemma}
\begin{proof}
  This is quite simple to see and hence a good opportunity to familiarise
  ourselves with the concept of \emph{Löb induction}, the induction principle of
  guarded recursion.
  Löb induction arises simply from applying the guarded recursive fixpoint
  combinator to a proposition:
  \[
    \textsf{löb} = \fix : \forall P.\ (\later P \Longrightarrow P) \Longrightarrow P
  \]
  That is, we assume that our proposition holds \emph{later}, \eg
  \[
    IH ∈ (\later P \triangleq \later (
        \forall n ∈ ℕ_ω.\
        \forall (σ_i)_{i∈\overline{n}}.\
        \len(α_\STraces((σ_i)_{i∈\overline{n}},\cont(σ_0))) = n
      ))
  \]
  and use $IH$ to prove $P$.
  Let us assume $n$ and $(σ_i)_{i∈\overline{n}}$ are given, define
  $τ \triangleq α_\STraces((σ_i)_{i∈\overline{n}},\cont(σ_0))$ and proceed by case analysis
  over $n$:
  \begin{itemize}
    \item \textbf{Case $n=0$}: Then we have $j = 0$ and either $τ = \goodend{α_\States(σ_0)}$
      or $τ = \stuckend$, both of which map to $0$ under
      $\len$.
    \item \textbf{Case $n>0$}: Then $n = 1+m$ and $m ∈ \later ℕ_ω$ and the
      first case of $α_\States$ applies, hence $τ = σ \cons τ^{\later}$ for some
      $σ∈\States, τ^{\later}∈\later \VTraces$.
      Now we apply the inductive hypothesis, as follows:
      Let $(σ_{i+1})_{i∈\overline{m}} ∈ \later \STraces$ be the guarded
      tail of the LK trace $(σ_i)_{i∈\overline{n}}$.
      Then we can apply $IH \aplater m \aplater (σ_{i+1})_{i∈\overline{m}}$ and
      get a proof for $\later (\len(τ^{\later}) = m)$.
      Now we can prove
      \[
        n = 1 + m = 1 + \len(τ^{\later}) = \len(τ).
      \]
  \end{itemize}
\end{proof}

\begin{lemma}[Preservation of characteristic]
  \label{thm:abs-max-trace}
  Let $(σ_i)_{i∈\overline{n}}$ be a maximal trace.
  Then $α_\STraces((σ_i)_{i∈\overline{n}}, cont(σ_0))$ is ...
  \begin{itemize}
    \item ... infinite if and only if $(σ_i)_{i∈\overline{n}}$ is diverging
    \item ... ending with $\goodend{\wild,\wild}$ if and only if $(σ_i)_{i∈\overline{n}}$ is balanced
    \item ... ending with $\stuckend$ if and only if $(σ_i)_{i∈\overline{n}}$ is stuck
  \end{itemize}
\end{lemma}
\begin{proof}
  The first point follows by a similar inductive argument as in \Cref{thm:abs-length}.

  In the other cases, we may assume that $n$ is finite.
  If $(σ_i)_{i∈\overline{n}}$ is balanced, then $σ_n$ is a return state with
  continuation $\cont(σ_0)$, so its control expression is a value.
  Then $α_\STraces$ will conclude with $\goodend{\wild,\wild}$.
  Conversely, if the trace ended with $\goodend{\wild,\wild}$, then $\cont(σ_n) = \cont(σ_0)$
  and $\ctrl(σ_n)$ is a value, so $(σ_i)_{i∈\overline{n}}$ forms a
  balanced trace.
  The stuck case is similar.
\end{proof}

The previous lemma is interesting as it allows us to apply the classifying
terminology of interior traces to a $τ$ that is an abstraction of a
\emph{maximal} LK trace.
For such a maximal $τ$ we will say that it is balanced when it ends with
$\goodend{\wild,\wild}$, stuck if ending in $\stuckend$ and diverging if
infinite.

With increased clarity, we go on to prove the correctness predicate:

\begin{theorem}[Correctness of $\semvan{\wild}$]
  \label{thm:semvan-correct}
  $\mathcal{C}$ from \Cref{fig:semvan-correctness} holds.
  That is, whenever $(σ_i)_{i∈\overline{n}}$ is a maximal LK trace with source
  state $(\pe,ρ,μ,κ)$, we have
  $α_{\STraces}((σ_i)_{i∈\overline{n}},κ) = \semvan{\pe}_{ρ}(α_\Heaps(μ))$.
\end{theorem}
\begin{proof}
By Löb induction, with $IH ∈ \later C$ as the hypothesis.

We will say that an LK state $σ$ is stuck if there is no applicable rule in the
transition system (\ie, the singleton LK trace $σ$ is maximal and stuck).

Now let $(σ_i)_{i∈\overline{n}}$ be a maximal LK trace with source state
$σ_0=(\pe,ρ,μ,κ)$ and let $τ = \semvan{\pe}_{α_\Environments(ρ)}(α_\Heaps(μ))$.
Then the goal is to show $α_{\STraces}((σ_i)_{i∈\overline{n}},κ) = τ$.
We do so by cases over $\pe$, abbreviating $\tm \triangleq α_\Heaps(μ)$:
\begin{itemize}
  \item \textbf{Case $\px$}:
    Let us assume first that $σ_0$ is stuck. Then $\px \not∈ \dom(ρ)$ (because
    $\LookupT$ is the only transition that could apply), so
    $τ = \stuckend$ and the goal follows from
    \Cref{thm:abs-max-trace}.

    Otherwise, $σ_1 \triangleq (\pe', ρ', μ, \UpdateF(\pa) \pushF κ), σ_0 \smallstep σ_1$
    via $\LookupT$, and $ρ(\px) = \pa, μ(\pa) = (ρ', \pe')$.
    To show that the tails equate, it suffices to show that they equate \emph{later}.

    We can infer that $\tm(\pa) = \memo(\pa,\semvan{\pe'}_{ρ'})$ from the
    definition of $α_\Heaps$, so
    \[
      \tm(ρ(\px))(\tm) = (\semvan{\pe'}_{ρ'} \betastep \fn{v}{(\fn{μ}{\laterC~\goodend{v,μ[\pa ↦ \memo(\pa,\ret(v))]}})})(\tm)
    \]

    Let us define $τ^\later \triangleq \idiom{\semvan{\pe'}_{ρ'}(\tm)}$ and
    apply the induction hypothesis $IH$ to the maximal trace starting at $σ_1$.
    This yields an equality
    \[
      IH \aplater (σ_{i+1})_{i∈\overline{m}} ∈ \idiom{α_\STraces((σ_{i+1})_{i∈\overline{m}},\UpdateF(\pa) \pushF κ) = τ^{\later}}
    \]
    When $τ^{\later}$ is infinite, we are done. Similarly, if $τ^{\later}$ ends
    in $\stuckend$ then $(\betastep)$ will return $τ^{\later}$, indicating
    by \Cref{thm:abs-length} and \Cref{thm:abs-max-trace} that
    $(σ_{i+1})_{i∈\overline{n-1}}$ is stuck and hence $(σ_i)_{i∈\overline{n}}$
    is, too.

    Otherwise $τ^{\later}$ ends after $m-1$ $\laterC$s with $\goodend{v,\tm_m}$ and
    by \Cref{thm:abs-max-trace} $(σ_{i+1})_{i∈\overline{m}}$ is balanced; hence
    $\cont(σ_m) = \UpdateF(\pa) \pushF κ$ and $\ctrl(σ_m)$ is a value.
    So $σ_m = (\pv,ρ_m,μ_m,\UpdateF(\pa) \pushF κ)$ and the
    $\UpdateT$ transition fires, reaching $(\pv,ρ_m,μ_m[\pa ↦ (ρ_m, \pv)],κ)$
    and this must be the target state $σ_n$ (so $m = n-2$), because it remains
    a return state and has continuation $κ$, so $(σ_i)_{i∈\overline{n}}$ is
    balanced.
    Likewise, by the second argument of $(\betastep)$, we call do another
    memoisation step on $\goodend{v,\tr_m}$, updating the heap to
    \[
      \goodend{v,\tm_m[\pa↦\memo(\pa,\ret(v))]} = \goodend{v,\tm_m[\pa↦\memo(\pa,\semvan{\pv}_{ρ_m})]} = α_\VanV(σ_n),
    \]
    and this equality concludes the proof.

  \item \textbf{Case $\pe~\px$}:
    The cases where $τ$ gets stuck or diverges before finishing evaluation of
    $\pe$ are similar to the variable case.

    So let us focus on the situation when $τ^{\later} \triangleq
    \idiom{\semvan{\pe}_{ρ}(\tm)}$ returns and let $σ_m$ be LK state at the
    end of the finite maximal trace $(σ_{i+1})_{i∈\overline{m-1}}$ through $\pe$
    starting in stack $\ApplyF(\pa) \pushF κ$.
    Since it is maximal, any transition $σ_m \smallstep σ_{m+1}$ must leave
    the stack $\ApplyF(\pa) \pushF κ$, necessarily by an $\AppET$ transition.
    That in turn means that the value in $\ctrl(σ_m)$ must be a lambda
    $\Lam{\py}{\pe'}$, hence $τ^{\later}$ ends in $\goodend{\FunV(\fn{\pa}{\idiom{\semvan{\pe'}_{ρ_m[\py ↦ \pa]}}}), \tm_m} = σ_\VanV(σ_m)$
    (where $\tm_m$ corresponds to the heap in $σ_m$ in the usual way).

    Now let $(σ_{i+m+1})_{i∈\overline{k}}$ be the maximal trace starting at
    $σ_{m+1}=(\pe',ρ_m[\py↦\pa], μ_m,κ)$.
    We can apply the induction hypothesis to this LK trace and
    $τ_2^{\later} \triangleq \idiom{\semvan{\pe'}_{ρ_m[\py↦\pa]}(\tm_m)}$
    to get the equality
    $\idiom{α_\STraces((σ_{i+m+1})_{i∈\overline{k}},κ) = τ_2^{\later}}$.
    From this and our earlier equalities, we get
    $α_\STraces((σ_i)_{i∈\overline{n}},κ) = τ$, concluding the proof.

  \item \textbf{Case $\Case{\pe_s}{\Sel[r]}$}:
    Similar to the application and lookup case.

  \item \textbf{Cases $\Lam{\px}{\pe}$, $K~\many{\px}$}:
    The length of both traces is $n = 0$ and the goal follows by simple calculation.

  \item \textbf{Case $\Let{\px}{\pe_1}{\pe_2}$}:
    Let $σ_0 = (\Let{\px}{\pe_1}{\pe_2},ρ,μ,κ)$.
    Then $σ_1 = (\pe_2, ρ', μ',κ)$ by $\BindT$, where $ρ' = ρ[\px↦\pa], μ'
    = μ[\pa↦(ρ',\pe_1)]$.
    Since the stack does not grow, maximality from the tail $(σ_{i+1})_{i∈\overline{n-1}}$
    transfers to $(σ_{i})_{i∈\overline{n}}$.
    Straightforward application of the induction hypothesis to
    $(σ_{i+1})_{i∈\overline{n-1}}$ yields the equality for the tail (after a bit
    of calculation for the updated environment and heap), which concludes the
    proof.
\end{itemize}
\end{proof}

\Cref{thm:semvan-correct} and \Cref{thm:abs-max-trace} are the key to proving a
strong version of adequacy for $\semvan{\wild}$, where $σ$ is defined to be a
\emph{final} state if $\ctrl(σ)$ is a value and $\cont(σ) = \StopF$.

\begin{theorem}[Adequacy of $\semvan{\wild}$]
  \label{thm:semvan-adequate}
  Let $τ = \semvan{\pe}_{[]}([])$.
  \begin{itemize}
    \item
      $τ$ ends with $\goodend{\wild,\wild}$ (is balanced) iff there exists a final
      state $σ$ such that $\inj(\pe) \smallstep^* σ$.
    \item
      $τ$ ends with $\stuckend$ (is stuck) iff there exists a non-final
      state $σ$ such that $\inj(\pe) \smallstep^* σ$ and there exists no $σ'$
      such that $σ \smallstep σ'$.
    \item
      $τ$ is infinite (is diverging) iff for all $σ$ with $\inj(\pe)
      \smallstep^* σ$ there exists $σ'$ with $σ \smallstep σ'$.
  \end{itemize}
\end{theorem}
\begin{proof}
  There exists a maximal trace $(σ_i)_{i∈\overline{n}}$ starting
  from $σ_0 = \inj(\pe)$, and by \Cref{thm:semvan-correct} we have
  $α_\STraces((σ_i)_{i∈\overline{n}},\StopF) = τ$.
  \begin{itemize}
    \item[$\Rightarrow$]
      \begin{itemize}
        \item
          If $(σ_i)_{i∈\overline{n}}$ is balanced, its target state $σ_n$
          is a return state that must also have the empty continuation, hence it
          is a final state.
        \item
          If $(σ_i)_{i∈\overline{n}}$ is stuck, it is finite and maximal, but not balanced, so its
          target state $σ_n$ cannot be a return state;
          otherwise maximality implies $σ_n$ has an (initial) empty continuation
          and the trace would be balanced. On the other hand, the only returning
          transitions apply to return states, so maximality implies there is no
          $σ'$ such that $σ \smallstep σ'$ whatsoever.
        \item
          If $(σ_i)_{i∈\overline{n}}$ is diverging, $n=ω$ and for every $σ$ with
          $\inj(\pe) \smallstep^* σ$ there exists an $i$ such that $σ = σ_i$ by
          determinism.
      \end{itemize}

    \item[$\Leftarrow$]
      \begin{itemize}
        \item
          If $σ_n$ is a final state, it has $\cont(σ) = \cont(\inj(\pe)) = []$,
          so the trace is balanced.
        \item
          If $σ$ is not a final state, $τ'$ is not balanced. Since there is no
          $σ'$ such that $σ \smallstep^* σ'$, it is still maximal; hence it must
          be stuck.
        \item
          Suppose that $n∈ℕ_ω$ was finite.
          Then, if for every choice of $σ$ there exists $σ'$ such that $σ
          \smallstep σ'$, then there must be $σ_{n+1}$ with $σ_n \smallstep
          σ_{n+1}$, violating maximality of the trace.
          Hence it must be infinite.
          It is also interior, because every stack extends the empty stack,
          hence it is diverging.
      \end{itemize}
  \end{itemize}
\end{proof}

\subsection{Discussion}

We can already give perspective on two of the goals we set ourselves in
\Cref{sec:problem}:

As the domain $\VanD$ of our semantics $\semvan{\wild}$ is one defined by
guarded recursion, the approximation order between elements of the domain is
discrete and all elements are total.
$\semvan{\wild}$ is formulated entirely within this internal language and as
such, looping programs are denoted by total elements as well,
fullfilling Goal 2.
