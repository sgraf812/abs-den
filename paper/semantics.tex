\section{Semantics}
\label{sec:semantics}

\subsection{Labelled Syntax}

Recall \Cref{fig:syntax}; it defines the syntax of $Λ$, an untyped lambda
calculus with recursive let bindings and data types in the style of
\citet{Launchbury:93} and \citet{Sestoft:97}.
Any (sub-)expression of $Λ$ has a unique \emph{label} (think of it as the AST node's
pointer identity) that we usually omit. For example, a correct labelling of
$\Let{x}{f~y}{f~x}$ would be
\[
  (\slbln{1} \Let{x}{(\slbln{2} (\slbln{3} f)~y)}{(\slbln{4} (\slbln{5} f)~x)}).
\]
Labels are there so that we do not conflate the (otherwise structurally equal)
sub-terms $(\slbln{3} f)$ and $(\slbln{5} f)$ as equivalent. This is an important
distinction for, \eg, control-flow analysis. Since labels introduce excessive
clutter, we will omit them unless they are distinctively important. If anything,
labels make it so that everything ``works as expected''.

\subsection{Transition System}

\Cref{fig:lk-semantics} gave an operational semantics for $Λ$ in terms of
a small-step transition system closest to the lazy Krivine machine
\citep{AgerDanvyMidtgaard:04} for Launchbury's language.
It is worth having a second look at the workings of our Gold Standard.

When the control expression $ctrl(σ)$ of a state $σ$ is a value $\pv$, we
call $σ$ a \emph{return} state and say that the continuation $cont(σ)$ drives
evaluation.
Otherwise, $σ$ is an \emph{evaluation} state and $ctrl(σ)$ drives evaluation.
The entries in the heap $μ$ are \emph{closures} of the form $(ρ,e)$, where the
environment $ρ$ closes over the expression $e$.
Finally, the $cont(σ)$ lists actions to be taken in a return state, such as
applying the result to an argument address or updating a heap entry with its
value.

Heap entries are introduced via $\BindT$ transitions under a \emph{fresh} address
$\pa \not∈ \dom(μ)$ that we call an \emph{activation} of the let-bound variable
$\px$. The lexical activation of every variable in scope is maintained
in $ρ$. The $\AppIT$ rule pushes an \emph{application frame} with the address of
the argument variable onto the stack, while the rule $\LookupT$ pushes an
\emph{update frame} with the address of the variable the heap entry of which is
accessed. When a return state is reached, the original heap entry is overwritten
with the value in the control.

Let us conclude with an example trace in this transition system, evaluating
$\pe \triangleq \Let{i}{\Lam{x}{x}}{i~i}$ to completion:
\[\begin{array}{c}
  \arraycolsep2pt
  \begin{array}{clclclcl}
             & (\pe, [], [], \StopF)         & \smallstep & (i~i, ρ_1, μ, \StopF)
             & \smallstep & (i, ρ_1, μ, κ_1) & \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_2)
             \\
  \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_1)     & \smallstep & (x, ρ_2, μ, \StopF) & \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_3)
             & \smallstep & (\Lam{x}{x}, ρ_1, μ, \StopF) \\
  \end{array} \\
  \\[-0.5em]
  \quad \text{where} \quad \begin{array}{lll}
  ρ_1 = [i ↦ \pa_1] & ρ_2 = [i ↦ \pa_1, x ↦ \pa_1] & μ = [\pa_1 ↦ (ρ_1,\Lam{x}{x})] \\
  κ_1 = \ApplyF(\pa_1) \pushF \StopF & κ_2 = \UpdateF(\pa_1) \pushF κ_1 & κ_3 = \UpdateF(\pa_1) \pushF \StopF
  \end{array}
\end{array}\]

\subsection{Guarded Recursive Types}

The key to avoiding Domain Theory and $\bot$ as a semantic domain for our work
is use of a total type theory with \emph{guarded recursive types}, such as
Guarded Dependent Type Theory (GDTT) \citep{gdtt}.%
\footnote{Of course, in reality we are just using GDTT as a meta
language~\citep{Moggi:07} with a known domain theoretic interpretation in terms
of the topos of trees~\citep{gdtt}.
Thanks to GDTT this meta language is sufficiently expressive as a logic to
express proofs, though, justifying the view that we are extending ``math''
with the ability to conveniently reason about infinite data without needing to
think about topology and approximation directly.}
The fundamental construct of this theory is addition of the ``later''
modality $\later[κ]$ which allows to define coinductive data types with negative
occurrences, as first realised by \citet{Nakano:00}.
Whereas previous theories of coinduction require syntactic productivity
checks~\citep{Coquand:94}, requiring tiresome constraints on the form of guarded
recursive functions, the appeal of GDTT is that productivity is instead proven
semantically, in the type system.

The way that GDTT achieves this is roughly as follows: The type $\later T$
represents data of type $T$ that will become available after a finite amount
of computation, such as unrolling one layer of a fixpoint definition.
It comes with a general fixpoint combinator $\fix : \forall A.\ (\later A \to
A) \to A$ that can be used to define both coinductive \emph{types} (via guarded
recursive functions on the universe of types~\citep{BirkedalMogelbergEjlers:13})
as well as guarded recursive \emph{terms} inhabiting said types.
The classic example is that of coinductive streams:
\[
  Str = ℕ \times \later Str \qquad ones = \fix (r : \later Str).\ (1,r),
\]
where $ones : Str$ is the constant stream of $1$.
In particular, $Str$ is the fixpoint of a locally contractive functor $F(X) =
ℕ \times \later X$.
According to \citet{BirkedalMogelbergEjlers:13}, any type expression in simply
typed lambda calculus defines a locally contractive functor as long as any
occurrence of $X$ is under a $\later$, so we take that as the well-formedness
criterion of coinductive types in this work.

As a type constructor, $\later$ is an applicative
functor~\citep{McBridePaterson:08} via functions
\[
  \purelater : \forall A.\ A \to \later A \qquad \wild \aplater \wild : \forall A,B.\ \later (A \to B) \to \later A \to \later B,
\]
allowing us to apply a familar framework of reasoning around $\later$.
In order not to obscure our work with pointless symbol pushing, we will omit
the idiom brackets that would be necessary in a mechanised form to indicate
where the $\later$ ``effects'' happen; they should be easy to infer anyway.
\sg{Perhaps we should add the elaborated version in the Appendix.}

\begin{figure}
\[\begin{array}{c}
 \begin{array}{rrclclrrclcl}
  \text{States}        & σ   & ∈ & \States        & =      & \Controls \times \Heaps
  &
  \text{Environments}  & ρ   & ∈ & \Environments  & =      & \Var \pfun \later\StateD
  \\
  \text{Controls}      & \pc & ∈ & \Controls      & ::=    & \pe \mid (\pv, v)
  &
  \text{Heaps}         & μ   & ∈ & \Heaps         & =      & \Addresses \pfun \later\StateD
  \\
  \\[-0.5em]
 \end{array} \\
 \begin{array}{rrclclrrclcl}
  \text{Stateful traces} & τ      & ∈          & \STraces & ::= & \goodend{σ} \mid \stuckend{σ} \mid σ \cons τ^{\later}
  &
  \text{Delayed trace} & τ^{\later} & ∈ & \later\STraces &   &
  \\
  \text{Stateful domain} & d & ∈ & \StateD & = & \Heaps \to \STraces
  &
  \text{Delayed element} & d^{\later} & ∈ & \later\StateD &   &
  \\
  \\[-0.5em]
 \end{array} \\
 \begin{array}{rrclcl}
  \text{Semantic values} & v & ∈ & \StateV & ::= & \FunV(f ∈ (\later\StateD \to \later\StateD)) \mid \ConV(K,\many{d^{\later}}^{α_K}) \\
 \end{array} \\
  \\[-0.5em]
\end{array}\]
\[\begin{array}{c}
 \begin{array}{rcl}
  \multicolumn{3}{c}{ \ruleform{
    \begin{array}{c}
      (\betastep) : \later\STraces \to (\later\States \pfun \later\STraces) \to \later\STraces \quad  \mathit{ret} : (\Val \times \StateV) \to \StateD \\
      \mathit{deref} : \Addresses \to \later\StateD \quad \mathit{apply} : \later\STraces \to \later\StateD \to \later\STraces \\
      \mathit{select} : \later\STraces \to ((\later\STraces)^{α_K} \pfun \later\STraces)^* \to \later\STraces \\
    \end{array}
  }} \\
  \\[-0.5em]
  τ \betastep f & = & \begin{cases}
      τ :: f(σ) & \text{$τ = ... \cons \goodend{σ}$ and $σ ∈ \dom(f)$} \\
      τ' :: \stuckend{σ} & \text{$τ = τ' \cons \goodend{σ}$ and $σ \not∈ \dom(f)$} \\
      τ & \text{otherwise} \\
    \end{cases} \\
  \\[-0.5em]
  \mathit{ret}(\pv,v)(μ) & = & \goodend{((\pv,v),μ)} \\
  \\[-0.5em]
  \mathit{deref}(\pa)(μ) & = & μ(\pa)(μ) \betastep \fn{((\pv,v),μ)}{\goodend{((\pv,v),μ[\pa ↦ \mathit{ret}(\pv,v)])}} \\
  \\[-0.5em]
  \mathit{apply}(τ,d) & = & τ \betastep \fn{((\wild,\FunV(f)),μ)}{f(d)(μ)} \\
  \\[-0.5em]
  \mathit{select}(τ,\many{f}) & = & τ \betastep \fn{((\wild,\ConV(K_s,\many{d_s})),μ)}{f_s(\many{d_s})} \\
  \\[-0.5em]
  \multicolumn{3}{c}{ \ruleform{ \semst{\wild} \colon \Exp → (\Var \pfun \later\StateD) → \StateD } } \\
  \\[-0.5em]
  \semst{\px}_ρ(μ) & = & \begin{cases}
    (\px,μ) \cons ρ(\px)(μ) & \px ∈ \dom(ρ) \\
    \stuckend{(\px,μ)} & \text{otherwise}
    \end{cases} \\
  \\[-0.5em]
  \semst{\Lam{\px}{\pe}}_ρ & = & \mathit{ret}(\Lam{\px}{\pe},\FunV(\fn{d}{\semst{\pe}_{ρ[\px↦d]}})) \\
  \\[-0.5em]
  \semst{\pe~\px}_ρ(μ) & = & \begin{cases}
      (\pe~\px,μ) \cons \mathit{apply}(\semst{\pe}_ρ(μ),ρ(\px)) & \px ∈ \dom(ρ) \\
      \stuckend{(\pe~\px,μ)} & \text{otherwise} \\
    \end{cases} \\
  \\[-0.5em]
  \semst{\Let{\px}{\pe_1}{\pe_2}}_ρ(μ) & = & \begin{letarray}
    \text{let} & ρ' = ρ[\px ↦ \mathit{deref}(\pa)] \quad \text{where $\pa \not∈ \dom(μ)$} \\
               & μ' = μ[\pa ↦ \semst{\pe_1}_{ρ'}] \\
    \text{in}  & (\Let{\px}{\pe_1}{\pe_2},μ) \cons \semst{\pe_2}_{ρ'}(μ') \\
  \end{letarray} \\
  \\[-0.5em]
  \semst{K~\many{\px}}_ρ & = & \mathit{ret}(K~\many{\px},\ConV(K,\many{\semst{\px}_ρ})) \\
  \\[-0.5em]
  \semst{\pe@(\Case{\pe_s}{\Sel[r]})}_ρ(μ) & = & (\pe,μ) \cons \mathit{select}(\semst{\pe_s}_ρ(μ),\many{\fn{\many{d}^{α_K}}{\semst{\pe_r}_{ρ[\many{\px↦d}]}}})  \\
 \end{array}
  \\[-0.5em]
\end{array}\]
\caption{Structural call-by-need stateful trace semantics $\semst{-}$}
  \label{fig:semst}
\end{figure}

\subsection{Definition}

\Cref{fig:semst} finally gives the definition for $\semst{\wild}$, a function
defined by structural recursion on an input expression $\pe$. Given a denotation
for free variables $ρ$, $\semst{\pe}_ρ$ assigns $\pe$ a denotation $d$ in terms of
the semantic domain $\StateD$ of stateful call-by-need trace functions.
If such a trace function is supplied the heap $μ$ just before $\pe$ takes
control, then $d(μ)$ is a trace $τ$ starting at $\pe$ in that heap $μ$.
If evaluation of $\pe$ terminates, then $τ$ will be a finite list of states
ending with $\goodend{σ}$ for some return state $σ$. Otherwise, it might be
finite but stuck ($\stuckend{σ}$), or diverge without ever leaving $\pe$, in
which case $τ$ will be infinite.

Compared to the LK transition semantics, the most striking difference in state
structure is the lack of environment and stack components. The former is
maintained as a parameter to $\semst{\wild}$, while the latter is implicit in
the recursive call structure.
As we have seen in \Cref{sec:problem} at the example of $\semscott{\wild}$,
this reflection of machine state into ``math'' bears great potential for
program analysis, one we will exploit in \Cref{sec:abstractions}.
The second difference is that the environment $ρ$ and the heap $μ$ do not map to
addresses or syntactic closures but to delayed semantic values $\later \StateD$,
offering further abstraction possibilities compared to the rigid and indirect
syntactic domain.
The third difference is in control structure which explicitly signals the
distinction between evaluation states and return states.
In a return state $((\pv,v),μ)$, the syntactic value $\pv$ travels together with
a \emph{semantic} value $v ∈ \StateV$.
Crucially, this allows the embedding of function values $\FunV(f)$ in the
lambda case $\semst{\Lam{\px}{\pe}}$, enabling a compositional definition of the
application case $\semst{\pe~\px}$, just as in $\semscott{\wild}$.

It is worth noting that without guarded recursive types, the definition of
$\StateV$ would not be well-founded; a nuisance usually solved via restriction
to continuous functions on Scott domains and solving the corresponding domain
equation.

Note that we will continue to use the cons notation $τ \cons τ'$ quite liberally
to denote concatenation of traces. Doing so is unambiguous (because states are
distinct from traces) and well-defined via the following guarded fixpoint:
\[
  \fix (f : \later (\STraces \to \STraces \to \STraces)).\ λ(τ : \STraces)~(τ' : \STraces).\ \begin{cases}
    \stuckend{σ} & τ = \stuckend{σ} \\
    σ \cons τ'   & τ = \goodend{σ} \\
    σ \cons f \aplater τ^{\later} \aplater \purelater τ' & τ = σ \cons τ^{\later} \\
  \end{cases}
\]
A similar productive definition can be given for $\betastep$, which is to be
understood as yielding from the input trace $τ$ until it hits either end case of
the trace.

Intuitively, the heap lists the denotation of the expression bound at a
particular address, while the environment passed to $\semst{\wild}$ assigns each
free variable $\px$ a $\mathit{deref}(\pa)$ action for the particular address that $\px$
should be bound to.

Let us now understand $\semst{\wild}$ by way of evaluating the example program
from earlier, $\pe \triangleq \Let{i}{\Lam{x}{x}}{i~i}$:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[mymatrixenv,anchor=center]
      \matrix [mymatrix] (m)
      {
        1 & (\pe, []) \cons {} & \hspace{3.7em} & \hspace{4.2em} & \hspace{3.9em} & \hspace{2.5em} \\
        2 & (i~i, μ) \cons {} & & & & \\
        3 & (i, μ) \cons {} & & & & \\
        4 & ((\Lam{x}{x}, \FunV(f)), μ) \cons {} & & & & \\
        5 & ((\Lam{x}{x}, \FunV(f)), μ) \cons {} & & & & \\
        6 & (x, μ) \cons {} & & & & \\
        7 & ((\Lam{x}{x}, \FunV(f)), μ) \cons {} & & & & \\
        8 & \goodend{((\Lam{x}{x}, \FunV(f)), μ)} & & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{8}{$\semst{\pe}_{[]}$}
      \myleftbrace{4}{1}{2}{$\BindT$}
      \myleftbrace{4}{2}{8}{$\semst{i~i}_{ρ_1}$}
      \myleftbrace{5}{2}{3}{$\AppIT$}
      \myleftbrace{5}{3}{5}{$\semst{i}_{ρ_1}$}
      \myleftbrace{5}{5}{6}{$\AppET$}
      \myleftbrace{5}{6}{8}{$\semst{x}_{ρ_2}$}
      \myleftbrace{6}{3}{4}{$\LookupT$}
      \myleftbrace{6}{4}{5}{$\UpdateT$}
      \myleftbrace{6}{6}{7}{$\LookupT$}
      \myleftbrace{6}{7}{8}{$\UpdateT$}
  \end{tikzpicture}
  $}} &
  \!\!\!\!\text{where}  \begin{array}{ll}
  ρ_1 = [i ↦ \mathit{deref}(\pa_1)] & \\
  ρ_2 = ρ_1[x ↦ \mathit{deref}(\pa_1)] &  \\
  μ = [\pa_1 ↦ \semst{\Lam{x}{x}}_{ρ_1}] & \\
  f = d \mapsto \semst{\px}_{ρ_1[\px↦d]}
  \end{array}
\end{array}\]
The annotations to the right of the trace can be understood as denoting the
``call graph'' of $\semst{\pe}_{[]}$, with the corresponding LK transitions
as leaves.
Evaluation begins with a $\BindT$ transition from state 1 to state 2.
A fresh address $\pa_1$ is allocated for variable $i$ and the heap is extended
with $\semst{\Lam{x}{x}}_{ρ_1}$.
It is interesting to realise that this process does not involve a fixpoint
despite the recursive semantics of let.
Of course, the self-application in $\mathit{deref}$ does the job just as well, as we will
see in due course.

Evaluation recurses into the body $\semst{i~i}_{ρ_1}$ in the extended
environment $ρ_1$ to produce state 2, also yielding another $\AppIT$ transition
into $\semst{i}_{ρ_1}$.
Note that the final state 5 of $\semst{i}_{ρ_1}$ will later be fed (via
$\betastep$) into anonymous function in $\mathit{apply}$.
This scheme is quite common: Continuation items of the transition semantics
(``data'') are reflected into the call stack of the trace semantics (``code'').

$\semst{i}_{ρ_1}$ guides the trace through a heap lookup:
A $\LookupT$ goes straight into the $\mathit{deref}(\pa_1)$ action stored in the
environment entry for $i$, which performs the aforementioned self-application
to run the heap action $μ(\pa_1) = \semst{\Lam{x}{x}}_{ρ_1}$ starting in the
current heap $μ$.
Evaluation of $\semst{\Lam{x}{x}}_{ρ_1}$ terminates immediately in return state
4.
Returning to $\mathit{deref}(\pa_1)$, we witness for the first time a reduction
operation via $\betastep$:
Since the trace terminates, the anonymous function in $\mathit{deref}(\pa_1)$ is called
(in $\betastep$) with state 4, making an $\UpdateT$ transition to state 5.
Note that there is no observable change to the heap $μ$ because
$\mathit{ret}(\Lam{x}{x}, \FunV(f))$ is precisely the same as $\semst{\Lam{x}{x}}_{ρ_1}$.

After the heap update we leave $\semst{i}$ in return state 5, where $\betastep$
yields to the anonymous function in $\mathit{apply}$ (from the call to
$\semst{i~i}_{ρ_1}$), yielding another $\AppET$ reduction and giving control
to $f(ρ_1(i)) = \semst{x}_{ρ_1[x ↦ ρ_1(i)]}$.
Since $x$ is an alias for $i$, steps 6 to 8 just repeat the same same heap
update sequence we observed in steps 3 to 5, concluding the example.

It is useful to review another example involving an observable heap
update. The following trace begins right before the heap update occurs in
$\Let{i}{(\Lam{y}{\Lam{x}{x}})~i}{i~i}$, that is, after reaching the value
in $\semst{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1}$:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[baseline={-0.5ex},mymatrixenv]
      \matrix [mymatrix] (m)
      {
        1 & ((\Lam{x}{x},\FunV(f)), μ_1) \cons {} & \hspace{4em} & \hspace{4em} & \hspace{2.5em} \\
        2 & ((\Lam{x}{x},\FunV(f)), μ_2) \cons {} & & & \\
        3 & (x, μ_2) \cons {} & & & \\
        4 & ((\Lam{x}{x}, \FunV(f)), μ_2) \cons {} & & & \\
        5 & \goodend{((\Lam{x}{x}, \FunV(f)), μ_2)} & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{5}{$\semst{i~i}_{ρ_1}$}
      \myleftbrace{4}{1}{2}{$\semst{i}_{ρ_1}$}
      \myleftbrace{4}{2}{3}{$\AppET$}
      \myleftbrace{4}{3}{5}{$\semst{x}_{ρ_3}$}
      \myleftbrace{5}{1}{2}{$\UpdateT$}
      \myleftbrace{5}{3}{4}{$\LookupT$}
      \myleftbrace{5}{4}{5}{$\UpdateT$}
    \end{tikzpicture}
  $}} &
  \!\!\!\text{where} \begin{array}{l}
  ρ_1 = [i ↦ \pa_1] \\
  ρ_2 = [i ↦ \pa_1, y ↦ \pa_1] \\
  ρ_3 = [i ↦ \pa_1, y ↦ \pa_1, x ↦ \pa_1] \\
  μ_1 = [\pa_1 ↦ \semst{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1}] \\
  μ_2 = [\pa_1 ↦ \semst{\Lam{x}{x}}_{ρ_2}] \\
  f = \fn{d}{\semst{\px}_{ρ_2[\px↦d}} \\
  \end{array} \\
\end{array}\]
Note that both the denotation in the heap \emph{and} its environment are updated
in state 2, and that the new denotation is immediately visible on the next heap
lookup in state 3, so that $\semst{\Lam{x}{x}}_{ρ_2}$ takes control rather than
$\semst{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1}$, just as the transition system requires.

The handling of data types and case expressions is routine (if a bit
syntactically heavy) and not different to denotational semantics in call-by-name
or call-by-value, but it allows us to observe type errors other than scoping
errors.
Let us consider evaluation of the closed expression
$\pe \triangleq \Let{x}{\ttrue}{\ttrue~x}$
(where $\ttrue$ is one of two unary data constructors of the data type $\bool
::= \ttrue \mid \ffalse$).
$\semst{\wild}$ makes it is easy to observe that the trace gets stuck:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[baseline={-0.5ex},mymatrixenv]
      \matrix [mymatrix] (m)
      {
        1 & (\pe, []) \cons {} & \hspace{4em} & \hspace{5em} & \hspace{2.5em} \\
        2 & (\ttrue~x, μ) \cons {} & & & \\
        3 & \stuckend{((\ttrue,\ConV(\ttrue)), μ)} & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{3}{$\semst{\pe}_{[]}$}
      \myleftbrace{4}{1}{2}{$\BindT$}
      \myleftbrace{4}{2}{3}{$\semst{\ttrue~x}_{ρ}$}
      \myleftbrace{5}{2}{3}{$\AppIT$}
    \end{tikzpicture}
  $}} &
  \!\!\!\text{where} \begin{array}{l}
  ρ = [x ↦ \pa_1] \\
  μ = [\pa_1 ↦ \semst{\ttrue}_ρ] \\
  \end{array} \\
\end{array}\]
Crucially, $\betastep$ is equipped to propagate $\stuckend{\wild}$ up the call
stack (through potential $\UpdateT$ transitions, in particular), similar to
\citeauthor{Milner:78}'s $\mathbf{wrong}$.

Diverging traces hold no new surprises, other than they are observably different
to stuck traces.

%\begin{figure}
%\[\begin{array}{c}
% \begin{array}{rrclcl}
%  \text{LK traces}                    & τ      & ∈          & \STraces & ::=_{\gfp} & \goodend{σ} \mid σ \cons τ \\
% \end{array} \qquad
% \begin{array}{c}
%  \ruleform{ \validtrace{τ} \quad \deep{κ}{τ}} \\
%  \\[-0.5em]
%  \mprset{fraction={===}}
%  \inferrule*
%    {\quad}
%    {\validtrace{\goodend{σ}}}
%  \quad
%  \inferrule*
%    {σ \smallstep src_\States(τ) \quad \validtrace{τ}}
%    {\validtrace{(σ \cons τ)}} \\
% \end{array} \\
% \begin{array}{c} \\
% \mprset{fraction={===}}
% \inferrule*
%   {cont(σ) = ...κ}
%   {\deep{κ}{\goodend{σ}}}
% \quad
% \inferrule*
%   {cont(σ) = ... κ \quad σ \smallstep src_\States(τ) \quad \deep{κ}{τ}}
%   {\deep{κ}{(σ \cons τ)}}
% \end{array} \\
% \\
% \begin{array}{rcl}
%  \multicolumn{3}{c}{ \ruleform{ src_\States(τ) = σ \qquad tgt_\States(τ) = σ } } \\
%  \\[-0.5em]
%  src_\States(\goodend{σ})    & = & σ \\
%  src_\States(σ \cons τ) & = & σ \\
%  \\[-0.5em]
%  tgt_\States(τ)    & = & \begin{cases}
%    undefined & \text{if $τ$ infinite} \\
%    σ         & \text{if $τ = ... \cons \goodend{σ}$}
%  \end{cases} \\
% \end{array} \quad
% \begin{array}{c}
%  \ruleform{ τ_1 \sconcat τ_2 = τ_3 } \\
%  \\[-0.5em]
%  τ_1 \sconcat τ_2 = \begin{cases}
%    σ \cons (τ_1' \sconcat τ_2) & \text{if $τ_1 = σ \cons τ_1'$} \\
%    τ_2                    & \text{if $τ_1 = \goodend{σ}$ and $src_\States(τ_2) = σ$} \\
%    undefined              & \text{if $τ_1 = \goodend{σ}$ and $src_\States(τ_2) \not= σ$} \\
%  \end{cases} \\
% \end{array} \\
%\end{array}\]
%\caption{LK traces}
%  \label{fig:lk-traces}
%\end{figure}

\subsection{Maximal LK Traces}

It turns out that the traces $\semst{\pe}$ generates correspond to
\emph{maximal} traces in the LK transition system.
Let us make precise what that means.

A transition system is characterised by the set of \emph{traces} it generates.
An \emph{LK trace} is a trace in $(\smallstep)$, \eg, a non-empty and
potentially infinite sequence of LK states $(σ_i)_{i∈\overline{n}}$
(where $\overline{n} = \{ m ∈ ℕ_+ \mid m ≤ n \}, \overline{ω} = ℕ_+ $),
such that $σ_i \smallstep σ_{i+1}$ for $i,(i+1)∈\overline{n}$.
%\Cref{fig:lk-traces} gives a (coinductive) definition of such a trace type
%$\STraces$ which is to be understood as the greatest fixed-point of the
%functional $F(X) = \States + (\States \times X)$.
%This is isomorphic to the definition as a sequence, hence we will freely
%switch between notations for $τ$, in particular to index its states.

The \emph{source} state $σ_1$ exists for finite and infinite traces, while the
\emph{target} state $σ_n$ is only defined when $n \not= ω$ is finite.
%The expression $τ_1 \sconcat τ_2$ denotes the concatenation of two traces; it is
%simply $τ_1$ when $τ_1$ is infinite and undefined when the target state of $τ_1$
%does not coincide with the source state of $τ_2$.

An important kind of trace is one that never leaves the evaluation context of
its source state:

\begin{definition}[Interior and balanced traces]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is
  \emph{interior} if every intermediate continuation
  $κ_i = cont(σ_i)$ extends $κ_1$ (so $κ_i = κ_1$ or $κ_i = ... \pushF κ_1$,
  abbreviated $κ_i = ...κ_1$).

  Furthermore, an interior trace $(σ_i)_{i∈\overline{n}}$ is
  \emph{balanced}~\citep{Sestoft:97} if the target state exists and is a return
  state with continuation $κ_1$.
\end{definition}

\begin{example}
  Let $ρ=[x↦\pa_1],μ=[\pa_1↦([], \Lam{y}{y})]$ and $κ$ an arbitrary
  continuation. The trace
  \[
     (x, ρ, μ, κ) \smallstep (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, κ)
  \]
  is interior and balanced. Its prefixes are interior but not balanced.
  The trace suffix
  \[
     (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, κ)
  \]
  is neither interior nor balanced.
\end{example}

%We will later use the following alternative characterisation of interior traces
%in terms of the coinductive predicate $\deep{κ}{τ}$ from \Cref{fig:lk-traces}:
%
%\begin{lemma}
%  An LK trace $τ$ is interior iff $\deep{κ}{τ}$, where $(κ,\wild,\wild,\wild) =
%  src_\States(τ)$.
%\end{lemma}
%\begin{proof}
%  The coinductive predicate is a constructive encoding of the informal
%  definition of interior traces that ``inlines'' the well-formedness condition.
%\end{proof}

We will say that the transition rules $\LookupT$, $\AppIT$, $\CaseIT$ and $\BindT$
are interior, because the lifting into a trace is, whereas the returning
transitions $\UpdateT$, $\AppET$ and $\CaseET$ are not.

A balanced trace starting at a focus expression $\pe$ and ending with $(\pv,v)$
loosely corresponds to a derivation of $\pe \Downarrow \pv$ in a natural
big-step semantics~\citep{Sestoft:97} or a non-$⊥$ result in a denotational
semantics.

It is when a derivation in a natural semantics does not exist that a small-step
semantics shows finesse, in that it differentiates two different kinds of
\emph{maximally interior} (or, just \emph{maximal}) traces:

\begin{definition}[Maximal trace]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is \emph{maximal} if and only if it is
  interior and there is no $σ_{n+1}$ such that $(σ_i)_{i∈\overline{n+1}}$ is
  interior.
  More formally (and without a negative occurrence of ``interior''),
  \[
    \maxtrace{(σ_i)_{i∈\overline{n}}} \triangleq \interior{(σ_i)_{i∈\overline{n}}} \wedge (\not\exists σ_{n+1}.\ σ_n \smallstep σ_{n+1} \wedge cont(σ_{n+1}) = ...cont(σ_1))
  \]
  We notate maximal traces as $\maxtrace{(σ_i)_{i∈\overline{n}}}$.
\end{definition}

For call-by-value semantics there exists a maximal trace for every
expression~\citep[Lemma 10]{LeroyGrall:09}; it is not difficult to see that the
same holds for the LK transition semantics.

We call infinite and interior traces \emph{diverging}.
A maximally finite, but unbalanced trace is called \emph{stuck}.
Note that usually stuckness is associated with a state of a transition
system rather than a trace.
That is not possible in our framework; the following example clarifies.

\begin{example}[Stuck and diverging traces]
Consider the interior trace
\[
             (\ttrue~x, [x↦\pa_1], [\pa_1↦...], κ)
  \smallstep (\ttrue, [x↦\pa_1], [\pa_1↦...], \ApplyF(\pa_1) \pushF κ)
\]
It is stuck, but its singleton suffix is balanced.
An example for a diverging trace where $ρ=[x↦\pa_1]$ and $μ=[\pa_1↦(x,ρ,())]$ is
\[
  (\Let{x}{x}{x}, [], [], κ) \smallstep (x, ρ, μ, κ) \smallstep (x, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep ...
\]
\end{example}

A maximal trace that is not balanced either diverges or is stuck:

\begin{lemma}[Characterisation of maximal traces]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is maximal if and only if it is balanced,
  diverging or stuck.
\end{lemma}
\begin{proof}
  $\Rightarrow$: Let $(σ_i)_{i∈\overline{n}}$ be maximal.
  If $n=ω$ is infinite, then it is diverging due to interiority, and if
  $(σ_i)_{i∈\overline{n}}$ is stuck, the goal follows immediately.
  So we assume that $(σ_i)_{i∈\overline{n}}$ is maximal, finite and not stuck,
  so it must be balanced by the definition of stuckness.

  $\Leftarrow$: Both balanced and stuck traces are maximal.
  A diverging trace $(σ_i)_{i∈\overline{n}}$ is interior and infintie,
  hence $n=ω$.
  Indeed $(σ_i)_{i∈\overline{ω}}$ is maximal, because the expression $σ_{ω+1}$
  is undefined and hence does not exist.
\end{proof}

\subsection{Specification}

Our goal is to define a function $\semst{\pe}$ that produces maximal traces that
start out having $\pe$ in control. But there are as many traces as there
are states that have $\pe$ in control, each corresponding to the different
evaluation contexts in which $\pe$ might occur. Hence it makes sense to tell
$\semst{\pe}$ the particular source state $σ$ for which we wish to generate a
trace, leading to functionality $\semst{\pe} ∈ \States → \STraces$.

We will call $\semst{\pe}$ the \emph{denotation} of $\pe$ (a term that is
justified when we flesh out its properties relative to $\pe$) and abbreviate
the set of denotations to $\StateD$, as in \Cref{fig:lk-domain}.
$\StateD$ is used as the instantiation for parameter $D$ for our elaborated
semantics.
Likewise, we instantiate $V$ to a semantic representation of values
$\StateV$.
The keen reader may note immediately that $\StateD$ is not well-defined because
of a recursive occurrence in negative position (through $\States \to \Heaps \to
\StateD$); we discuss the necessary domain theory in \Cref{sec:domain-theory}
and focus on its application here.

So far we have collected the following two requirements for $τ = \semst{\pe}(σ)$:
The source state of $τ$ should be $σ$ again and $τ$ should be a maximal trace.
That is enough to begin ``calculating'' an elaborated trace with $\semst{\wild}$:
\[
  \semst{\Lam{x}{x}}(\Lam{x}{x}, ρ, μ, κ) = (\Lam{x}{x}, ρ, μ, κ) \cons ((\Lam{x}{x},\FunV(f)), ρ, μ, κ)\trend
\]
This undoubtedly is a maximal trace because it is balanced.
But what is $f$ supposed to do?
Like function values in denotational semantics, $f$ \emph{reflects} beta
reduction of the transition system into the meta language of Scott domains.
Thus the $f$ here is meant to guide the $\AppET$ rule.
The following required equation captures this intuition:
\[
  f(\pa)((\Lam{x}{x},\FunV(f)), ρ, μ, \ApplyF(\pa) \pushF κ) = ((\Lam{x}{x},\FunV(f)), ρ, μ, \ApplyF(\pa) \pushF κ) \cons \semst{x}(x, ρ[x ↦ \pa], μ, κ)
\]
This equation only specifies $f$'s behavior when the argument address on the
stack matches that of $f$'s first argument.
The free variables $\pa,ρ,μ,κ$ of this equation are intended to be universally
quantified; that is, it matches all states where the lambda expression is
applied.
Note also that $f$ closes over the semantics of the sub-program $\semst{x}$.
This is possible only thanks to the ability of Scott domains to turn the
``code'' (\eg, continuous functions) for the recursive invocation into ``data'',
and it is what ultimately enables a structural definition!

In general, semantic values pop exactly one frame from the stack and then produce
another balanced trace of the redex. This statement extends to other kinds of
values such as data constructors, as we shall see in \cref{ssec:adts}.

So not only do we require $\semst{\wild}$ to return maximal traces, we also pose
requirements on how these traces are elaborated. We have seen the requirement
on function values, and of course there is a similar requirement on the $d$
stored in a heap entry $(\pe, ρ, d)$: We require that $d = \semst{\pe}$.

The elaboration requirements can be summarised by the following predicate on
states and extends in the usual way to traces:

\begin{definition}[Well-elaborated]
  We say that a state $σ$ is \emph{well-elaborated} if
  \begin{itemize}
    \item For every heap entry $(\pe, ρ, d) ∈ \rng(μ)$, where $μ$ is the heap of
          $σ$, we have $d=\semst{\pe}$.
    \item If $σ$ is a return state with control $(\Lam{\px}{\pe}, \FunV(f))$,
          then for any state $σ'$ of the form \\
          $((\Lam{\px}{\pe}, \FunV(f)), ρ, μ, \ApplyF(\pa) \pushF κ)$,
          we have
          $f(\pa)(σ') = σ' \cons \semst{\pe}(\pe, ρ[\px ↦ \pa], μ, κ)$
          and $f(\pa)(σ') = σ'\trend$ everywhere else.
  \end{itemize}
  We notate well-elaborated states as $\elabstate{σ}$ and well-elaborated traces
  as $\elabtrace{τ}$ (defined coinductively over the states in $τ$).
\end{definition}

Note that the initial configurations $inj(\pe)$ are well-elaborated, because
they are never return states and their heap is empty.
Whenever $\semst{\wild}$ is given a well-elaborated state, the trace it produces
should be well-elaborated.

We conclude with the following specification:

\begin{definition}[Specification of $\semst{\wild}$]
\label{defn:semst-spec}
Let $σ$ be a well-elaborated state and $\pe$ its control expression. Then
\begin{itemize}
  \item[(S1)] $σ$ is the source state of the trace $\semst{\pe}(σ)$.
  \item[(S2)] $\maxtrace{\semst{\pe}(σ)}$
  \item[(S3)] $\elabtrace{\semst{\pe}(σ)}$
\end{itemize}
\end{definition}

\begin{figure}
\[\begin{array}{c}
 \begin{array}{rcl}
  \multicolumn{3}{c}{ \ruleform{ \semst{\wild} \colon \Exp → \StateD } } \\
  \\[-0.5em]
  \ternary{b}{t}{e} & = & \begin{cases} t & \text{if $b$ is true} \\ e & \text{otherwise} \\ \end{cases} \\
  \\[-0.5em]
  (d_1 \sfcomp d_2)(σ) & = & \ternary{d_1(σ) = \goodend{σ}}{\goodend{σ}}{d_1(σ) \sconcat d_2(tgt_\States(d_1(σ)))} \\
  \\[-0.5em]
  step(f)(σ) & = & \ternary{σ ∈ \dom(f)}{σ \cons f(σ)}{\goodend{σ}} \\
  \\[-0.5em]
  val(\pv,v)(\pv,ρ,μ,κ) & = & ((\pv,v),ρ,μ,κ) \trend \\
  \\[-0.5em]
  look(\px)(\px,ρ,μ,κ) & = &
    \begin{letarray}
      \text{let} & \pa = ρ(\px) \\
                 & (\pe,ρ',d) = μ(\pa) \\
      \text{in}  & d(\pe,ρ',μ,\UpdateF(\pa) \pushF κ) \\
    \end{letarray} \\
  \\[-0.5em]
  upd((\pv,v),ρ,μ,\UpdateF(\pa) \pushF κ) & = & ((\pv,v),ρ,μ[\pa ↦ (\pv,ρ,step(val(\pv,v)))], κ)\trend \\
  \\[-0.5em]
  app_1(\pe~\px)(\pe~\px,ρ,μ,κ) & = & (\pe,ρ,μ,\ApplyF(ρ(\px)) \pushF κ)\trend \\
  \\[-0.5em]
  app_2(\Lam{\px}{\pe},\pa)((\Lam{\px}{\pe},\FunV(\wild)),ρ,μ, \ApplyF(\pa) \pushF κ) & = & (\pe,ρ[\px ↦ \pa],μ,κ) \trend \\
  \\[-0.5em]
  bind(d_1)(\Let{\px}{\pe_1}{\pe_2},ρ,μ,κ) & = &
    \begin{letarray}
      \text{let} & ρ' = ρ[\px ↦ \pa] \quad \text{where $\pa \not∈ \dom(μ)$} \\
      \text{in}  & (\pe_2,ρ',μ[\pa ↦ (\pe_1, ρ', d_1)],κ)\trend \\
    \end{letarray} \\
  \\[-0.5em]
  \mathit{apply}(σ) & = & \begin{cases}
    f(\pa)(σ) & \text{if $σ=((\pv,\FunV(f)),\wild,\wild,\ApplyF(\pa) \pushF \wild)$} \\
    σ \trend & \text{otherwise} \\
  \end{cases} \\
  \\[-0.5em]
  \semst{\px} & = & step(look(\px)) \sfcomp step(upd) \\
  \\[-0.5em]
  \semst{\Lam{\px}{\pe}} & = & \begin{letarray}
    \text{let} & f = \pa \mapsto step(app_2(\Lam{\px}{\pe},\pa)) \sfcomp \semst{\pe} \\
    \text{in}  & step(val(\Lam{\px}{\pe},\FunV(f))) \\
  \end{letarray} \\
  \\[-0.5em]
  \semst{\pe~\px} & = & step(app_1(\pe~\px)) \sfcomp \semst{\pe} \sfcomp \mathit{apply} \\
  \\[-0.5em]
  \semst{\Let{\px}{\pe_1}{\pe_2}} & = & step(bind(\semst{\pe_1})) \sfcomp \semst{\pe_2} \\
 \end{array} \\
\end{array}\]
\caption{Structural call-by-need stateful trace semantics $\semst{-}$}
  \label{fig:semst}
\end{figure}

\subsection{Definition}

\Cref{fig:semst} defines $\semst{\wild}$.
Let us understand the function by \subsection{Domain Theory}

\label{sec:domain-theory}

\subsubsection{Domain construction}

Recall that $\StateD$ in \Cref{fig:lk-syntax} is not a well-formed inductive
definition without further clarification: It recurses in negative position via
$\States \to \Heaps \to \StateD$ and similarly through $\StateV$.
Hence we must understand $\StateD$ as a Scott domain and its ``definition'' as
a \emph{domain equation}, of which $\StateD$ is the least solution.

For that to carry meaning, we interpret all occuring function types, such as
$\States \to \STraces$, as continuous between their hypothetical source and
target domains.
This applies in the following way to finite maps:
$f ∈ A \pfun B$ (for flat domain $A$ and arbitrary domain $B$) is the
sub-domain of $f ∈ A \to (\{\notfound\} + B)$ of strict functions (so $f(⊥) =
⊥$) where the map's domain $\dom(f) ⊆ A$ is finite. Whenever $a \not∈ \dom(f)
\setminus ⊥$, we have $f(a) = \notfound$.

Recall that that an element $d$ of some domain $D$ is a \emph{total} element iff
there exists no $d' ∈ D$ such that $d ⊏ d'$. Otherwise if such a $d'$ exists,
$d$ is \emph{partial}.

Remarkably, we \emph{do not} conflate $⊥ ∈ A \pfun B$ with $[] ∈ A \pfun B$, the
finite map with $\dom(f) = \varnothing$.
The former is a partial element of the domain and assigns $⊥_B$ everywhere;
the latter is totally defined as an element of the domain and assigns
$\notfound$ everywhere.
As a consequence, $[a ↦ b] \triangleq [][a ↦ b] \not\sqsupseteq []$ since the
total elements of the domain are discrete.

The other domain constructors for products $\times$, sums $+$, fixpoints and the
derived inductive EBNF-style syntax definitions such as the potentially infinite
$\STraces$ (indicated by the $\gfp$ subscript) or finite $\Continuations$ are
standard, see for example \citep{Cartwright:16}. The domains on $\Addresses$ and
$\Var$ are the flat ones; the one on $\Exp$ is the flat one on labels.

This proves that $\StateD$ is well-defined as a domain.

\subsubsection{Continuity}

It is easy to verify (by simple type checking) that $\semst{\wild}$
is indeed a function from elements of $\States$ to something close to the
elements of $\STraces$ (ignoring embedding of recursive calls for a moment).
The missing ingredient to show that $\semst{\wild} ∈ \StateD$ is well-defined is
\emph{continuity}.

As given, the definition of $\semst{\wild}$ does not account for partial
elements at all, although it does a sufficient job provided the elements it
manipulates are total. It quite clearly is computable, so it should have a
continuous extension to partial elements; such was the entire point of
\citet{ScottStrachey:71} and we don't need to repeat it here. Now, we might
spend much time and space here clarifying boring technical details of strictness
such as ``Is $step(look)(\wild,\wild,\wild,\ApplyF(\pa) \pushF ⊥) = ⊥$?'' and
``What is the continuous elaboration of $tgt_\States$?'' that are implicit in a
code listing, only to finally conclude that the clarified formulation is indeed
continuous.

We decide to give the code listing instead: In the Appendix you can find 2 pages
of a model implementation in SML of New Jersey serving as a ``continuity
specification'' of $\semst{\wild}$ that we will treat as its ``ground truth''.
We chose SML because it has a standardised small-step operational semantics that
gives rise to an adequate denotational semantics, the core of which can be found
in \citep{Milner:78}.

On the spectrum between viable continuous extensions of $\semst{\wild}$, the
specification in ML is quite on the strict end. In fact, it introduces a lazy
field in one key position: The tail $τ$ of the cons form $σ \cons τ$ of $\STraces$.
That is hardly surprising given the coinductive nature of $τ$.

We find it ironic that in order to specify a semantics of a programming
language it is easier to reflect a code listing in a sufficiently
well-defined programming language (fittingly called ``Meta Language'') into a
continuous function than to find a language-agnostic, mathematical formulation
that we laboriously have to prove continuous.

Note that the considerably larger \emph{artifact} associated to this work is
implemented in Haskell because of familiarity to the authors and comfortable
ecosystem, serving as an example for a viable extension of $\semst{\wild}$
erring more towards the non-strict end. Still, it makes abundant use of
strictness annotations for good measure, debuggability and performance.
This demonstrates the semantic leeway a denotational formulation such as
$\semst{\wild}$ has while still being continuous and enjoying the termination
properties implied by our specification.

\subsection{Conformance}

Having a good grasp on the definition of $\semst{\wild}$ now, let us show that
$\semst{\wild}$ conforms to its specification in \Cref{defn:semst-spec}.

We will often talk about states that are well-elaborated and have a certain
expression in control, hence we abbreviate this set as
\[
  \States_\pe \triangleq \{σ ∈ \States \mid \elabstate{σ} \wedge ctrl(σ)=\pe\},
\]

\begin{lemma}[S1]
  \label{thm:s1}
  Let $σ ∈ \States_\pe$. Then $σ$ is the source state of $\semst{\pe}(σ)$.
\end{lemma}
\begin{proof}
  Trivial for the first clause of $\semst{\wild}$.
  Now, realising that $src_\States((l \sfcomp r)(σ)) = src_\States(l(σ))$
  and that $src_\States(step(f)(σ)) = σ$ for any $f$, we can see that the
  proposition follows for other clauses by applying these two rewrites to
  completion.
\end{proof}

The proof of (S2) depends on (S3), hence we will prove (S3) first.

\begin{lemma}[S3]
  \label{thm:s3}
  If $σ ∈ \States_\pe$, then $\elabtrace{\semst{\pe}(σ)}$.
\end{lemma}
\begin{proof}
By coinduction, following~\citet{Czajka:2019}.
The coinduction hypothesis is:
\[
  P(α) = ∀σ,\pe.\ σ ∈ \States_\pe \Longrightarrow \elabtracen{α}{\semst{\pe}(σ)}
\]
Where $α$ is a limit ordinal smaller than or equal to the closure ordinal $ζ$,
$ctrl(σ)$ selects the control of $σ$ and $\elabtracen{α}{τ}$ is the
$α$-approximant of the coinductive predicate $\elabtrace{τ}$.

Let us assume that $\elabstate{σ}$ for an arbitrary $σ$ with control expression
$\pe$. Whenever $f(σ)$ is undefined for some $f$, we can see that
$step(f)(σ) = \goodend{σ}$ is well-elaborated. Furthermore, if both $g$ and $h$
yield well-elaborated traces given a well-elaborated input state, then
$g \sfcomp h$ does so, too.

We abbreviate $τ \triangleq \semst{\pe}(σ)$ and proceed by case analysis over
$\pe$. We have $src_\States(τ) = σ$ by (S1) which is thus well-elaborated.
\begin{itemize}
  \item \textbf{Case $\px$}:
    Let us assume first that $look(\px)(σ)$ is undefined.
    Then $step(look(\px))(σ) = \goodend{σ}$.
    On the other hand, $step(upd)(σ) = \goodend{σ}$ because $upd$ is only defined on
    return states.
    Thus, $τ = \goodend{σ}$ and $\elabtracen{α+1}{τ}$.

    When $look(\px)(σ)$ is defined, $σ$ must be of the form $(\px,ρ,μ,κ)$, and
    $\pa,\pe,ρ',d$ must exist as in the definition of $look$ (shadowing $\pe =
    \px$ from the assumption, for simplicity).
    Clearly, $σ' \triangleq (\pe, ρ', μ, \UpdateF(\pa) \pushF κ)$ is
    well-elaborated, because $σ$ is and the heap did not change.
    Similarly, by $\elabstate{σ}$ we have $d = \semst{\pe}$.
    Now we apply the coinduction hypothesis to $τ' = \semst{\pe}(σ')$
    (noting that $\semst{\pe}$ is well-defined on $σ'$) and see that
    $\elabtracen{α}{τ'}$, hence $\elabtracen{α+1}{(σ \cons τ')}$.

    If $τ'$ is infinite, we are done.
    Otherwise, $σ_u \triangleq tgt_\States(τ')$ is well-elaborated and if
    $upd(σ_u)$ is undefined we are done, too, by our preceding considerations.
    If $σ_v \triangleq upd(σ_u)$, the $σ_u$ must have the form
    $((\pv,v),ρ,μ,\UpdateF(\pa) \pushF κ)$. We must show that
    $step(val(\pv,v)) = \semst{\pv}$ in order to show that $σ_v$ is
    well-elaborated.
    That is the case: well-elaboratedness of $σ_u$ implies that $v = \FunV(f)$
    for an $f$ just like that in the definition of $\semst{\pv}$.
    Since $τ'$ is finite, we have $\elabtracen{α+1}{(σ \cons τ' \cons \goodend{σ_v})}$ by
    reassociating the applications of the $\elabtrace{\wild}$ functional.
  \item \textbf{Case $\Lam{\px}{\pe}$}:
    The $\ValueT$ transition does not change the heap, but it transitions into a
    return state. We have established in the previous point that the semantic
    value $\FunV(f)$ fits our requirements for well-elaboratedness exactly,
    hence well-elaboratedness for the trace follows.
  \item \textbf{Case $\pe~\px$}:
    The $\AppIT$ transition preserves well-elaboratedness to its target state, so
    the input $σ'$ to $\semst{\pe}$ is well-elaborated. We apply the coinduction
    hypothesis and and have $\elabtracen{α+1}{(σ \cons \semst{\pe}(σ'))}$.
    (As before, if the resulting trace is infinite, we are done.)
    Forward composition preserves well-elaboratedness, hence it suffices to
    prove that given a well-elaborated input state $σ''$, $\mathit{apply}(σ'')$ is
    well-elaborated.
    That is the case if the subterm $f(\pa)(σ'')$ produces a well-elaborated
    trace.
    By $\elabstate{σ''}$, we know that $f$ must come from the
    $\semst{\Lam{\px}{\pe'}}$ case.
    $\AppET$ preserves well-elaboratedness to its target state and for
    $\semst{\pe'}$ we can apply the coinductive hypothesis.
    Now we have $\elabtracen{α+1}{(σ \cons \semst{\pe}(σ'))}$ and
    $\elabtracen{α+1}{\mathit{apply}(σ'')}$, so the same must hold for its concatenation.
  \item \textbf{Case $\Let{\px}{\pe_1}{\pe_2}$}:
    The $\BindT$ transition updates the heap, but it is clear that
    $bind(\semst{\pe_1})$ elaborates the correct $d_1$ into $σ'$.
    For the recursive call, we apply the coinduction hypothesis
    and conclude $\elabtracen{α+1}{(σ \cons \semst{\pe_2}(σ'))}$.
\end{itemize}
\end{proof}

The preceding lemma implies a very desirable property:
Whenever $σ$ is well-elaborated (and thus a total element of the approximation
order), $\semst{\pe}(σ)$ is total, too.
The approximation order restricted to total elements is discrete; hence we may
now put domain theoretic considerations behind us in favor of a coinductive
understanding.
We can capture the termination properties of $\semst{\wild}$ as follows:

\begin{corollary}
  The restriction of $\semst{\pe}$ to $\States_\pe$ is a total function, defined
  by \emph{guarded recursion}.
\end{corollary}

\begin{lemma}
  \label{thm:step-interior}
  If $f(σ) = τ$ implies $σ \smallstep src_\States(τ)$ interior and
  $τ$ interior, then $step(f)(σ)$ interior.
\end{lemma}
\begin{proof}
  Immediate. The case where $f$ is undefined is trivial.
\end{proof}

With increased clarity, we go on to prove the keystone property:

\begin{theorem}[S2]
  \label{thm:s2}
  If $σ ∈ \States_\pe$, then $\maxtrace{\semst{\pe}(σ)}$.
\end{theorem}
\begin{proof}
By coinduction, with the following hypothesis, similar to the proof of (S3):
\[
  P(α) = ∀σ,\pe.\ σ ∈ \States_\pe \Longrightarrow \maxtracen{α}{\semst{\pe}(σ)}
\]
Furthermore, we tacitly assume by (S3) that all occuring states are
well-elaborated. We will say that a state $σ$ is stuck if there is no applicable
rule in the transition system (\ie, $\goodend{σ}$ is a stuck maximal trace).

We abbreviate $τ \triangleq \semst{\pe}(σ)$ and proceed by case analysis over
$\pe$.
\begin{itemize}
  \item \textbf{Case $\px$}:
    Let us assume first that $look(\px)(σ)$ is undefined. Then the lookup
    $ρ(\px)$ must have failed and $\goodend{σ}$ is the result.
    On the other hand, $step(upd)(σ) = \goodend{σ}$ because $upd$ is only defined on
    return states, so $\goodend{σ}$ is the result of the composition, which is stuck
    and thus maximal.

    When $look(\px)(σ)$ is defined, $σ$ must be of the form $(\px,ρ,μ,κ)$, and
    $\pa,\pe,ρ',d$ must exist as in the definition of $look$.
    Clearly, $σ \smallstep (σ' \triangleq (\pe, ρ', μ, \UpdateF(\pa) \pushF κ))$
    by interior rule $\LookupT$.
    By $\elabstate{σ'}$ we have $d = \semst{\pe}$.
    Now we apply the coinduction hypothesis to $τ' \triangleq \semst{\pe}(σ')$
    and see that $\maxtracen{α}{τ'}$, hence with \Cref{thm:step-interior}
    $\interiorn{α+1}{σ \cons τ'}$.

    If $τ'$ is infinite, it is diverging and $\maxtracen{α+1}{σ \consτ'}$ follows.
    Otherwise, $σ_u \triangleq tgt_\States(τ')$ and either there is no
    transition $σ_u \smallstep σ_v$ or it leaves $cont(σ')$.
    The only two returning (\eg, non-interior) transitions are $\UpdateT$ and
    $\AppET$. Both pop a single continuation frame, thus $cont(σ_u) = cont(σ')$,
    because otherwise $cont(σ_u) = ... \pushF cont(σ')$ and popping one frame
    yields an interior transition.

    If $upd(σ_u)$ is defined, then the $\UpdateT$ transition exists as can
    easily be checked.
    Furthermore, since exactly one frame is popped, we must have
    $cont(σ) = cont(σ_v)$ and thus $\deepn{α+1}{cont(σ)}{(σ \cons τ \cons \goodend{σ_v})}$ by slight
    (corecursive) rearrangement of the proof for $\interiorn{α}{τ}$.
    $σ_v$ is a return state and any further transition must pop a continuation
    frame; hence $\maxtracen{α+1}{(σ \cons τ \cons \goodend{σ_v})}$.

    If $upd(σ_u)$ is undefined, then the $\UpdateT$ transition could not have
    fired. But the $\AppET$ transition can't have fired either, because if it
    could, we'd have $cont(σ_u) = cont(σ')$ by $\maxtracen{α}{τ'}$, but the top
    of $σ'$ is an update frame. Thus, again by maximality, there is no
    transition $σ_u \smallstep σ_v$ whatsoever and $\maxtracen{α+1}{σ \cons τ'}$.

  \item \textbf{Case $\Lam{\px}{\pe}$}:
    If $val(v, \FunV(f))$ is defined, then $σ \smallstep{\ValueT} σ'$ must
    exist. Furthermore, $σ \cons \goodend{σ'}$ is a maximal trace, as $σ'$ is a return
    state and any applicable transition leaves $cont(σ) = cont(σ')$.

    If $val(v, \FunV(f))$ is undefined, then $ctrl(σ) \not= \Lam{\px}{\pe}$, a
    contradiction.
  \item \textbf{Case $\pe~\px$}:
    If $app_1(\pe~\px)$ is undefined, then either $ctrl(σ) \not=\pe~\px$
    (contradiction), or $ρ(\px)$ was undefined, in which case $\goodend{σ}$ is stuck
    and thus maximal.

    If $app_1(\pe~\px)$ is defined, then
    $σ \smallstep{\AppIT} (σ' \triangleq (\pe,ρ,μ,\ApplyF(ρ(\px)) \pushF κ))$
    and $τ_1 \triangleq \semst{\pe}(σ')$ with $\maxtracen{α}{τ_1}$.

    Similar to the variable case, if $τ_\pe$ is infinite, $σ \cons τ_\pe$ is
    diverging and we are done. Otherwise, we have $σ_a \triangleq
    tgt_\States(τ_\pe)$ and either there is no transition $σ_a \smallstep σ_e$
    or it leaves $cont(σ')$, in which case we know $cont(σ') = cont(σ_a)$ and
    that the transition must have been $\AppET$.

    When the $\AppET$ transition exists, the first case of $\mathit{apply}(σ_a)$ matches.
    With $\elabstate{σ}$, we know that $f$ is defined just like in
    $\semst{\Lam{\px'}{\pe'}}$, where $ctrl(σ_a) = (\Lam{\px'}{\pe'}, \FunV(f))$.
    Similar to the variable case, we can see that
    $app_2$ matches and that $\maxtracen{α+1}{σ \cons τ_1 \cons \goodend{σ_e}}$, because
    $cont(σ_e) = cont(σ)$. By the coinductive hypothesis,
    $\maxtracen{α}{(τ_2 \triangleq \semst{\pe'}(σ_e))}$. By $cont(σ_e) = cont(σ)$
    and rearrangement we can see that $\interiorn{α+1}{σ \cons τ_1 \cons σ_e \cons τ_2}$ and
    maximality follows directly from maximality of $τ_2$.

    When the $\AppET$ transition does not exist, no other transition from $σ_a$
    does. Then the first case of $\mathit{apply}$ could not match, because the only
    syntactic values $\pv$ are lambdas and $\elabstate{σ_a}$ requires that
    $\FunV(f)$ matches accordingly.
    Thus, $σ \cons τ_1$ is the final, maximal trace.

  \item \textbf{Case $\Let{\px}{\pe_1}{\pe_2}$}:
    The $σ \smallstep{\BindT} σ'$ transition (which always exists for our choice
    of $σ$) does not push a new stack frame, hence $cont(σ) = cont(σ')$ and
    from the coinductive hypothesis $\maxtracen{α}{\semst{\pe_2}(σ')}$ we can
    immediately see $\maxtracen{α+1}{σ \cons \semst{\pe_2}(σ')}$.
\end{itemize}
\end{proof}

\Cref{thm:s2} is the key to proving a strong version of adequacy for
$\semst{\wild}$:

\begin{lemma}[Adequacy of $\semst{\wild}$]
  Let $τ = \semst{\pe}(inj(\pe))$.
  \begin{itemize}
    \item
      $τ$ is balanced iff there exists a final state $σ$ such that
      $inj(\pe) \smallstep^* σ$.
    \item
      $τ$ is stuck iff there exists a non-final state $σ$ such that
      $inj(\pe) \smallstep^* σ$ and there exists no $σ'$ such that $σ \smallstep
      σ'$.
    \item
      $τ$ is diverging iff for all $σ$ with $inj(\pe) \smallstep^* σ$ there
      exists $σ'$ with $σ \smallstep σ'$.
  \end{itemize}
\end{lemma}
\begin{proof}
  Note that $\maxtrace{τ}$ since $inj(\pe) ∈ \States_\pe$
  and the initial state $inj(\pe) = src_\States(τ)$ has an empty continuation.

  Clearly, the trace $τ'$ determined by a $σ$ such that $inj(\pe)
  \smallstep^* σ$ is an interior trace. Since $(\smallstep)$ is
  deterministic, it must be a prefix of the maximally interior trace $τ$.

  \begin{itemize}
    \item[$\Rightarrow$]
      \begin{itemize}
        \item
          If $τ$ is balanced, its target state $σ \triangleq tgt_\States(τ)$
          is a return state that must also have the empty continuation. Hence
          it is a final state and there exists $inj(\pe) \smallstep^* σ$ by
          $\validtrace{τ}$.
        \item
          If $τ$ is stuck, it is finite and maximal, but not balanced, so its
          target state $σ \triangleq tgt_\States(τ)$ cannot be a return state;
          otherwise maximality implies $σ$ has an (initial) empty continuation
          and the trace would be balanced. on the other hand, the only two
          returning transitions apply to return states, so maximality implies
          there is no $σ'$ such that $σ \smallstep σ'$ whatsoever.
        \item
          If $τ$ is diverging it is infinite and for every $σ$ with $inj(\pe)
          \smallstep^* σ$ determinism allows us to trace a finite prefix of
          $τ$, and there always exists $σ'$ such that $σ \smallstep σ'$ since
          $\validtrace{τ}$.
      \end{itemize}

    \item[$\Leftarrow$]
      \begin{itemize}
        \item
          If $σ$ is a final state, it has $cont(σ) = cont(inj(\pe)) = []$, so it
          is balanced.
        \item
          If $σ$ is not a final state, $τ'$ is not balanced. Since there is no
          $σ'$ such that $σ \smallstep^* σ'$, it is still maximal; hence it must
          be stuck.
        \item
          If for every choice of $σ$ (and thus $τ'$) there exists $σ'$ such that
          $σ \smallstep σ'$, there must be an infinite number of such $τ'$, all
          of which are prefixes of $τ$. Hence $τ$ must be infinite and interior,
          hence diverging.
      \end{itemize}
  \end{itemize}
\end{proof}

But there's more. Let us define the following binary relation $\equiv_\States$
by coinduction:
\[
\]

% \begin{theorem}[Full abstraction]
%   \label{thm:full-abstraction}
%  The restriction $S = \fn{\pe}{\semst{\pe}\restrict{\States_\pe}}$ is
%  \emph{fully abstract}~\citep{Plotkin:77}, meaning that
%
%  $\forall \pe_1,\pe_2.\ S(\pe_1) = S(\pe_2)
%
% \end{theorem}
