\section{Semantics}
\label{sec:semantics}

\subsection{Labelled Syntax}

Recall \Cref{fig:syntax}; it defines the syntax of $Λ$, an untyped lambda
calculus with recursive let bindings and data types in the style of
\citet{Launchbury:93} and \citet{Sestoft:97}.
Any (sub-)expression of $Λ$ has a unique \emph{label} (think of it as the AST node's
pointer identity) that we usually omit. For example, a correct labelling of
$\Let{x}{f~y}{f~x}$ would be
\[
  (\slbln{1} \Let{x}{(\slbln{2} (\slbln{3} f)~y)}{(\slbln{4} (\slbln{5} f)~x)}).
\]
Labels are there so that we do not conflate the (otherwise structurally equal)
sub-terms $(\slbln{3} f)$ and $(\slbln{5} f)$ as equivalent. This is an important
distinction for, \eg, control-flow analysis. Since labels introduce excessive
clutter, we will omit them unless they are distinctively important. If anything,
labels make it so that everything ``works as expected''.

\subsection{Transition System}

\Cref{fig:lk-semantics} gave an operational semantics for $Λ$ in terms of
a small-step transition system closest to the lazy Krivine machine
\citep{AgerDanvyMidtgaard:04} for Launchbury's language.
It is worth having a second look at the workings of our Gold Standard.

When the control expression $\mathit{ctrl}(σ)$ of a state $σ$ is a value $\pv$, we
call $σ$ a \emph{return} state and say that the continuation $\mathit{cont}(σ)$ drives
evaluation.
Otherwise, $σ$ is an \emph{evaluation} state and $\mathit{ctrl}(σ)$ drives evaluation.
The entries in the heap $μ$ are \emph{closures} of the form $(ρ,e)$, where the
environment $ρ$ closes over the expression $e$.
Finally, the $\mathit{cont}(σ)$ lists actions to be taken in a return state, such as
applying the result to an argument address or updating a heap entry with its
value.

Heap entries are introduced via $\BindT$ transitions under a \emph{fresh} address
$\pa \not∈ \dom(μ)$ that we call an \emph{activation} of the let-bound variable
$\px$. The lexical activation of every variable in scope is maintained
in $ρ$. The $\AppIT$ rule pushes an \emph{application frame} with the address of
the argument variable onto the stack, while the rule $\LookupT$ pushes an
\emph{update frame} with the address of the variable the heap entry of which is
accessed. When a return state is reached, the original heap entry is overwritten
with the value in the control.

Let us conclude with an example trace in this transition system, evaluating
$\pe \triangleq \Let{i}{\Lam{x}{x}}{i~i}$ to completion:
\[\begin{array}{c}
  \arraycolsep2pt
  \begin{array}{clclclcl}
             & (\pe, [], [], \StopF)         & \smallstep & (i~i, ρ_1, μ, \StopF)
             & \smallstep & (i, ρ_1, μ, κ_1) & \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_2)
             \\
  \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_1)     & \smallstep & (x, ρ_2, μ, \StopF) & \smallstep & (\Lam{x}{x}, ρ_1, μ, κ_3)
             & \smallstep & (\Lam{x}{x}, ρ_1, μ, \StopF) \\
  \end{array} \\
  \\[-0.5em]
  \quad \text{where} \quad \begin{array}{lll}
  ρ_1 = [i ↦ \pa_1] & ρ_2 = [i ↦ \pa_1, x ↦ \pa_1] & μ = [\pa_1 ↦ (ρ_1,\Lam{x}{x})] \\
  κ_1 = \ApplyF(\pa_1) \pushF \StopF & κ_2 = \UpdateF(\pa_1) \pushF κ_1 & κ_3 = \UpdateF(\pa_1) \pushF \StopF
  \end{array}
\end{array}\]

\subsection{Guarded Recursive Types}

The key to avoiding Domain Theory and $\bot$ as a semantic domain for our work
is use of a total type theory with \emph{guarded recursive types}, such as
Guarded Dependent Type Theory (GDTT) \citep{gdtt}.%
\footnote{Of course, in reality we are just using GDTT as a meta
language~\citep{Moggi:07} with a known domain theoretic interpretation in terms
of the topos of trees~\citep{gdtt}.
Thanks to GDTT this meta language is sufficiently expressive as a logic to
express proofs, though, justifying the view that we are extending ``math''
with the ability to conveniently reason about infinite data without needing to
think about topology and approximation directly.}
The fundamental construct of this theory is addition of the ``later''
modality $\later[κ]$ which allows to define coinductive data types with negative
occurrences, as first realised by \citet{Nakano:00}.
Whereas previous theories of coinduction require syntactic productivity
checks~\citep{Coquand:94}, requiring tiresome constraints on the form of guarded
recursive functions, the appeal of GDTT is that productivity is instead proven
semantically, in the type system.

The way that GDTT achieves this is roughly as follows: The type $\later T$
represents data of type $T$ that will become available after a finite amount
of computation, such as unrolling one layer of a fixpoint definition.
It comes with a general fixpoint combinator $\fix : \forall A.\ (\later A \to
A) \to A$ that can be used to define both coinductive \emph{types} (via guarded
recursive functions on the universe of types~\citep{BirkedalMogelbergEjlers:13})
as well as guarded recursive \emph{terms} inhabiting said types.
The classic example is that of coinductive streams:
\[
  Str = ℕ \times \later Str \qquad ones = \fix (r : \later Str).\ (1,r),
\]
where $ones : Str$ is the constant stream of $1$.
In particular, $Str$ is the fixpoint of a locally contractive functor $F(X) =
ℕ \times \later X$.
According to \citet{BirkedalMogelbergEjlers:13}, any type expression in simply
typed lambda calculus defines a locally contractive functor as long as any
occurrence of $X$ is under a $\later$, so we take that as the well-formedness
criterion of coinductive types in this work.

As a type constructor, $\later$ is an applicative
functor~\citep{McBridePaterson:08} via functions
\[
  \purelater : \forall A.\ A \to \later A \qquad \wild \aplater \wild : \forall A,B.\ \later (A \to B) \to \later A \to \later B,
\]
allowing us to apply a familiar framework of reasoning around $\later$.
In order not to obscure our work with pointless symbol pushing
in, \eg, \Cref{fig:semst}, we will often omit the idiom
brackets~\citep{McBridePaterson:08} $\idiom{}$ that would be necessary in a
mechanised form to indicate where the $\later$ ``effects'' happen; they should
be easy to infer anyway.
\sg{Perhaps we should add the elaborated version in the Appendix.}

\begin{figure}
\[\begin{array}{c}
 \begin{array}{rrclclrrclcl}
  \text{States}        & σ   & ∈ & \States        & =      & \Controls \times \Heaps
  &
  \text{Environments}  & ρ   & ∈ & \Environments  & =      & \Var \pfun \later\StateD
  \\
  \text{Controls}      & \pc & ∈ & \Controls      & ::=    & \pe \mid (\lbl, v)
  &
  \text{Heaps}         & μ   & ∈ & \Heaps         & =      & \Addresses \pfun \later\StateD
  \\
  \\[-0.5em]
 \end{array} \\
 \begin{array}{rrclclrrclcl}
  \text{Stateful traces} & τ      & ∈          & \STraces & ::= & \goodend{σ} \mid \stuckend{σ} \mid σ \cons τ^{\later}
  &
  \text{Delayed trace} & τ^{\later} & ∈ & \later\STraces &   &
  \\
  \text{Stateful domain} & d & ∈ & \StateD & = & \Heaps \to \STraces
  &
  \text{Delayed element} & d^{\later} & ∈ & \later\StateD &   &
  \\
  \\[-0.5em]
 \end{array} \\
 \begin{array}{rrclcl}
  \text{Semantic values} & v & ∈ & \StateV & ::= & \FunV(f ∈ (\later\StateD \to \later\StateD)) \mid \ConV(K,\many{d^{\later}}^{α_K}) \\
 \end{array} \\
  \\[-0.5em]
\end{array}\]
\[\begin{array}{c}
 \begin{array}{rcl}
  \multicolumn{3}{c}{ \ruleform{
    \begin{array}{c}
      (\betastep) : \later\STraces \to (\later\States \pfun \later\STraces) \to \later\STraces \quad  \mathit{ret} : (\Val \times \StateV) \to \StateD \\
      \mathit{deref} : \Addresses \to \later\StateD \quad \mathit{apply} : \later\STraces \to \later\StateD \to \later\STraces \\
      \mathit{select} : \later\STraces \to ((\later\STraces)^{α_K} \pfun \later\STraces)^* \to \later\STraces \\
    \end{array}
  }} \\
  \\[-0.5em]
  τ \betastep f & = & \begin{cases}
      τ :: f(σ) & \text{$τ = ... \cons \goodend{σ}$ and $σ ∈ \dom(f)$} \\
      τ' :: \stuckend{σ} & \text{$τ = τ' \cons \goodend{σ}$ and $σ \not∈ \dom(f)$} \\
      τ & \text{otherwise} \\
    \end{cases} \\
  \\[-0.5em]
  \mathit{ret}(\lbl,v)(μ) & = & \goodend{((\lbl,v),μ)} \\
  \\[-0.5em]
  \mathit{deref}(\pa)(μ) & = & μ(\pa)(μ) \betastep \fn{((\lbl,v),μ)}{\goodend{((\lbl,v),μ[\pa ↦ \mathit{ret}(\lbl,v)])}} \\
  \\[-0.5em]
  \mathit{apply}(τ,d) & = & τ \betastep \fn{((\wild,\FunV(f)),μ)}{f(d)(μ)} \\
  \\[-0.5em]
  \mathit{select}(τ,\many{f}) & = & τ \betastep \fn{((\wild,\ConV(K_s,\many{d_s})),μ)}{f_s(\many{d_s})} \\
  \\[-0.5em]
  \multicolumn{3}{c}{ \ruleform{ \semst{\wild} \colon \Exp → (\Var \pfun \later\StateD) → \StateD } } \\
  \\[-0.5em]
  \semst{\px}_ρ(μ) & = & \begin{cases}
    (\px,μ) \cons ρ(\px)(μ) & \px ∈ \dom(ρ) \\
    \stuckend{(\px,μ)} & \text{otherwise}
    \end{cases} \\
  \\[-0.5em]
  \semst{\slbl \Lam{\px}{\pe}}_ρ & = & \mathit{ret}(\lbl,\FunV(\fn{d}{\semst{\pe}_{ρ[\px↦d]}})) \\
  \\[-0.5em]
  \semst{\pe~\px}_ρ(μ) & = & \begin{cases}
      (\pe~\px,μ) \cons \mathit{apply}(\semst{\pe}_ρ(μ),ρ(\px)) & \px ∈ \dom(ρ) \\
      \stuckend{(\pe~\px,μ)} & \text{otherwise} \\
    \end{cases} \\
  \\[-0.5em]
  \semst{\Let{\px}{\pe_1}{\pe_2}}_ρ(μ) & = & \begin{letarray}
    \text{let} & ρ' = ρ[\px ↦ \mathit{deref}(\pa)] \quad \text{where $\pa \not∈ \dom(μ)$} \\
               & μ' = μ[\pa ↦ \semst{\pe_1}_{ρ'}] \\
    \text{in}  & (\Let{\px}{\pe_1}{\pe_2},μ) \cons \semst{\pe_2}_{ρ'}(μ') \\
  \end{letarray} \\
  \\[-0.5em]
  \semst{\slbl K~\many{\px}}_ρ & = & \mathit{ret}(\lbl,\ConV(K,\many{\semst{\px}_ρ})) \\
  \\[-0.5em]
  \semst{\pe@(\Case{\pe_s}{\Sel[r]})}_ρ(μ) & = & (\pe,μ) \cons \mathit{select}(\semst{\pe_s}_ρ(μ),\many{\fn{\many{d}^{α_K}}{\semst{\pe_r}_{ρ[\many{\px↦d}]}}})  \\
 \end{array}
  \\[-0.5em]
\end{array}\]
\caption{Structural call-by-need stateful trace semantics $\semst{-}$}
  \label{fig:semst}
\end{figure}

\subsection{Definition}

\Cref{fig:semst} finally gives the definition for $\semst{\wild}$, a function
defined by structural recursion on an input expression $\pe$. Given a denotation
for free variables $ρ$, $\semst{\pe}_ρ$ assigns $\pe$ a denotation $d$ in terms of
the semantic domain $\StateD$ of stateful call-by-need trace functions.
If such a trace function is supplied the heap $μ$ just before $\pe$ takes
control, then $d(μ)$ is a trace $τ$ starting at $\pe$ in that heap $μ$.
If evaluation of $\pe$ terminates, then $τ$ will be a finite list of states
ending with $\goodend{σ}$ for some return state $σ$. Otherwise, it might be
finite but stuck ($\stuckend{σ}$), or diverge without ever leaving $\pe$, in
which case $τ$ will be infinite.

Compared to the LK transition semantics, the most striking difference in state
structure is the lack of environment and stack components. The former is
maintained as a parameter to $\semst{\wild}$, while the latter is implicit in
the recursive call structure.
As we have seen in \Cref{sec:problem} at the example of $\semscott{\wild}$,
this reflection of machine state into ``math'' bears great potential for
program analysis, one we will exploit in \Cref{sec:abstractions}.
The second difference is that the environment $ρ$ and the heap $μ$ do not map to
addresses or syntactic closures but to delayed semantic values $\later \StateD$,
offering further abstraction possibilities compared to the rigid and indirect
syntactic domain.
The third difference is in control structure which explicitly signals the
distinction between evaluation states and return states.
In a return state $((\lbl,v),μ)$, the syntactic value's label $\lbl$ travels
together with a \emph{semantic} value $v ∈ \StateV$.
Crucially, this allows the embedding of function values $\FunV(f)$ in the
lambda case $\semst{\Lam{\px}{\pe}}$, enabling a compositional definition of the
application case $\semst{\pe~\px}$, just as in $\semscott{\wild}$.

It is worth noting that without guarded recursive types, the definition of
$\StateV$ would not be well-founded; a nuisance usually solved via restriction
to continuous functions on Scott domains and solving the corresponding domain
equation.

Note that we will continue to use the cons notation $τ \cons τ'$ quite liberally
to denote concatenation of traces. Doing so is unambiguous (because states are
distinct from traces) and well-defined via the following guarded fixpoint:
\[
  \fix (f : \later (\STraces \to \STraces \to \STraces)).\ λ(τ : \STraces)~(τ' : \STraces).\ \begin{cases}
    \stuckend{σ} & τ = \stuckend{σ} \\
    σ \cons τ'   & τ = \goodend{σ} \\
    σ \cons f \aplater τ^{\later} \aplater \purelater τ' & τ = σ \cons τ^{\later} \\
  \end{cases}
\]
A similar productive definition can be given for $\betastep$, which is to be
understood as yielding from the input trace $τ$ until it hits either end case of
the trace.

Intuitively, the heap lists the denotation of the expression bound at a
particular address, while the environment passed to $\semst{\wild}$ assigns each
free variable $\px$ a $\mathit{deref}(\pa)$ action for the particular address that $\px$
should be bound to.

Let us now understand $\semst{\wild}$ by way of evaluating the example program
from earlier, $\pe \triangleq \Let{i}{\Lam{x}{x}}{i~i}$:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[mymatrixenv,anchor=center]
      \matrix [mymatrix] (m)
      {
        1 & (\pe, []) \cons {} & \hspace{3.7em} & \hspace{4.2em} & \hspace{3.9em} & \hspace{2.5em} \\
        2 & (i~i, μ) \cons {} & & & & \\
        3 & (i, μ) \cons {} & & & & \\
        4 & ((\Lam{x}{x}, \FunV(f)), μ) \cons {} & & & & \\
        5 & ((\Lam{x}{x}, \FunV(f)), μ) \cons {} & & & & \\
        6 & (x, μ) \cons {} & & & & \\
        7 & ((\Lam{x}{x}, \FunV(f)), μ) \cons {} & & & & \\
        8 & \goodend{((\Lam{x}{x}, \FunV(f)), μ)} & & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{8}{$\semst{\pe}_{[]}$}
      \myleftbrace{4}{1}{2}{$\BindT$}
      \myleftbrace{4}{2}{8}{$\semst{i~i}_{ρ_1}$}
      \myleftbrace{5}{2}{3}{$\AppIT$}
      \myleftbrace{5}{3}{5}{$\semst{i}_{ρ_1}$}
      \myleftbrace{5}{5}{6}{$\AppET$}
      \myleftbrace{5}{6}{8}{$\semst{x}_{ρ_2}$}
      \myleftbrace{6}{3}{4}{$\LookupT$}
      \myleftbrace{6}{4}{5}{$\UpdateT$}
      \myleftbrace{6}{6}{7}{$\LookupT$}
      \myleftbrace{6}{7}{8}{$\UpdateT$}
  \end{tikzpicture}
  $}} &
  \!\!\!\!\text{where}  \begin{array}{ll}
  ρ_1 = [i ↦ \mathit{deref}(\pa_1)] & \\
  ρ_2 = ρ_1[x ↦ \mathit{deref}(\pa_1)] &  \\
  μ = [\pa_1 ↦ \semst{\Lam{x}{x}}_{ρ_1}] & \\
  f = d \mapsto \semst{\px}_{ρ_1[\px↦d]}
  \end{array}
\end{array}\]
The annotations to the right of the trace can be understood as denoting the
``call graph'' of $\semst{\pe}_{[]}$, with the corresponding LK transitions
as leaves.
Evaluation begins with a $\BindT$ transition from state 1 to state 2.
A fresh address $\pa_1$ is allocated for variable $i$ and the heap is extended
with $\semst{\Lam{x}{x}}_{ρ_1}$.
It is interesting to realise that this process does not involve a fixpoint
despite the recursive semantics of let.
Of course, the self-application in $\mathit{deref}$ does the job just as well, as we will
see in due course.

Evaluation recurses into the body $\semst{i~i}_{ρ_1}$ in the extended
environment $ρ_1$ to produce state 2, also yielding another $\AppIT$ transition
into $\semst{i}_{ρ_1}$.
Note that the final state 5 of $\semst{i}_{ρ_1}$ will later be fed (via
$\betastep$) into anonymous function in $\mathit{apply}$.
This scheme is quite common: Continuation items of the transition semantics
(``data'') are reflected into the call stack of the trace semantics (``code'').

$\semst{i}_{ρ_1}$ guides the trace through a heap lookup:
A $\LookupT$ goes straight into the $\mathit{deref}(\pa_1)$ action stored in the
environment entry for $i$, which performs the aforementioned self-application
to run the heap action $μ(\pa_1) = \semst{\Lam{x}{x}}_{ρ_1}$ starting in the
current heap $μ$.
Evaluation of $\semst{\Lam{x}{x}}_{ρ_1}$ terminates immediately in return state
4.
Returning to $\mathit{deref}(\pa_1)$, we witness for the first time a reduction
operation via $\betastep$:
Since the trace terminates, the anonymous function in $\mathit{deref}(\pa_1)$ is called
(in $\betastep$) with state 4, making an $\UpdateT$ transition to state 5.
Note that there is no observable change to the heap $μ$ because
$\mathit{ret}(\Lam{x}{x}, \FunV(f))$ is precisely the same as $\semst{\Lam{x}{x}}_{ρ_1}$.

After the heap update we leave $\semst{i}$ in return state 5, where $\betastep$
yields to the anonymous function in $\mathit{apply}$ (from the call to
$\semst{i~i}_{ρ_1}$), yielding another $\AppET$ reduction and giving control
to $f(ρ_1(i)) = \semst{x}_{ρ_1[x ↦ ρ_1(i)]}$.
Since $x$ is an alias for $i$, steps 6 to 8 just repeat the same same heap
update sequence we observed in steps 3 to 5, concluding the example.

It is useful to review another example involving an observable heap
update. The following trace begins right before the heap update occurs in
$\Let{i}{(\Lam{y}{\Lam{x}{x}})~i}{i~i}$, that is, after reaching the value
in $\semst{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1}$:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[baseline={-0.5ex},mymatrixenv]
      \matrix [mymatrix] (m)
      {
        1 & ((\Lam{x}{x},\FunV(f)), μ_1) \cons {} & \hspace{4em} & \hspace{4em} & \hspace{2.5em} \\
        2 & ((\Lam{x}{x},\FunV(f)), μ_2) \cons {} & & & \\
        3 & (x, μ_2) \cons {} & & & \\
        4 & ((\Lam{x}{x}, \FunV(f)), μ_2) \cons {} & & & \\
        5 & \goodend{((\Lam{x}{x}, \FunV(f)), μ_2)} & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{5}{$\semst{i~i}_{ρ_1}$}
      \myleftbrace{4}{1}{2}{$\semst{i}_{ρ_1}$}
      \myleftbrace{4}{2}{3}{$\AppET$}
      \myleftbrace{4}{3}{5}{$\semst{x}_{ρ_3}$}
      \myleftbrace{5}{1}{2}{$\UpdateT$}
      \myleftbrace{5}{3}{4}{$\LookupT$}
      \myleftbrace{5}{4}{5}{$\UpdateT$}
    \end{tikzpicture}
  $}} &
  \!\!\!\text{where} \begin{array}{l}
  ρ_1 = [i ↦ \pa_1] \\
  ρ_2 = [i ↦ \pa_1, y ↦ \pa_1] \\
  ρ_3 = [i ↦ \pa_1, y ↦ \pa_1, x ↦ \pa_1] \\
  μ_1 = [\pa_1 ↦ \semst{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1}] \\
  μ_2 = [\pa_1 ↦ \semst{\Lam{x}{x}}_{ρ_2}] \\
  f = \fn{d}{\semst{\px}_{ρ_2[\px↦d}} \\
  \end{array} \\
\end{array}\]
Note that both the denotation in the heap \emph{and} its environment are updated
in state 2, and that the new denotation is immediately visible on the next heap
lookup in state 3, so that $\semst{\Lam{x}{x}}_{ρ_2}$ takes control rather than
$\semst{(\Lam{y}{\Lam{x}{x}})~i}_{ρ_1}$, just as the transition system requires.

The handling of data types and case expressions is routine (if a bit
syntactically heavy) and not different to denotational semantics in call-by-name
or call-by-value, but it allows us to observe type errors other than scoping
errors.
Let us consider evaluation of the closed expression
$\pe \triangleq \Let{x}{\ttrue}{\ttrue~x}$
(where $\ttrue$ is one of two unary data constructors of the data type $\bool
::= \ttrue \mid \ffalse$).
$\semst{\wild}$ makes it is easy to observe that the trace gets stuck:
\[\begin{array}{ll}
  \newcommand{\myleftbrace}[4]{\draw[mymatrixbrace] (m-#2-#1.west) -- node[right=2pt] {#4} (m-#3-#1.west);}
  \vcenter{\hbox{$
    \begin{tikzpicture}[baseline={-0.5ex},mymatrixenv]
      \matrix [mymatrix] (m)
      {
        1 & (\pe, []) \cons {} & \hspace{4em} & \hspace{5em} & \hspace{2.5em} \\
        2 & (\ttrue~x, μ) \cons {} & & & \\
        3 & \stuckend{((\ttrue,\ConV(\ttrue)), μ)} & & & \\
      };
      % Braces, using the node name prev as the state for the previous east
      % anchor. Only the east anchor is relevant
      \foreach \i in {1,...,\the\pgfmatrixcurrentrow}
        \draw[dotted] (m.east|-m-\i-\the\pgfmatrixcurrentcolumn.east) -- (m-\i-2);
      \myleftbrace{3}{1}{3}{$\semst{\pe}_{[]}$}
      \myleftbrace{4}{1}{2}{$\BindT$}
      \myleftbrace{4}{2}{3}{$\semst{\ttrue~x}_{ρ}$}
      \myleftbrace{5}{2}{3}{$\AppIT$}
    \end{tikzpicture}
  $}} &
  \!\!\!\text{where} \begin{array}{l}
  ρ = [x ↦ \pa_1] \\
  μ = [\pa_1 ↦ \semst{\ttrue}_ρ] \\
  \end{array} \\
\end{array}\]
Crucially, $\betastep$ is equipped to propagate $\stuckend{\wild}$ up the call
stack (through potential $\UpdateT$ transitions, in particular), similar to
\citeauthor{Milner:78}'s $\mathbf{wrong}$.

Diverging traces hold no new surprises, other than they are observably different
to stuck traces.

\subsection{Maximal LK Traces}
\label{sec:maximal-traces}

It turns out that the traces $\semst{\pe}$ generates correspond to
\emph{maximal} traces in the LK transition system.
Let us make precise what that means.

A transition system is characterised by the set of \emph{traces} it generates.
An \emph{LK trace} is a trace in $(\smallstep)$, \eg, a non-empty and
potentially infinite sequence of LK states $(σ_i)_{i∈\overline{n}}$
(where $\overline{n} = \{ m ∈ ℕ_+ \mid m ≤ n \}$ when $n∈ℕ_+$, $\overline{ω} = ℕ_+$),
such that $σ_i \smallstep σ_{i+1}$ for $i,(i+1)∈\overline{n}$.

The \emph{source} state $σ_1$ exists for finite and infinite traces, while the
\emph{target} state $σ_n$ is only defined when $n \not= ω$ is finite.

For proofs, we will often regard $(σ_i)_{i∈\overline{n}}$ as an object of type
$∃n∈ℕ_ω.\ \overline{n} \to \States$, where $ℕ_ω$ is defined by guarded recursion
as $ℕ_ω = \{1\} + \later ℕ_ω$.
The constructor for the right sum alternative is written $1 + $ (a different
kind of $+$ than in the recursive equation for $ℕ_ω$).
Now $ℕ_ω$ contains all natural numbers (where $n$ is encoded as $(1+)^{n-1}(1)$) and
the transfinite limit ordinal $ω = 1 + (1 + ...)$.
Hence, when $(σ_i)_{i∈\overline{n}} ∈ \STraces$ is an LK trace and $n > 1$, then
$(σ_{i+1})_{i∈\overline{n-1}} ∈ \later \STraces$ is the guarded tail of the
trace with an associated induction principle.

An important kind of trace is one that never leaves the evaluation context of
its source state:

\begin{definition}[Deep, interior and balanced traces]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is
  \emph{$κ$-deep} if every intermediate continuation
  $κ_i = \mathit{cont}(σ_i)$ extends $κ$ (so $κ_i = κ$ or $κ_i = ... \pushF κ$,
  abbreviated $κ_i = ...κ$).

  A trace $(σ_i)_{i∈\overline{n}}$ is called \emph{interior} if it is
  $\mathit{cont}(σ_1)$-deep.
  Furthermore, an interior trace $(σ_i)_{i∈\overline{n}}$ is
  \emph{balanced}~\citep{Sestoft:97} if the target state exists and is a return
  state with continuation $κ_1$.

  We notate $κ$-deep, interior and balanced traces as
  $\deep{κ}{(σ_i)_{i∈\overline{n}}}$, $\interior{(σ_i)_{i∈\overline{n}}}$ and
  $\balanced{(σ_i)_{i∈\overline{n}}}$, respectively.
\end{definition}

\begin{example}
  Let $ρ=[x↦\pa_1],μ=[\pa_1↦([], \Lam{y}{y})]$ and $κ$ an arbitrary
  continuation. The trace
  \[
     (x, ρ, μ, κ) \smallstep (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, κ)
  \]
  is interior and balanced. Its prefixes are interior but not balanced.
  The trace suffix
  \[
     (\Lam{y}{y}, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep (\Lam{y}{y}, ρ, μ, κ)
  \]
  is neither interior nor balanced.
\end{example}

We will say that the transition rules $\LookupT$, $\AppIT$, $\CaseIT$ and $\BindT$
are interior, because the lifting into a trace is, whereas the returning
transitions $\UpdateT$, $\AppET$ and $\CaseET$ are not.

A balanced trace starting at a focus expression $\pe$ and ending with $\pv$
loosely corresponds to a derivation of $\pe \Downarrow \pv$ in a natural
big-step semantics~\citep{Sestoft:97} or a non-$⊥$ result in a denotational
semantics.

It is when a derivation in a natural semantics does not exist that a small-step
semantics shows finesse, in that it differentiates two different kinds of
\emph{maximally interior} (or, just \emph{maximal}) traces:

\begin{definition}[Maximal trace]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is \emph{maximal} if and only if it is
  interior and there is no $σ_{n+1}$ such that $(σ_i)_{i∈\overline{n+1}}$ is
  interior.
  More formally (and without a negative occurrence of ``interior''),
  \[
    \maxtrace{(σ_i)_{i∈\overline{n}}} \triangleq \interior{(σ_i)_{i∈\overline{n}}} \wedge (\not\exists σ_{n+1}.\ σ_n \smallstep σ_{n+1} \wedge \mathit{cont}(σ_{n+1}) = ...\mathit{cont}(σ_1))
  \]
  We notate maximal traces as $\maxtrace{(σ_i)_{i∈\overline{n}}}$.
\end{definition}

We call infinite and interior traces \emph{diverging}.
A maximally finite, but unbalanced trace is called \emph{stuck}.
Note that usually stuckness is associated with a state of a transition
system rather than a trace.
That is not possible in our framework; the following example clarifies.

\begin{example}[Stuck and diverging traces]
Consider the interior trace
\[
             (\ttrue~x, [x↦\pa_1], [\pa_1↦...], κ)
  \smallstep (\ttrue, [x↦\pa_1], [\pa_1↦...], \ApplyF(\pa_1) \pushF κ)
\]
It is stuck, but its singleton suffix is balanced.
An example for a diverging trace where $ρ=[x↦\pa_1]$ and $μ=[\pa_1↦(x,ρ,())]$ is
\[
  (\Let{x}{x}{x}, [], [], κ) \smallstep (x, ρ, μ, κ) \smallstep (x, ρ, μ, \UpdateF(\pa_1) \pushF κ) \smallstep ...
\]
\end{example}

A maximal trace that is not balanced either diverges or is stuck:

\begin{lemma}[Characterisation of maximal traces]
  An LK trace $(σ_i)_{i∈\overline{n}}$ is maximal if and only if it is balanced,
  diverging or stuck.
\end{lemma}
\begin{proof}
  $\Rightarrow$: Let $(σ_i)_{i∈\overline{n}}$ be maximal.
  If $n=ω$ is infinite, then it is diverging due to interiority, and if
  $(σ_i)_{i∈\overline{n}}$ is stuck, the goal follows immediately.
  So we assume that $(σ_i)_{i∈\overline{n}}$ is maximal, finite and not stuck,
  so it must be balanced by the definition of stuckness.

  $\Leftarrow$: Both balanced and stuck traces are maximal.
  A diverging trace $(σ_i)_{i∈\overline{n}}$ is interior and infintie,
  hence $n=ω$.
  Indeed $(σ_i)_{i∈\overline{ω}}$ is maximal, because the expression $σ_{ω+1}$
  is undefined and hence does not exist.
\end{proof}

Interiority guarantees that the particular initial stack $κ$ of a maximal trace
is irrelevant to execution, so maximal traces that differ only in the initial
stack are bisimilar.

One class of maximal traces is of particular interest:
The maximal trace starting in $inj(\pe)$ (or, rather whether it is infinite,
stuck or balanced) is the defining operational characteristic of $\pe$.

If we can show that $\semst{\pe}$ associates similar meaning to $\pe$, we have
proven it an adequate replacement for the LK transition system.

\subsection{Adequacy}

\Cref{fig:semst-correctness} shows the correctness predicate $\mathcal{C}$ in
our endeavour to prove $\semst{\wild}$ adequate.
It builds on the framework of maximal LK traces established in the last section;
specifically it encodes that an abstraction of every maximal LK trace can be
recovered by running $\semst{\wild}$ starting from the abstraction of an initial
state.

\begin{figure}
\[\begin{array}{rcl}
  α_\Environments(ρ) & = & \mathit{deref} \circ ρ \\
  α_\Heaps([\many{\pa ↦ (ρ,\pe)}]) & = & [\many{\pa ↦ \idiom{\semst{\pe}_{α_\Environments(ρ)}}}] \\
  α_\States(\slbl \Lam{\px}{\pe},ρ,μ,κ) & = & ((\lbl,\FunV(\fn{d}{\idiom{\semst{\pe}_{α_\Environments(ρ)[\px↦d]}}})),α_\Heaps(μ)) \\
  α_\States(\slbl K~\overline{\px},ρ,μ,κ) & = & ((\lbl,\ConV(K,\overline{\idiom{\semst{\px}_{α_\Environments(ρ)}}})),α_\Heaps(μ)) \\
  α_\States(\pe,ρ,μ,κ) & = & (\pe,α_\Heaps(μ)) \\
  α_{\STraces}((σ_i)_{i∈\overline{n}},κ) & = & \begin{cases}
    α_\States(σ_1) \cons \idiom{α_{\STraces}((σ_{i+1})_{i∈\overline{n-1}},κ)} & n > 1 \\
    \goodend{α_\States(σ_1)} & \mathit{ctrl}(σ_1) \text{ value } \wedge \mathit{cont}(σ_1) = κ \\
    \stuckend{α_\States(σ_1)} & \text{otherwise} \\
  \end{cases} \\
  \mathcal{C}((σ_i)_{i∈\overline{n}}) & = & \maxtrace{(σ_i)_{i∈\overline{n}}} \Longrightarrow ∀((\pe,ρ,μ,κ) = σ_1).\ α_{\STraces}((σ_i)_{i∈\overline{n}},κ) = \semst{\pe}_{α_\Environments(ρ)}(α_\Heaps(μ)) \\
\end{array}\]
\caption{Correctness predicate for $\semst{\wild}$, defining the family of functions $α_\LKStates$}
  \label{fig:semst-correctness}
\end{figure}

The family of abstraction functions (which we henceworth refer to as
$α_\LKStates$ and treat as overloaded for $\Environments,\Heaps,\States$ and
$\STraces$) makes precise the intuitive connection between the semantic objects
in $\semst{\wild}$ and the syntactic objects in the transition system.

We will sometimes need to disambiguate the clashing definitions from
\Cref{sec:semantics} and \Cref{sec:problem}.
We do so by adorning semantic objects with a tilde, so $\tr \triangleq
α_\Environments(ρ)$ denotes a semantic environment which in this instance is
defined to be the abstraction of a syntactic environment $ρ$.

%We will often talk about states that are well-elaborated and have a certain
%expression in control, hence we abbreviate this set as
%\[
%  \States_\pe \triangleq \{σ ∈ \States \mid \elabstate{σ} \wedge \mathit{ctrl}(σ)=\pe\},
%\]

Note first that $α_\STraces$ is effectively defined by guarded recursion over
the LK trace, in the sense defined in \Cref{sec:maximal-traces}.
As such, the expression $\idiom{α_{\STraces}((σ_{i+1})_{i∈\overline{n-1}},κ)}$ has type
$\later \tSTraces$ (the $\later$ in the type of $(σ_{i+1})_{i∈\overline{n-1}}$
maps through $α_\STraces$ via the idiom brackets).
Likewise, $=$ on $\tSTraces$ is defined in the obvious structural way by guarded
recursion (as it would be if it was a finite, inductive type).

Our first goal is to establish a few auxiliary lemmas showing what kind of
properties of LK traces are preserved by $α_\States$ and in which way.

\begin{lemma}[Preservation of length]
  \label{thm:abs-length}
  Let us define the length $\mathit{len} : \tSTraces \to ℕ_ω$ of a trace by
  guarded recursion
  \[
    \mathit{len}(τ) = \begin{cases}
      1 + \idiom{\mathit{len}(τ^{\later})} & τ = σ \cons τ^{\later} \\
      1 & \text{otherwise} \\
    \end{cases}
  \]
  Now let $(σ_i)_{i∈\overline{n}}$ be an arbitrary trace.
  Then $\mathit{len}(α_\STraces((σ_i)_{i∈\overline{n}},\mathit{cont}(σ_1))) = n$.
\end{lemma}
\begin{proof}
  This is quite simple to see and hence a good opportunity to familiarise
  ourselves with the concept of \emph{Löb induction}, the induction principle of
  guarded recursion.
  Löb induction arises simply from applying the guarded recursive fixpoint
  combinator to a proposition:
  \[
    \textsf{löb} = \fix : \forall P.\ (\later P \Longrightarrow P) \Longrightarrow P
  \]
  That is, we assume that our proposition holds \emph{later}, \eg
  \[
    IH ∈ (\later P \triangleq \later (
        \forall n ∈ ℕ_ω.\
        \forall (σ_i)_{i∈\overline{n}}.\
        \mathit{len}(α_\STraces((σ_i)_{i∈\overline{n}},\mathit{cont}(σ_1))) = n
      ))
  \]
  and use $IH$ to prove $P$.
  Let us assume $n$ and $(σ_i)_{i∈\overline{n}}$ are given, define
  $τ \triangleq α_\STraces((σ_i)_{i∈\overline{n}},\mathit{cont}(σ_1))$ and proceed by case analysis
  over $n$:
  \begin{itemize}
    \item \textbf{Case $n=1$}: Then either we have $τ = \goodend{α_\States(σ_1)}$
      or $τ = \stuckend{α_\States(σ_1)}$, $j = 1$, both of which map to $1$ under
      $\mathit{len}$.
    \item \textbf{Case $n>1$}: Then $n = 1+m$ and $m ∈ \later ℕ_ω$ and the
      first case of $α_\States$ applies, hence $τ = σ \cons τ^{\later}$ for some
      $σ∈\States, τ^{\later}∈\later \tSTraces$.
      Now we apply the inductive hypothesis, as follows:
      Let $(σ_{i+1})_{i∈\overline{m}} ∈ \later \STraces$ be the guarded
      tail of the LK trace $(σ_i)_{i∈\overline{n}}$.
      Then we can apply $IH \aplater m \aplater (σ_{i+1})_{i∈\overline{m}}$ and
      get a proof for $\later (\mathit{len}(τ^{\later}) = m)$.
      Now we can prove
      \[
        n = 1 + m = 1 + \mathit{len}(τ^{\later}) = \mathit{len}(τ).
      \]
  \end{itemize}
\end{proof}

\begin{lemma}[Preservation of components]
  \label{thm:abs-states}
  Let $(σ_i)_{i∈\overline{n}}$ be a trace and let $τ = α_\STraces((σ_i)_{i∈\overline{n}},\mathit{cont}(σ_1))$.
  Then for all $j∈\overline{n}$, $τ_j = α_\States(σ_j)$
  (where $τ_j$ denotes the $j$th state in $τ$).
\end{lemma}
\begin{proof}
  With \Cref{thm:abs-length} it is enough to regard the finite prefix of the
  trace $(σ_i)_{i∈\overline{j}}$, for which the proposition is easily shown by
  induction on $j$.
\end{proof}

\begin{lemma}[Preservation of characteristic]
  \label{thm:abs-max-trace}
  Let $(σ_i)_{i∈\overline{n}}$ be a maximal trace.
  Then $α_\STraces((σ_i)_{i∈\overline{n}}, cont(σ_1))$ is ...
  \begin{itemize}
    \item ... infinite if and only if $(σ_i)_{i∈\overline{n}})$ is diverging
    \item ... ending with $\goodend{\wild}$ if and only if $(σ_i)_{i∈\overline{n}}$ is balanced
    \item ... ending with $\stuckend{\wild}$ if and only if $(σ_i)_{i∈\overline{n}}$ is stuck
  \end{itemize}
\end{lemma}
\begin{proof}
  The first point follows by a similar inductive argument as in \Cref{thm:abs-length}.

  In the other cases, we may assume that $n$ is finite.
  If $(σ_i)_{i∈\overline{n}}$ is balanced, then $σ_n$ is a return state with
  continuation $\mathit{cont}(σ_1)$, so its control expression is a value.
  Then $α_\STraces$ will conclude with $\goodend{\wild}$.
  Conversely, if the trace ended with $\goodend{\wild}$, then $\mathit{cont}(σ_n) = \mathit{cont}(σ_1)$
  and $\mathit{ctrl}(σ_n)$ is a value, so $(σ_i)_{i∈\overline{n}}$ forms a
  balanced trace.
  The stuck case is similar.
\end{proof}

%\begin{lemma}[S3]
%  \label{thm:s3}
%  If $σ ∈ \States_\pe$, then $\elabtrace{\semst{\pe}(σ)}$.
%\end{lemma}
%\begin{proof}
%By coinduction, following~\citet{Czajka:2019}.
%The coinduction hypothesis is:
%\[
%  P(α) = ∀σ,\pe.\ σ ∈ \States_\pe \Longrightarrow \elabtracen{α}{\semst{\pe}(σ)}
%\]
%Where $α$ is a limit ordinal smaller than or equal to the closure ordinal $ζ$,
%$\mathit{ctrl}(σ)$ selects the control of $σ$ and $\elabtracen{α}{τ}$ is the
%$α$-approximant of the coinductive predicate $\elabtrace{τ}$.
%
%Let us assume that $\elabstate{σ}$ for an arbitrary $σ$ with control expression
%$\pe$. Whenever $f(σ)$ is undefined for some $f$, we can see that
%$step(f)(σ) = \goodend{σ}$ is well-elaborated. Furthermore, if both $g$ and $h$
%yield well-elaborated traces given a well-elaborated input state, then
%$g \sfcomp h$ does so, too.
%
%We abbreviate $τ \triangleq \semst{\pe}(σ)$ and proceed by case analysis over
%$\pe$. We have $src_\States(τ) = σ$ by (S1) which is thus well-elaborated.
%\begin{itemize}
%  \item \textbf{Case $\px$}:
%    Let us assume first that $look(\px)(σ)$ is undefined.
%    Then $step(look(\px))(σ) = \goodend{σ}$.
%    On the other hand, $step(upd)(σ) = \goodend{σ}$ because $upd$ is only defined on
%    return states.
%    Thus, $τ = \goodend{σ}$ and $\elabtracen{α+1}{τ}$.
%
%    When $look(\px)(σ)$ is defined, $σ$ must be of the form $(\px,ρ,μ,κ)$, and
%    $\pa,\pe,ρ',d$ must exist as in the definition of $look$ (shadowing $\pe =
%    \px$ from the assumption, for simplicity).
%    Clearly, $σ' \triangleq (\pe, ρ', μ, \UpdateF(\pa) \pushF κ)$ is
%    well-elaborated, because $σ$ is and the heap did not change.
%    Similarly, by $\elabstate{σ}$ we have $d = \semst{\pe}$.
%    Now we apply the coinduction hypothesis to $τ' = \semst{\pe}(σ')$
%    (noting that $\semst{\pe}$ is well-defined on $σ'$) and see that
%    $\elabtracen{α}{τ'}$, hence $\elabtracen{α+1}{(σ \cons τ')}$.
%
%    If $τ'$ is infinite, we are done.
%    Otherwise, $σ_u \triangleq tgt_\States(τ')$ is well-elaborated and if
%    $upd(σ_u)$ is undefined we are done, too, by our preceding considerations.
%    If $σ_v \triangleq upd(σ_u)$, the $σ_u$ must have the form
%    $((\pv,v),ρ,μ,\UpdateF(\pa) \pushF κ)$. We must show that
%    $step(val(\pv,v)) = \semst{\pv}$ in order to show that $σ_v$ is
%    well-elaborated.
%    That is the case: well-elaboratedness of $σ_u$ implies that $v = \FunV(f)$
%    for an $f$ just like that in the definition of $\semst{\pv}$.
%    Since $τ'$ is finite, we have $\elabtracen{α+1}{(σ \cons τ' \cons \goodend{σ_v})}$ by
%    reassociating the applications of the $\elabtrace{\wild}$ functional.
%  \item \textbf{Case $\Lam{\px}{\pe}$}:
%    The $\ValueT$ transition does not change the heap, but it transitions into a
%    return state. We have established in the previous point that the semantic
%    value $\FunV(f)$ fits our requirements for well-elaboratedness exactly,
%    hence well-elaboratedness for the trace follows.
%  \item \textbf{Case $\pe~\px$}:
%    The $\AppIT$ transition preserves well-elaboratedness to its target state, so
%    the input $σ'$ to $\semst{\pe}$ is well-elaborated. We apply the coinduction
%    hypothesis and and have $\elabtracen{α+1}{(σ \cons \semst{\pe}(σ'))}$.
%    (As before, if the resulting trace is infinite, we are done.)
%    Forward composition preserves well-elaboratedness, hence it suffices to
%    prove that given a well-elaborated input state $σ''$, $\mathit{apply}(σ'')$ is
%    well-elaborated.
%    That is the case if the subterm $f(\pa)(σ'')$ produces a well-elaborated
%    trace.
%    By $\elabstate{σ''}$, we know that $f$ must come from the
%    $\semst{\Lam{\px}{\pe'}}$ case.
%    $\AppET$ preserves well-elaboratedness to its target state and for
%    $\semst{\pe'}$ we can apply the coinductive hypothesis.
%    Now we have $\elabtracen{α+1}{(σ \cons \semst{\pe}(σ'))}$ and
%    $\elabtracen{α+1}{\mathit{apply}(σ'')}$, so the same must hold for its concatenation.
%  \item \textbf{Case $\Let{\px}{\pe_1}{\pe_2}$}:
%    The $\BindT$ transition updates the heap, but it is clear that
%    $bind(\semst{\pe_1})$ elaborates the correct $d_1$ into $σ'$.
%    For the recursive call, we apply the coinduction hypothesis
%    and conclude $\elabtracen{α+1}{(σ \cons \semst{\pe_2}(σ'))}$.
%\end{itemize}
%\end{proof}
%
%The preceding lemma implies a very desirable property:
%Whenever $σ$ is well-elaborated (and thus a total element of the approximation
%order), $\semst{\pe}(σ)$ is total, too.
%The approximation order restricted to total elements is discrete; hence we may
%now put domain theoretic considerations behind us in favor of a coinductive
%understanding.
%We can capture the termination properties of $\semst{\wild}$ as follows:
%
%\begin{corollary}
%  The restriction of $\semst{\pe}$ to $\States_\pe$ is a total function, defined
%  by \emph{guarded recursion}.
%\end{corollary}
%
%\begin{lemma}
%  \label{thm:step-interior}
%  If $f(σ) = τ$ implies $σ \smallstep src_\States(τ)$ interior and
%  $τ$ interior, then $step(f)(σ)$ interior.
%\end{lemma}
%\begin{proof}
%  Immediate. The case where $f$ is undefined is trivial.
%\end{proof}

With increased clarity, we go on to prove the correctness predicate:

\begin{theorem}[Correctness of $\semst{\wild}$]
  \label{thm:semst-correct}
  $\mathcal{C}$ from \Cref{fig:semst-correctness} holds everywhere.
  That is, whenever $(σ_i)_{i∈\overline{n}}$ is a maximal LK trace with source
  state $(\pe,ρ,μ,κ)$, we have
  $α_{\STraces}((σ_i)_{i∈\overline{n}},κ) = \semst{\pe}_{α_\Environments(ρ)}(α_\Heaps(μ))$.
\end{theorem}
\begin{proof}
By Löb induction, with the following hypothesis:
\[
  IH ∈ \later (\forall (σ_i)_{i∈\overline{n}}.\ C((σ_i)_{i∈\overline{n}}))
\]
Furthermore, we tacitly assume by (S3) that all occuring states are
well-elaborated. We will say that a state $σ$ is stuck if there is no applicable
rule in the transition system (\ie, $\goodend{σ}$ is a stuck maximal trace).

We abbreviate $τ \triangleq \semst{\pe}(σ)$ and proceed by case analysis over
$\pe$.
\begin{itemize}
  \item \textbf{Case $\px$}:
    Let us assume first that $look(\px)(σ)$ is undefined. Then the lookup
    $ρ(\px)$ must have failed and $\goodend{σ}$ is the result.
    On the other hand, $step(upd)(σ) = \goodend{σ}$ because $upd$ is only defined on
    return states, so $\goodend{σ}$ is the result of the composition, which is stuck
    and thus maximal.

    When $look(\px)(σ)$ is defined, $σ$ must be of the form $(\px,ρ,μ,κ)$, and
    $\pa,\pe,ρ',d$ must exist as in the definition of $look$.
    Clearly, $σ \smallstep (σ' \triangleq (\pe, ρ', μ, \UpdateF(\pa) \pushF κ))$
    by interior rule $\LookupT$.
    By $\elabstate{σ'}$ we have $d = \semst{\pe}$.
    Now we apply the coinduction hypothesis to $τ' \triangleq \semst{\pe}(σ')$
    and see that $\maxtracen{α}{τ'}$, hence with \Cref{thm:step-interior}
    $\interiorn{α+1}{σ \cons τ'}$.

    If $τ'$ is infinite, it is diverging and $\maxtracen{α+1}{σ \consτ'}$ follows.
    Otherwise, $σ_u \triangleq tgt_\States(τ')$ and either there is no
    transition $σ_u \smallstep σ_v$ or it leaves $\mathit{cont}(σ')$.
    The only two returning (\eg, non-interior) transitions are $\UpdateT$ and
    $\AppET$. Both pop a single continuation frame, thus $\mathit{cont}(σ_u) = \mathit{cont}(σ')$,
    because otherwise $\mathit{cont}(σ_u) = ... \pushF \mathit{cont}(σ')$ and popping one frame
    yields an interior transition.

    If $upd(σ_u)$ is defined, then the $\UpdateT$ transition exists as can
    easily be checked.
    Furthermore, since exactly one frame is popped, we must have
    $\mathit{cont}(σ) = \mathit{cont}(σ_v)$ and thus $\deepn{α+1}{\mathit{cont}(σ)}{(σ \cons τ \cons \goodend{σ_v})}$ by slight
    (corecursive) rearrangement of the proof for $\interiorn{α}{τ}$.
    $σ_v$ is a return state and any further transition must pop a continuation
    frame; hence $\maxtracen{α+1}{(σ \cons τ \cons \goodend{σ_v})}$.

    If $upd(σ_u)$ is undefined, then the $\UpdateT$ transition could not have
    fired. But the $\AppET$ transition can't have fired either, because if it
    could, we'd have $\mathit{cont}(σ_u) = \mathit{cont}(σ')$ by $\maxtracen{α}{τ'}$, but the top
    of $σ'$ is an update frame. Thus, again by maximality, there is no
    transition $σ_u \smallstep σ_v$ whatsoever and $\maxtracen{α+1}{σ \cons τ'}$.

  \item \textbf{Case $\Lam{\px}{\pe}$}:
    If $val(v, \FunV(f))$ is defined, then $σ \smallstep{\ValueT} σ'$ must
    exist. Furthermore, $σ \cons \goodend{σ'}$ is a maximal trace, as $σ'$ is a return
    state and any applicable transition leaves $\mathit{cont}(σ) = \mathit{cont}(σ')$.

    If $val(v, \FunV(f))$ is undefined, then $\mathit{ctrl}(σ) \not= \Lam{\px}{\pe}$, a
    contradiction.
  \item \textbf{Case $\pe~\px$}:
    If $app_1(\pe~\px)$ is undefined, then either $\mathit{ctrl}(σ) \not=\pe~\px$
    (contradiction), or $ρ(\px)$ was undefined, in which case $\goodend{σ}$ is stuck
    and thus maximal.

    If $app_1(\pe~\px)$ is defined, then
    $σ \smallstep{\AppIT} (σ' \triangleq (\pe,ρ,μ,\ApplyF(ρ(\px)) \pushF κ))$
    and $τ_1 \triangleq \semst{\pe}(σ')$ with $\maxtracen{α}{τ_1}$.

    Similar to the variable case, if $τ_\pe$ is infinite, $σ \cons τ_\pe$ is
    diverging and we are done. Otherwise, we have $σ_a \triangleq
    tgt_\States(τ_\pe)$ and either there is no transition $σ_a \smallstep σ_e$
    or it leaves $\mathit{cont}(σ')$, in which case we know $\mathit{cont}(σ') = \mathit{cont}(σ_a)$ and
    that the transition must have been $\AppET$.

    When the $\AppET$ transition exists, the first case of $\mathit{apply}(σ_a)$ matches.
    With $\elabstate{σ}$, we know that $f$ is defined just like in
    $\semst{\Lam{\px'}{\pe'}}$, where $\mathit{ctrl}(σ_a) = (\Lam{\px'}{\pe'}, \FunV(f))$.
    Similar to the variable case, we can see that
    $app_2$ matches and that $\maxtracen{α+1}{σ \cons τ_1 \cons \goodend{σ_e}}$, because
    $\mathit{cont}(σ_e) = \mathit{cont}(σ)$. By the coinductive hypothesis,
    $\maxtracen{α}{(τ_2 \triangleq \semst{\pe'}(σ_e))}$. By $\mathit{cont}(σ_e) = \mathit{cont}(σ)$
    and rearrangement we can see that $\interiorn{α+1}{σ \cons τ_1 \cons σ_e \cons τ_2}$ and
    maximality follows directly from maximality of $τ_2$.

    When the $\AppET$ transition does not exist, no other transition from $σ_a$
    does. Then the first case of $\mathit{apply}$ could not match, because the only
    syntactic values $\pv$ are lambdas and $\elabstate{σ_a}$ requires that
    $\FunV(f)$ matches accordingly.
    Thus, $σ \cons τ_1$ is the final, maximal trace.

  \item \textbf{Case $\Let{\px}{\pe_1}{\pe_2}$}:
    The $σ \smallstep{\BindT} σ'$ transition (which always exists for our choice
    of $σ$) does not push a new stack frame, hence $\mathit{cont}(σ) = \mathit{cont}(σ')$ and
    from the coinductive hypothesis $\maxtracen{α}{\semst{\pe_2}(σ')}$ we can
    immediately see $\maxtracen{α+1}{σ \cons \semst{\pe_2}(σ')}$.
\end{itemize}
\end{proof}

\Cref{thm:s2} is the key to proving a strong version of adequacy for
$\semst{\wild}$:

\begin{lemma}[Adequacy of $\semst{\wild}$]
  Let $τ = \semst{\pe}(inj(\pe))$.
  \begin{itemize}
    \item
      $τ$ is balanced iff there exists a final state $σ$ such that
      $inj(\pe) \smallstep^* σ$.
    \item
      $τ$ is stuck iff there exists a non-final state $σ$ such that
      $inj(\pe) \smallstep^* σ$ and there exists no $σ'$ such that $σ \smallstep
      σ'$.
    \item
      $τ$ is diverging iff for all $σ$ with $inj(\pe) \smallstep^* σ$ there
      exists $σ'$ with $σ \smallstep σ'$.
  \end{itemize}
\end{lemma}
\begin{proof}
  Note that $\maxtrace{τ}$ since $inj(\pe) ∈ \States_\pe$
  and the initial state $inj(\pe) = src_\States(τ)$ has an empty continuation.

  Clearly, the trace $τ'$ determined by a $σ$ such that $inj(\pe)
  \smallstep^* σ$ is an interior trace. Since $(\smallstep)$ is
  deterministic, it must be a prefix of the maximally interior trace $τ$.

  \begin{itemize}
    \item[$\Rightarrow$]
      \begin{itemize}
        \item
          If $τ$ is balanced, its target state $σ \triangleq tgt_\States(τ)$
          is a return state that must also have the empty continuation. Hence
          it is a final state and there exists $inj(\pe) \smallstep^* σ$ by
          $\validtrace{τ}$.
        \item
          If $τ$ is stuck, it is finite and maximal, but not balanced, so its
          target state $σ \triangleq tgt_\States(τ)$ cannot be a return state;
          otherwise maximality implies $σ$ has an (initial) empty continuation
          and the trace would be balanced. on the other hand, the only two
          returning transitions apply to return states, so maximality implies
          there is no $σ'$ such that $σ \smallstep σ'$ whatsoever.
        \item
          If $τ$ is diverging it is infinite and for every $σ$ with $inj(\pe)
          \smallstep^* σ$ determinism allows us to trace a finite prefix of
          $τ$, and there always exists $σ'$ such that $σ \smallstep σ'$ since
          $\validtrace{τ}$.
      \end{itemize}

    \item[$\Leftarrow$]
      \begin{itemize}
        \item
          If $σ$ is a final state, it has $\mathit{cont}(σ) = \mathit{cont}(inj(\pe)) = []$, so it
          is balanced.
        \item
          If $σ$ is not a final state, $τ'$ is not balanced. Since there is no
          $σ'$ such that $σ \smallstep^* σ'$, it is still maximal; hence it must
          be stuck.
        \item
          If for every choice of $σ$ (and thus $τ'$) there exists $σ'$ such that
          $σ \smallstep σ'$, there must be an infinite number of such $τ'$, all
          of which are prefixes of $τ$. Hence $τ$ must be infinite and interior,
          hence diverging.
      \end{itemize}
  \end{itemize}
\end{proof}

But there's more. Let us define the following binary relation $\equiv_\States$
by coinduction:
\[
\]

% \begin{theorem}[Full abstraction]
%   \label{thm:full-abstraction}
%  The restriction $S = \fn{\pe}{\semst{\pe}\restrict{\States_\pe}}$ is
%  \emph{fully abstract}~\citep{Plotkin:77}, meaning that
%
%  $\forall \pe_1,\pe_2.\ S(\pe_1) = S(\pe_2)
%
% \end{theorem}

\subsection{Discussion}

\begin{itemize}
  \item Generated traces are not enough to recover transition system. Unnecessary!
  \item Correctness predicate simpler to come up than for liveness analysis directly
  \item Compare to coinductive big-step \citep{LeroyGrall:09}? Perhaps in related work
  \item Full Abstraction. Do we want to prove it? Seems boring and obvious
\end{itemize}
